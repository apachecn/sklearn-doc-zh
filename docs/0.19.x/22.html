
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>2.3. 聚类 · sklearn 中文文档</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="ApacheCN">
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-insert-logo/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-pageview-count/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-emphasize/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-alerts/style.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-auto-scroll-table/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-page-toc-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-advanced-emoji/emoji-website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="23.html" />
    
    
    <link rel="prev" href="21.html" />
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {"buttons":[{"user":"apachecn","repo":"sklearn-doc-zh","type":"star","count":true,"size":"small"}]};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="79.html">
            
                <a href="79.html">
            
                    
                    安装 scikit-learn
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    用户指南
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="1.html">
            
                <a href="1.html">
            
                    
                    1. 监督学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1.1" data-path="2.html">
            
                <a href="2.html">
            
                    
                    1.1. 广义线性模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.2" data-path="3.html">
            
                <a href="3.html">
            
                    
                    1.2. 线性和二次判别分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.3" data-path="4.html">
            
                <a href="4.html">
            
                    
                    1.3. 内核岭回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.4" data-path="5.html">
            
                <a href="5.html">
            
                    
                    1.4. 支持向量机
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.5" data-path="6.html">
            
                <a href="6.html">
            
                    
                    1.5. 随机梯度下降
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.6" data-path="7.html">
            
                <a href="7.html">
            
                    
                    1.6. 最近邻
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.7" data-path="8.html">
            
                <a href="8.html">
            
                    
                    1.7. 高斯过程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.8" data-path="9.html">
            
                <a href="9.html">
            
                    
                    1.8. 交叉分解
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.9" data-path="10.html">
            
                <a href="10.html">
            
                    
                    1.9. 朴素贝叶斯
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.10" data-path="11.html">
            
                <a href="11.html">
            
                    
                    1.10. 决策树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.11" data-path="12.html">
            
                <a href="12.html">
            
                    
                    1.11. 集成方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.12" data-path="13.html">
            
                <a href="13.html">
            
                    
                    1.12. 多类和多标签算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.13" data-path="14.html">
            
                <a href="14.html">
            
                    
                    1.13. 特征选择
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.14" data-path="15.html">
            
                <a href="15.html">
            
                    
                    1.14. 半监督学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.15" data-path="16.html">
            
                <a href="16.html">
            
                    
                    1.15. 等式回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.16" data-path="17.html">
            
                <a href="17.html">
            
                    
                    1.16. 概率校准
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.17" data-path="18.html">
            
                <a href="18.html">
            
                    
                    1.17. 神经网络模型（有监督）
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="19.html">
            
                <a href="19.html">
            
                    
                    2. 无监督学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" data-path="20.html">
            
                <a href="20.html">
            
                    
                    2.1. 高斯混合模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" data-path="21.html">
            
                <a href="21.html">
            
                    
                    2.2. 流形学习
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.2.3" data-path="22.html">
            
                <a href="22.html">
            
                    
                    2.3. 聚类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.4" data-path="23.html">
            
                <a href="23.html">
            
                    
                    2.4. 双聚类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.5" data-path="24.html">
            
                <a href="24.html">
            
                    
                    2.5. 分解成分中的信号（矩阵分解问题）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.6" data-path="25.html">
            
                <a href="25.html">
            
                    
                    2.6. 协方差估计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.7" data-path="26.html">
            
                <a href="26.html">
            
                    
                    2.7. 经验协方差
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.8" data-path="27.html">
            
                <a href="27.html">
            
                    
                    2.8. 收敛协方差
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.9" data-path="28.html">
            
                <a href="28.html">
            
                    
                    2.9. 稀疏逆协方差
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.10" data-path="29.html">
            
                <a href="29.html">
            
                    
                    2.10. Robust 协方差估计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.11" data-path="30.html">
            
                <a href="30.html">
            
                    
                    2.11. 新奇和异常值检测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.12" data-path="31.html">
            
                <a href="31.html">
            
                    
                    2.12. 密度估计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.13" data-path="32.html">
            
                <a href="32.html">
            
                    
                    2.13. 神经网络模型（无监督）
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="33.html">
            
                <a href="33.html">
            
                    
                    3. 模型选择和评估
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.3.1" data-path="34.html">
            
                <a href="34.html">
            
                    
                    3.1. 交叉验证：评估估算器的表现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.2" data-path="35.html">
            
                <a href="35.html">
            
                    
                    3.2. 调整估计器的超参数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.3" data-path="53.md">
            
                <span>
            
                    
                    3.3. 模型评估: 量化预测的质量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.4" data-path="54.md">
            
                <span>
            
                    
                    3.4. 模型持久化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.5" data-path="55.md">
            
                <span>
            
                    
                    3.5. 验证曲线: 绘制分数以评估模型
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="56.html">
            
                <a href="56.html">
            
                    
                    4. 数据集转换
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.4.1" data-path="57.html">
            
                <a href="57.html">
            
                    
                    4.1. Pipeline（管道）和 FeatureUnion（特征联合）: 合并的评估器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.2" data-path="58.html">
            
                <a href="58.html">
            
                    
                    4.2. 特征提取
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.3" data-path="59.html">
            
                <a href="59.html">
            
                    
                    4.3. 预处理数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.4" data-path="60.html">
            
                <a href="60.html">
            
                    
                    4.4. 无监督降维
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.5" data-path="61.html">
            
                <a href="61.html">
            
                    
                    4.5. 随机投影
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.6" data-path="62.html">
            
                <a href="62.html">
            
                    
                    4.6. 内核近似
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.7" data-path="63.html">
            
                <a href="63.html">
            
                    
                    4.7. 成对的矩阵, 类别和核函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.8" data-path="64.html">
            
                <a href="64.html">
            
                    
                    4.8. 预测目标 (y.md) 的转换
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="65.html">
            
                <a href="65.html">
            
                    
                    5. 数据集加载工具
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="66.html">
            
                <a href="66.html">
            
                    
                    6. 大规模计算的策略: 更大量的数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="67.html">
            
                <a href="67.html">
            
                    
                    7. 计算性能
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    教程
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="68.html">
            
                <a href="68.html">
            
                    
                    使用 scikit-learn 介绍机器学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="69.html">
            
                <a href="69.html">
            
                    
                    关于科学数据处理的统计学习教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="70.html">
            
                <a href="70.html">
            
                    
                    机器学习: scikit-learn 中的设置以及预估对象
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="71.html">
            
                <a href="71.html">
            
                    
                    监督学习：从高维观察预测输出变量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="72.html">
            
                <a href="72.html">
            
                    
                    模型选择：选择估计量及其参数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="73.html">
            
                <a href="73.html">
            
                    
                    无监督学习: 寻求数据表示
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="74.html">
            
                <a href="74.html">
            
                    
                    把它们放在一起
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="75.html">
            
                <a href="75.html">
            
                    
                    寻求帮助
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.9" data-path="76.html">
            
                <a href="76.html">
            
                    
                    处理文本数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.10" data-path="77.html">
            
                <a href="77.html">
            
                    
                    选择正确的评估器(estimator.md)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.11" data-path="78.html">
            
                <a href="78.html">
            
                    
                    外部资源，视频和谈话
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <a target="_blank" href="https://scikit-learn.org/stable/modules/classes.html">
            
                    
                    API 参考
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="80.html">
            
                <a href="80.html">
            
                    
                    常见问题
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="81.html">
            
                <a href="81.html">
            
                    
                    时光轴
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >2.3. 聚类</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="23-&#x805A;&#x7C7B;">2.3. &#x805A;&#x7C7B;</h1>
<p>&#x6821;&#x9A8C;&#x8005;:
        <a href="https://github.com/apachecn/scikit-learn-doc-zh" target="_blank">@&#x82B1;&#x5F00;&#x65E0;&#x58F0;</a>
        <a href="https://github.com/apachecn/scikit-learn-doc-zh" target="_blank">@&#x5C0F;&#x7476;</a>
&#x7FFB;&#x8BD1;&#x8005;:
        <a href="https://github.com/apachecn/scikit-learn-doc-zh" target="_blank">@&#x5C0F;&#x7476;</a>
        <a href="https://github.com/apachecn/scikit-learn-doc-zh" target="_blank">@krokyin</a></p>
<p>&#x672A;&#x6807;&#x8BB0;&#x7684;&#x6570;&#x636E;&#x7684; <a href="https://en.wikipedia.org/wiki/Cluster_analysis" target="_blank">Clustering&#xFF08;&#x805A;&#x7C7B;&#xFF09;</a> &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6A21;&#x5757; <a href="classes.html#module-sklearn.cluster" title="sklearn.cluster"><code>sklearn.cluster</code></a> &#x6765;&#x5B9E;&#x73B0;&#x3002;</p>
<p>&#x6BCF;&#x4E2A; clustering algorithm &#xFF08;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF09;&#x6709;&#x4E24;&#x4E2A;&#x53D8;&#x4F53;: &#x4E00;&#x4E2A;&#x662F; class, &#x5B83;&#x5B9E;&#x73B0;&#x4E86; <code>fit</code> &#x65B9;&#x6CD5;&#x6765;&#x5B66;&#x4E60; train data&#xFF08;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#xFF09;&#x7684; clusters&#xFF08;&#x805A;&#x7C7B;&#xFF09;&#xFF0C;&#x8FD8;&#x6709;&#x4E00;&#x4E2A; function&#xFF08;&#x51FD;&#x6570;&#xFF09;&#xFF0C;&#x662F;&#x7ED9;&#x5B9A; train data&#xFF08;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#xFF09;&#xFF0C;&#x8FD4;&#x56DE;&#x4E0E;&#x4E0D;&#x540C; clusters&#xFF08;&#x805A;&#x7C7B;&#xFF09;&#x5BF9;&#x5E94;&#x7684;&#x6574;&#x6570;&#x6807;&#x7B7E; array&#xFF08;&#x6570;&#x7EC4;&#xFF09;&#x3002;&#x5BF9;&#x4E8E; class&#xFF08;&#x7C7B;&#xFF09;&#xFF0C;training data&#xFF08;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#xFF09;&#x4E0A;&#x7684;&#x6807;&#x7B7E;&#x53EF;&#x4EE5;&#x5728; <code>labels_</code> &#x5C5E;&#x6027;&#x4E2D;&#x627E;&#x5230;&#x3002;</p>
<p>&#x8F93;&#x5165;&#x6570;&#x636E;</p>
<p>&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x4E00;&#x70B9;&#x662F;&#xFF0C;&#x8BE5;&#x6A21;&#x5757;&#x4E2D;&#x5B9E;&#x73B0;&#x7684;&#x7B97;&#x6CD5;&#x53EF;&#x4EE5;&#x91C7;&#x7528;&#x4E0D;&#x540C;&#x79CD;&#x7C7B;&#x7684; matrix &#xFF08;&#x77E9;&#x9635;&#xFF09;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#x3002;&#x6240;&#x6709;&#x8FD9;&#x4E9B;&#x90FD;&#x63A5;&#x53D7; shape <code>[n_samples, n_features]</code> &#x7684;&#x6807;&#x51C6;&#x6570;&#x636E;&#x77E9;&#x9635;&#x3002; &#x8FD9;&#x4E9B;&#x53EF;&#x4EE5;&#x4ECE;&#x4EE5;&#x4E0B;&#x7684; <a href="classes.html#module-sklearn.feature_extraction" title="sklearn.feature_extraction"><code>sklearn.feature_extraction</code></a> &#x6A21;&#x5757;&#x7684; classes &#xFF08;&#x7C7B;&#xFF09;&#x4E2D;&#x83B7;&#x5F97;&#x3002;&#x5BF9;&#x4E8E; <a href="generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation" title="sklearn.cluster.AffinityPropagation"><code>AffinityPropagation</code></a>, <a href="generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" title="sklearn.cluster.SpectralClustering"><code>SpectralClustering</code></a> &#x548C; <a href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code>DBSCAN</code></a> &#x4E5F;&#x53EF;&#x4EE5;&#x8F93;&#x5165; shape <code>[n_samples, n_samples]</code> &#x7684;&#x76F8;&#x4F3C;&#x77E9;&#x9635;&#x3002;&#x8FD9;&#x4E9B;&#x53EF;&#x4EE5;&#x4ECE; <a href="classes.html#module-sklearn.metrics.pairwise" title="sklearn.metrics.pairwise"><code>sklearn.metrics.pairwise</code></a> &#x6A21;&#x5757;&#x4E2D;&#x7684;&#x51FD;&#x6570;&#x83B7;&#x5F97;&#x3002;</p>
<h2 id="231-&#x805A;&#x7C7B;&#x65B9;&#x6CD5;&#x6982;&#x8FF0;">2.3.1. &#x805A;&#x7C7B;&#x65B9;&#x6CD5;&#x6982;&#x8FF0;</h2>
<p><a href="../auto_examples/cluster/plot_cluster_comparison.html"><img src="img/153aceb3cdac953277c6c840339ac023.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_cluster_comparison_0011.png"></a></p>
<p>&#x5728; scikit-learn &#x4E2D;&#x7684; clustering algorithms &#xFF08;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF09;&#x7684;&#x6BD4;&#x8F83;</p>
<table>
<thead>
<tr>
<th>Method name&#xFF08;&#x65B9;&#x6CD5;&#x540D;&#x79F0;&#xFF09;</th>
<th>Parameters&#xFF08;&#x53C2;&#x6570;&#xFF09;</th>
<th>Scalability&#xFF08;&#x53EF;&#x6269;&#x5C55;&#x6027;&#xFF09;</th>
<th>Usecase&#xFF08;&#x4F7F;&#x7528;&#x573A;&#x666F;&#xFF09;</th>
<th>Geometry (metric used)&#xFF08;&#x51E0;&#x4F55;&#x56FE;&#x5F62;&#xFF08;&#x516C;&#x5236;&#x4F7F;&#x7528;&#xFF09;&#xFF09;</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#k-means">K-Means&#xFF08;K-&#x5747;&#x503C;&#xFF09;</a></td>
<td>number of clusters&#xFF08;&#x805A;&#x7C7B;&#x5F62;&#x6210;&#x7684;&#x7C07;&#x7684;&#x4E2A;&#x6570;&#xFF09;</td>
<td>&#x975E;&#x5E38;&#x5927;&#x7684; <code>n_samples</code>, &#x4E2D;&#x7B49;&#x7684; <code>n_clusters</code> &#x4F7F;&#x7528; <a href="#mini-batch-kmeans">MiniBatch code&#xFF08;MiniBatch &#x4EE3;&#x7801;&#xFF09;</a></td>
<td>&#x901A;&#x7528;, &#x5747;&#x5300;&#x7684; cluster size&#xFF08;&#x7C07;&#x5927;&#x5C0F;&#xFF09;, flat geometry&#xFF08;&#x5E73;&#x9762;&#x51E0;&#x4F55;&#xFF09;, &#x4E0D;&#x662F;&#x592A;&#x591A;&#x7684; clusters&#xFF08;&#x7C07;&#xFF09;</td>
<td>Distances between points&#xFF08;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#xFF09;</td>
</tr>
<tr>
<td><a href="#affinity-propagation">Affinity propagation</a></td>
<td>damping&#xFF08;&#x963B;&#x5C3C;&#xFF09;, sample preference&#xFF08;&#x6837;&#x672C;&#x504F;&#x597D;&#xFF09;</td>
<td>Not scalable with n_samples&#xFF08;n_samples &#x4E0D;&#x53EF;&#x6269;&#x5C55;&#xFF09;</td>
<td>Many clusters, uneven cluster size, non-flat geometry&#xFF08;&#x8BB8;&#x591A;&#x7C07;&#xFF0C;&#x4E0D;&#x5747;&#x5300;&#x7684;&#x7C07;&#x5927;&#x5C0F;&#xFF0C;&#x975E;&#x5E73;&#x9762;&#x51E0;&#x4F55;&#xFF09;</td>
<td>Graph distance (e.g. nearest-neighbor graph)&#xFF08;&#x56FE;&#x5F62;&#x8DDD;&#x79BB;&#xFF08;&#x4F8B;&#x5982;&#xFF0C;&#x6700;&#x8FD1;&#x90BB;&#x56FE;&#xFF09;&#xFF09;</td>
</tr>
<tr>
<td><a href="#mean-shift">Mean-shift</a></td>
<td>bandwidth&#xFF08;&#x5E26;&#x5BBD;&#xFF09;</td>
<td>Not scalable with <code>n_samples</code> &#xFF08;&#x4E0D;&#x53EF;&#x6269;&#x5C55;&#x7684; <code>n_samples</code>&#xFF09;</td>
<td>Many clusters, uneven cluster size, non-flat geometry&#xFF08;&#x8BB8;&#x591A;&#x7C07;&#xFF0C;&#x4E0D;&#x5747;&#x5300;&#x7684;&#x7C07;&#x5927;&#x5C0F;&#xFF0C;&#x975E;&#x5E73;&#x9762;&#x51E0;&#x4F55;&#xFF09;</td>
<td>Distances between points&#xFF08;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#xFF09;</td>
</tr>
<tr>
<td><a href="#spectral-clustering">Spectral clustering</a></td>
<td>number of clusters&#xFF08;&#x7C07;&#x7684;&#x4E2A;&#x6570;&#xFF09;</td>
<td>&#x4E2D;&#x7B49;&#x7684; <code>n_samples</code>, &#x5C0F;&#x7684; <code>n_clusters</code></td>
<td>Few clusters, even cluster size, non-flat geometry&#xFF08;&#x51E0;&#x4E2A;&#x7C07;&#xFF0C;&#x5747;&#x5300;&#x7684;&#x7C07;&#x5927;&#x5C0F;&#xFF0C;&#x975E;&#x5E73;&#x9762;&#x51E0;&#x4F55;&#xFF09;</td>
<td>Graph distance (e.g. nearest-neighbor graph)&#xFF08;&#x56FE;&#x5F62;&#x8DDD;&#x79BB;&#xFF08;&#x4F8B;&#x5982;&#x6700;&#x8FD1;&#x90BB;&#x56FE;&#xFF09;&#xFF09;</td>
</tr>
<tr>
<td><a href="#hierarchical-clustering">Ward hierarchical clustering</a></td>
<td>number of clusters&#xFF08;&#x7C07;&#x7684;&#x4E2A;&#x6570;&#xFF09;</td>
<td>&#x5927;&#x7684; <code>n_samples</code> &#x548C; <code>n_clusters</code></td>
<td>Many clusters, possibly connectivity constraints&#xFF08;&#x5F88;&#x591A;&#x7684;&#x7C07;&#xFF0C;&#x53EF;&#x80FD;&#x8FDE;&#x63A5;&#x9650;&#x5236;&#xFF09;</td>
<td>Distances between points&#xFF08;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#xFF09;</td>
</tr>
<tr>
<td><a href="#hierarchical-clustering">Agglomerative clustering</a></td>
<td>number of clusters&#xFF08;&#x7C07;&#x7684;&#x4E2A;&#x6570;&#xFF09;, linkage type&#xFF08;&#x94FE;&#x63A5;&#x7C7B;&#x578B;&#xFF09;, distance&#xFF08;&#x8DDD;&#x79BB;&#xFF09;</td>
<td>&#x5927;&#x7684; <code>n_samples</code> &#x548C; <code>n_clusters</code></td>
<td>Many clusters, possibly connectivity constraints, non Euclidean distances&#xFF08;&#x5F88;&#x591A;&#x7C07;&#xFF0C;&#x53EF;&#x80FD;&#x8FDE;&#x63A5;&#x9650;&#x5236;&#xFF0C;&#x975E;&#x6B27;&#x51E0;&#x91CC;&#x5F97;&#x8DDD;&#x79BB;&#xFF09;</td>
<td>Any pairwise distance&#xFF08;&#x4EFB;&#x610F;&#x6210;&#x5BF9;&#x8DDD;&#x79BB;&#xFF09;</td>
</tr>
<tr>
<td><a href="#dbscan">DBSCAN</a></td>
<td>neighborhood size&#xFF08;neighborhood &#x7684;&#x5927;&#x5C0F;&#xFF09;</td>
<td>&#x975E;&#x5E38;&#x5927;&#x7684; <code>n_samples</code>, &#x4E2D;&#x7B49;&#x7684; <code>n_clusters</code></td>
<td>Non-flat geometry, uneven cluster sizes&#xFF08;&#x975E;&#x5E73;&#x9762;&#x51E0;&#x4F55;&#xFF0C;&#x4E0D;&#x5747;&#x5300;&#x7684;&#x7C07;&#x5927;&#x5C0F;&#xFF09;</td>
<td>Distances between nearest points&#xFF08;&#x6700;&#x8FD1;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#xFF09;</td>
</tr>
<tr>
<td><a href="mixture.html#mixture">Gaussian mixtures&#xFF08;&#x9AD8;&#x65AF;&#x6DF7;&#x5408;&#xFF09;</a></td>
<td>many&#xFF08;&#x5F88;&#x591A;&#xFF09;</td>
<td>Not scalable&#xFF08;&#x4E0D;&#x53EF;&#x6269;&#x5C55;&#xFF09;</td>
<td>Flat geometry, good for density estimation&#xFF08;&#x5E73;&#x9762;&#x51E0;&#x4F55;&#xFF0C;&#x9002;&#x7528;&#x4E8E;&#x5BC6;&#x5EA6;&#x4F30;&#x8BA1;&#xFF09;</td>
<td>Mahalanobis distances to centers&#xFF08;Mahalanobis &#x4E0E;&#x4E2D;&#x5FC3;&#x7684;&#x8DDD;&#x79BB;&#xFF09;</td>
</tr>
<tr>
<td><a href="#birch">Birch</a></td>
<td>branching factor&#xFF08;&#x5206;&#x652F;&#x56E0;&#x5B50;&#xFF09;, threshold&#xFF08;&#x9608;&#x503C;&#xFF09;, optional global clusterer&#xFF08;&#x53EF;&#x9009;&#x5168;&#x5C40;&#x7C07;&#xFF09;.</td>
<td>&#x5927;&#x7684; <code>n_clusters</code> &#x548C; <code>n_samples</code></td>
<td>Large dataset, outlier removal, data reduction.&#xFF08;&#x5927;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x5F02;&#x5E38;&#x503C;&#x53BB;&#x9664;&#xFF0C;&#x6570;&#x636E;&#x7B80;&#x5316;&#xFF09;</td>
<td>Euclidean distance between points&#xFF08;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x6B27;&#x5F0F;&#x8DDD;&#x79BB;&#xFF09;</td>
</tr>
</tbody>
</table>
<p>&#x5F53; clusters &#xFF08;&#x7C07;&#xFF09;&#x5177;&#x6709; specific shape &#xFF08;&#x7279;&#x6B8A;&#x7684;&#x5F62;&#x72B6;&#xFF09;&#xFF0C;&#x5373; non-flat manifold&#xFF08;&#x975E;&#x5E73;&#x9762; manifold&#xFF09;&#xFF0C;&#x5E76;&#x4E14;&#x6807;&#x51C6;&#x6B27;&#x51E0;&#x91CC;&#x5F97;&#x8DDD;&#x79BB;&#x4E0D;&#x662F;&#x6B63;&#x786E;&#x7684; metric &#xFF08;&#x5EA6;&#x91CF;&#x6807;&#x51C6;&#xFF09;&#x65F6;&#xFF0C;Non-flat geometry clustering &#xFF08;&#x975E;&#x5E73;&#x9762;&#x51E0;&#x4F55;&#x805A;&#x7C7B;&#xFF09;&#x662F;&#x975E;&#x5E38;&#x6709;&#x7528;&#x7684;&#x3002;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x51FA;&#x73B0;&#x5728;&#x4E0A;&#x56FE;&#x7684;&#x4E24;&#x4E2A;&#x9876;&#x884C;&#x4E2D;&#x3002;</p>
<p>&#x7528;&#x4E8E; clustering &#xFF08;&#x805A;&#x7C7B;&#xFF09;&#x7684; Gaussian mixture models &#xFF08;&#x9AD8;&#x65AF;&#x6DF7;&#x5408;&#x6A21;&#x578B;&#xFF09;&#xFF0C;&#x4E13;&#x7528;&#x4E8E; mixture models &#xFF08;&#x6DF7;&#x5408;&#x6A21;&#x578B;&#xFF09;&#x63CF;&#x8FF0;&#x5728; <a href="mixture.html#mixture">&#x6587;&#x6863;&#x7684;&#x53E6;&#x4E00;&#x7AE0;&#x8282;</a> &#x3002;&#x53EF;&#x4EE5;&#x5C06; KMeans &#x89C6;&#x4E3A;&#x5177;&#x6709; equal covariance per component &#xFF08;&#x6BCF;&#x4E2A;&#x5206;&#x91CF;&#x76F8;&#x7B49;&#x534F;&#x65B9;&#x5DEE;&#xFF09;&#x7684; Gaussian mixture model &#xFF08;&#x9AD8;&#x65AF;&#x6DF7;&#x5408;&#x6A21;&#x578B;&#xFF09;&#x7684;&#x7279;&#x6B8A;&#x60C5;&#x51B5;&#x3002;</p>
<h2 id="232-k-means">2.3.2. K-means</h2>
<p><a href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code>KMeans</code></a> &#x7B97;&#x6CD5;&#x901A;&#x8FC7;&#x8BD5;&#x56FE;&#x5206;&#x79BB; n groups of equal variance&#xFF08;n &#x4E2A;&#x76F8;&#x7B49;&#x65B9;&#x5DEE;&#x7EC4;&#xFF09;&#x7684;&#x6837;&#x672C;&#x6765;&#x805A;&#x96C6;&#x6570;&#x636E;&#xFF0C;minimizing &#xFF08;&#x6700;&#x5C0F;&#x5316;&#xFF09;&#x79F0;&#x4E3A; <a href="inertia">inertia</a> &#x6216;&#x8005; within-cluster sum-of-squares &#xFF08;&#x7C07;&#x5185;&#x548C;&#x5E73;&#x65B9;&#xFF09;&#x7684; criterion &#xFF08;&#x6807;&#x51C6;&#xFF09;&#x3002; &#x8BE5;&#x7B97;&#x6CD5;&#x9700;&#x8981;&#x6307;&#x5B9A; number of clusters &#xFF08;&#x7C07;&#x7684;&#x6570;&#x91CF;&#xFF09;&#x3002;&#x5B83;&#x53EF;&#x4EE5;&#x5F88;&#x597D;&#x5730; scales &#xFF08;&#x6269;&#x5C55;&#xFF09;&#x5230; large number of samples&#xFF08;&#x5927;&#x91CF;&#x6837;&#x672C;&#xFF09;&#xFF0C;&#x5E76;&#x5DF2;&#x7ECF;&#x88AB;&#x5E7F;&#x6CDB;&#x5E94;&#x7528;&#x4E8E;&#x8BB8;&#x591A;&#x4E0D;&#x540C;&#x9886;&#x57DF;&#x7684;&#x5E94;&#x7528;&#x9886;&#x57DF;&#x3002;</p>
<p>k-means &#x7B97;&#x6CD5;&#x5C06;&#x4E00;&#x7EC4; <img src="img/a44a7c045f2217894a894c482861387a.jpg" alt="N"> &#x6837;&#x672C; <img src="img/43c1fea57579e54f80c0535bc582626f.jpg" alt="X"> &#x5212;&#x5206;&#x6210; <img src="img/e279b8169ddd6581c5606c868ba52fae.jpg" alt="K"> &#x4E0D;&#x76F8;&#x4EA4;&#x7684; clusters &#xFF08;&#x7C07;&#xFF09; <img src="img/4b6d782a67ac392e97215c46b7590bf7.jpg" alt="C">, &#x6BCF;&#x4E2A;&#x90FD;&#x7528; cluster &#xFF08;&#x8BE5;&#x7C07;&#xFF09;&#x4E2D;&#x7684;&#x6837;&#x672C;&#x7684;&#x5747;&#x503C; <img src="img/38320089278fc639e640f3f772eac6b1.jpg" alt="\mu_j"> &#x63CF;&#x8FF0;&#x3002; &#x8FD9;&#x4E2A; means &#xFF08;&#x5747;&#x503C;&#xFF09;&#x901A;&#x5E38;&#x88AB;&#x79F0;&#x4E3A; cluster&#xFF08;&#x7C07;&#xFF09;&#x7684; &#x201C;centroids&#xFF08;&#x8D28;&#x5FC3;&#xFF09;&#x201D;; &#x6CE8;&#x610F;&#xFF0C;&#x5B83;&#x4EEC;&#x4E00;&#x822C;&#x4E0D;&#x662F;&#x4ECE; <img src="img/43c1fea57579e54f80c0535bc582626f.jpg" alt="X"> &#x4E2D;&#x6311;&#x9009;&#x51FA;&#x7684;&#x70B9;&#xFF0C;&#x867D;&#x7136;&#x5B83;&#x4EEC;&#x662F;&#x5904;&#x5728;&#x540C;&#x4E00;&#x4E2A; space&#xFF08;&#x7A7A;&#x95F4;&#xFF09;&#x3002; K-means&#xFF08;K-&#x5747;&#x503C;&#xFF09;&#x7B97;&#x6CD5;&#x65E8;&#x5728;&#x9009;&#x62E9;&#x6700;&#x5C0F;&#x5316; <em>inertia&#xFF08;&#x60EF;&#x6027;&#xFF09;</em> &#x6216; within-cluster sum of squared&#xFF08;&#x7C07;&#x5185;&#x548C;&#x7684;&#x5E73;&#x65B9;&#x548C;&#xFF09;&#x7684;&#x6807;&#x51C6;&#x7684; centroids&#xFF08;&#x8D28;&#x5FC3;&#xFF09;:</p>
<p><img src="img/c46633c42aaa3e030b14d90aadb323fc.jpg" alt="\sum_{i=0}^{n}\min_{\mu_j \in C}(||x_j - \mu_i||^2)"></p>
<p>Inertia&#xFF08;&#x60EF;&#x6027;&#xFF09;, &#x6216; the within-cluster sum of squares&#xFF08;&#x7C07;&#x5185;&#x548C;&#x5E73;&#x65B9;&#x5DEE;&#xFF09; criterion&#xFF08;&#x6807;&#x51C6;&#xFF09;,&#x53EF;&#x4EE5;&#x88AB;&#x8BA4;&#x4E3A;&#x662F; internally coherent clusters &#xFF08;&#x5185;&#x90E8;&#x60F3;&#x5E72;&#x805A;&#x7C7B;&#xFF09;&#x7684; measure &#xFF08;&#x5EA6;&#x91CF;&#xFF09;&#x3002; &#x5B83;&#x6709;&#x5404;&#x79CD;&#x7F3A;&#x70B9;:</p>
<ul>
<li>Inertia&#xFF08;&#x60EF;&#x6027;&#xFF09;&#x5047;&#x8BBE; clusters &#xFF08;&#x7C07;&#xFF09;&#x662F; convex&#xFF08;&#x51F8;&#xFF09;&#x7684;&#x548C; isotropic &#xFF08;&#x5404;&#x9879;&#x540C;&#x6027;&#xFF09;&#xFF0C;&#x8FD9;&#x5E76;&#x4E0D;&#x662F;&#x603B;&#x662F;&#x8FD9;&#x6837;&#x3002;&#x5B83;&#x5BF9; elongated clusters &#xFF08;&#x7EC6;&#x957F;&#x7684;&#x7C07;&#xFF09;&#x6216;&#x5177;&#x6709;&#x4E0D;&#x89C4;&#x5219;&#x5F62;&#x72B6;&#x7684; manifolds &#x53CD;&#x5E94;&#x4E0D;&#x4F73;&#x3002;</li>
<li>Inertia&#xFF08;&#x60EF;&#x6027;&#xFF09;&#x4E0D;&#x662F;&#x4E00;&#x4E2A; normalized metric&#xFF08;&#x5F52;&#x4E00;&#x5316;&#x5EA6;&#x91CF;&#xFF09;: &#x6211;&#x4EEC;&#x53EA;&#x77E5;&#x9053; lower values &#xFF08;&#x8F83;&#x4F4E;&#x7684;&#x503C;&#xFF09;&#x662F;&#x66F4;&#x597D;&#x7684;&#xFF0C;&#x5E76;&#x4E14; &#x96F6; &#x662F;&#x6700;&#x4F18;&#x7684;&#x3002;&#x4F46;&#x662F;&#x5728; very high-dimensional spaces &#xFF08;&#x975E;&#x5E38;&#x9AD8;&#x7EF4;&#x7684;&#x7A7A;&#x95F4;&#xFF09;&#x4E2D;&#xFF0C;&#x6B27;&#x51E0;&#x91CC;&#x5F97;&#x8DDD;&#x79BB;&#x5F80;&#x5F80;&#x4F1A;&#x53D8;&#x5F97; inflated &#xFF08;&#x81A8;&#x80C0;&#xFF09;&#xFF08;&#x8FD9;&#x5C31;&#x662F;&#x6240;&#x8C13;&#x7684; &#x201C;curse of dimensionality &#xFF08;&#x7EF4;&#x5EA6;&#x8BC5;&#x5492;/&#x7EF4;&#x5EA6;&#x60E9;&#x7F5A;&#xFF09;&#x201D;&#xFF09;&#x3002;&#x5728; k-means &#x805A;&#x7C7B;&#x4E4B;&#x524D;&#x8FD0;&#x884C;&#x8BF8;&#x5982; <a href="PCA">PCA</a> &#x4E4B;&#x7C7B;&#x7684; dimensionality reduction algorithm &#xFF08;&#x964D;&#x7EF4;&#x7B97;&#x6CD5;&#xFF09;&#x53EF;&#x4EE5;&#x51CF;&#x8F7B;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x5E76;&#x52A0;&#x5FEB;&#x8BA1;&#x7B97;&#x901F;&#x5EA6;&#x3002;</li>
</ul>
<p><a href="../auto_examples/cluster/plot_kmeans_assumptions.html"><img src="img/d97ae32100e54dfed8139aef0fcc9b68.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_kmeans_assumptions_0011.png"></a></p>
<p>K-means &#x901A;&#x5E38;&#x88AB;&#x79F0;&#x4E3A; Lloyd&#x2019;s algorithm&#xFF08;&#x52B3;&#x57C3;&#x5FB7;&#x7B97;&#x6CD5;&#xFF09;&#x3002;&#x5728;&#x57FA;&#x672C;&#x672F;&#x8BED;&#x4E2D;&#xFF0C;&#x7B97;&#x6CD5;&#x6709;&#x4E09;&#x4E2A;&#x6B65;&#x9AA4;&#x3002;&#x3001; &#x7B2C;&#x4E00;&#x6B65;&#x662F;&#x9009;&#x62E9; initial centroids &#xFF08;&#x521D;&#x59CB;&#x8D28;&#x5FC3;&#xFF09;&#xFF0C;&#x6700;&#x57FA;&#x672C;&#x7684;&#x65B9;&#x6CD5;&#x662F;&#x4ECE; <img src="img/43c1fea57579e54f80c0535bc582626f.jpg" alt="X"> &#x6570;&#x636E;&#x96C6;&#x4E2D;&#x9009;&#x62E9; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x4E2A;&#x6837;&#x672C;&#x3002;&#x521D;&#x59CB;&#x5316;&#x5B8C;&#x6210;&#x540E;&#xFF0C;K-means &#x7531;&#x4E24;&#x4E2A;&#x5176;&#x4ED6;&#x6B65;&#x9AA4;&#x4E4B;&#x95F4;&#x7684;&#x5FAA;&#x73AF;&#x7EC4;&#x6210;&#x3002; &#x7B2C;&#x4E00;&#x6B65;&#x5C06;&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#x5206;&#x914D;&#x5230;&#x5176; nearest centroid &#xFF08;&#x6700;&#x8FD1;&#x7684;&#x8D28;&#x5FC3;&#xFF09;&#x3002;&#x7B2C;&#x4E8C;&#x6B65;&#x901A;&#x8FC7;&#x53D6;&#x5206;&#x914D;&#x7ED9;&#x6BCF;&#x4E2A;&#x5148;&#x524D;&#x8D28;&#x5FC3;&#x7684;&#x6240;&#x6709;&#x6837;&#x672C;&#x7684;&#x5E73;&#x5747;&#x503C;&#x6765;&#x521B;&#x5EFA;&#x65B0;&#x7684;&#x8D28;&#x5FC3;&#x3002;&#x8BA1;&#x7B97;&#x65E7;&#x7684;&#x548C;&#x65B0;&#x7684;&#x8D28;&#x5FC3;&#x4E4B;&#x95F4;&#x7684;&#x5DEE;&#x5F02;&#xFF0C;&#x5E76;&#x4E14;&#x7B97;&#x6CD5;&#x91CD;&#x590D;&#x8FD9;&#x4E9B;&#x6700;&#x540E;&#x7684;&#x4E24;&#x4E2A;&#x6B65;&#x9AA4;&#xFF0C;&#x76F4;&#x5230;&#x8BE5;&#x503C;&#x5C0F;&#x4E8E;&#x9608;&#x503C;&#x3002;&#x6362;&#x53E5;&#x8BDD;&#x8BF4;&#xFF0C;&#x7B97;&#x6CD5;&#x91CD;&#x590D;&#x8FD9;&#x4E2A;&#x6B65;&#x9AA4;&#xFF0C;&#x76F4;&#x5230;&#x8D28;&#x5FC3;&#x4E0D;&#x518D;&#x663E;&#x8457;&#x79FB;&#x52A8;&#x3002;</p>
<p><a href="../auto_examples/cluster/plot_kmeans_digits.html"><img src="img/8a76c85f2de3d3777fe72f5d8e32e0cf.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_kmeans_digits_0011.png"></a></p>
<p>K-means &#x76F8;&#x5F53;&#x4E8E;&#x5177;&#x6709; small, all-equal, diagonal covariance matrix &#xFF08;&#x5C0F;&#x7684;&#x5168;&#x5BF9;&#x79F0;&#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;&#xFF09;&#x7684; expectation-maximization algorithm &#xFF08;&#x671F;&#x671B;&#x6700;&#x5927;&#x5316;&#x7B97;&#x6CD5;&#xFF09;&#x3002;</p>
<p>&#x8BE5;&#x7B97;&#x6CD5;&#x4E5F;&#x53EF;&#x4EE5;&#x901A;&#x8FC7; <a href="#id42"><code>Voronoi diagrams&#xFF08;Voronoi&#x56FE;&#xFF09;&amp;lt;https://en.wikipedia.org/wiki/Voronoi_diagram&amp;gt;</code>_</a> &#x7684;&#x6982;&#x5FF5;&#x6765;&#x7406;&#x89E3;&#x3002;&#x9996;&#x5148;&#x4F7F;&#x7528; current centroids &#xFF08;&#x5F53;&#x524D;&#x8D28;&#x5FC3;&#xFF09;&#x8BA1;&#x7B97;&#x70B9;&#x7684; Voronoi &#x56FE;&#x3002; Voronoi &#x56FE;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A; segment &#xFF08;&#x6BB5;&#xFF09;&#x90FD;&#x6210;&#x4E3A;&#x4E00;&#x4E2A; separate cluster &#xFF08;&#x5355;&#x72EC;&#x7684;&#x7C07;&#xFF09;&#x3002;&#x5176;&#x6B21;&#xFF0C;centroids&#xFF08;&#x8D28;&#x5FC3;&#xFF09;&#x88AB;&#x66F4;&#x65B0;&#x4E3A;&#x6BCF;&#x4E2A; segment &#xFF08;&#x6BB5;&#xFF09;&#x7684; mean&#xFF08;&#x5E73;&#x5747;&#x503C;&#xFF09;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x8BE5;&#x7B97;&#x6CD5;&#x91CD;&#x590D;&#x6B64;&#x64CD;&#x4F5C;&#xFF0C;&#x76F4;&#x5230;&#x6EE1;&#x8DB3;&#x505C;&#x6B62;&#x6761;&#x4EF6;&#x3002; &#x901A;&#x5E38;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x5F53; iterations &#xFF08;&#x8FED;&#x4EE3;&#xFF09;&#x4E4B;&#x95F4;&#x7684; objective function &#xFF08;&#x76EE;&#x6807;&#x51FD;&#x6570;&#xFF09;&#x7684;&#x76F8;&#x5BF9;&#x51CF;&#x5C0F;&#x5C0F;&#x4E8E;&#x7ED9;&#x5B9A;&#x7684; tolerance value &#xFF08;&#x516C;&#x5DEE;&#x503C;&#xFF09;&#x65F6;&#xFF0C;&#x7B97;&#x6CD5;&#x505C;&#x6B62;&#x3002;&#x5728;&#x6B64;&#x5B9E;&#x73B0;&#x4E2D;&#x4E0D;&#x662F;&#x8FD9;&#x6837;: &#x5F53;&#x8D28;&#x5FC3;&#x79FB;&#x52A8;&#x5C0F;&#x4E8E; tolerance &#xFF08;&#x516C;&#x5DEE;&#xFF09;&#x65F6;&#xFF0C;&#x8FED;&#x4EE3;&#x505C;&#x6B62;&#x3002;</p>
<p>&#x7ED9;&#x5B9A;&#x8DB3;&#x591F;&#x7684;&#x65F6;&#x95F4;&#xFF0C;K-means &#x5C06;&#x603B;&#x662F;&#x6536;&#x655B;&#x7684;&#xFF0C;&#x4F46;&#x8FD9;&#x53EF;&#x80FD;&#x662F; local minimum &#xFF08;&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#xFF09;&#x7684;&#x3002;&#x8FD9;&#x5F88;&#x5927;&#x7A0B;&#x5EA6;&#x4E0A;&#x53D6;&#x51B3;&#x4E8E; initialization of the centroids &#xFF08;&#x8D28;&#x5FC3;&#x7684;&#x521D;&#x59CB;&#x5316;&#xFF09;&#x3002; &#x56E0;&#x6B64;&#xFF0C;&#x901A;&#x5E38;&#x4F1A;&#x8FDB;&#x884C;&#x51E0;&#x6B21; different initializations of the centroids &#xFF08;&#x521D;&#x59CB;&#x5316;&#x4E0D;&#x540C;&#x8D28;&#x5FC3;&#xFF09;&#x7684;&#x8BA1;&#x7B97;&#x3002;&#x5E2E;&#x52A9;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x7684;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#x662F; k-means++ &#x521D;&#x59CB;&#x5316;&#x65B9;&#x6848;&#xFF0C;&#x5B83;&#x5DF2;&#x7ECF;&#x5728; scikit-learn &#x4E2D;&#x5B9E;&#x73B0;&#xFF08;&#x4F7F;&#x7528; <code>init=&apos;k-means++&apos;</code> &#x53C2;&#x6570;&#xFF09;&#x3002; &#x8FD9;&#x5C06;&#x521D;&#x59CB;&#x5316; centroids &#xFF08;&#x8D28;&#x5FC3;&#xFF09;&#xFF08;&#x901A;&#x5E38;&#xFF09;&#x5F7C;&#x6B64;&#x8FDC;&#x79BB;&#xFF0C;&#x5BFC;&#x81F4;&#x6BD4;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x66F4;&#x597D;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x5982;&#x53C2;&#x8003;&#x6587;&#x732E;&#x6240;&#x793A;&#x3002;</p>
<p>&#x53EF;&#x4EE5;&#x7ED9;&#x51FA;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#xFF0C;&#x4EE5;&#x5141;&#x8BB8; K-means &#x5E76;&#x884C;&#x8FD0;&#x884C;&#xFF0C;&#x79F0;&#x4E3A; <code>n_jobs</code>&#x3002;&#x7ED9;&#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#x4E00;&#x4E2A;&#x6B63;&#x503C;&#x4F7F;&#x7528;&#x8BB8;&#x591A;&#x5904;&#x7406;&#x5668;&#xFF08;&#x9ED8;&#x8BA4;&#x503C;: 1&#xFF09;&#x3002;&#x503C; -1 &#x4F7F;&#x7528;&#x6240;&#x6709;&#x53EF;&#x7528;&#x7684;&#x5904;&#x7406;&#x5668;&#xFF0C;-2 &#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#xFF0C;&#x7B49;&#x7B49;&#x3002;Parallelization &#xFF08;&#x5E76;&#x884C;&#x5316;&#xFF09;&#x901A;&#x5E38;&#x4EE5; cost of memory&#xFF08;&#x5185;&#x5B58;&#x7684;&#x4EE3;&#x4EF7;&#xFF09;&#x52A0;&#x901F;&#x8BA1;&#x7B97;&#xFF08;&#x5728;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x9700;&#x8981;&#x5B58;&#x50A8;&#x591A;&#x4E2A;&#x8D28;&#x5FC3;&#x526F;&#x672C;&#xFF0C;&#x6BCF;&#x4E2A;&#x4F5C;&#x4E1A;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#xFF09;&#x3002;</p>
<p>Warning</p>
<p>&#x5F53; &lt;cite&gt;numpy&lt;/cite&gt; &#x4F7F;&#x7528; &lt;cite&gt;Accelerate&lt;/cite&gt; &#x6846;&#x67B6;&#x65F6;&#xFF0C;K-Means &#x7684;&#x5E76;&#x884C;&#x7248;&#x672C;&#x5728; OS X &#x4E0A;&#x635F;&#x574F;&#x3002;&#x8FD9;&#x662F; expected behavior &#xFF08;&#x9884;&#x671F;&#x7684;&#x884C;&#x4E3A;&#xFF09;: &lt;cite&gt;Accelerate&lt;/cite&gt; &#x53EF;&#x4EE5;&#x5728; fork &#x4E4B;&#x540E;&#x8C03;&#x7528;&#xFF0C;&#x4F46;&#x662F;&#x60A8;&#x9700;&#x8981;&#x4F7F;&#x7528; Python binary&#xFF08;&#x4E8C;&#x8FDB;&#x5236;&#xFF09;&#xFF08;&#x8BE5;&#x591A;&#x8FDB;&#x7A0B;&#x5728; posix &#x4E0B;&#x4E0D;&#x6267;&#x884C;&#xFF09;&#x6765;&#x6267;&#x884C;&#x5B50;&#x8FDB;&#x7A0B;&#x3002;</p>
<p>K-means &#x53EF;&#x7528;&#x4E8E; vector quantization &#xFF08;&#x77E2;&#x91CF;&#x91CF;&#x5316;&#xFF09;&#x3002;&#x8FD9;&#x662F;&#x4F7F;&#x7528;&#x4EE5;&#x4E0B;&#x7C7B;&#x578B;&#x7684; trained model &#xFF08;&#x8BAD;&#x7EC3;&#x6A21;&#x578B;&#xFF09;&#x7684;&#x53D8;&#x6362;&#x65B9;&#x6CD5;&#x5B9E;&#x73B0;&#x7684; <a href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code>KMeans</code></a> &#x3002;</p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py">Demonstration of k-means assumptions</a>: &#x6F14;&#x793A; k-means &#x662F;&#x5426; performs intuitively &#xFF08;&#x76F4;&#x89C2;&#x6267;&#x884C;&#xFF09;&#xFF0C;&#x4F55;&#x65F6;&#x4E0D;&#x6267;&#x884C;</li>
<li><a href="../auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py">A demo of K-Means clustering on the handwritten digits data</a>: &#x805A;&#x7C7B;&#x624B;&#x5199;&#x6570;&#x5B57;</li>
</ul>
<p>&#x53C2;&#x8003;:</p>
<ul>
<li><a href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf" target="_blank">&#x201C;k-means++: The advantages of careful seeding&#x201D;</a> Arthur, David, and Sergei Vassilvitskii, <em>Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms</em>, Society for Industrial and Applied Mathematics (2007)</li>
</ul>
<h3 id="2321-&#x5C0F;&#x6279;&#x91CF;-k-means">2.3.2.1. &#x5C0F;&#x6279;&#x91CF; K-Means</h3>
<p><a href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><code>MiniBatchKMeans</code></a> &#x662F; <a href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code>KMeans</code></a> &#x7B97;&#x6CD5;&#x7684;&#x4E00;&#x4E2A;&#x53D8;&#x4F53;&#xFF0C;&#x5B83;&#x4F7F;&#x7528; mini-batches &#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x6765;&#x51CF;&#x5C11;&#x8BA1;&#x7B97;&#x65F6;&#x95F4;&#xFF0C;&#x540C;&#x65F6;&#x4ECD;&#x7136;&#x5C1D;&#x8BD5;&#x4F18;&#x5316;&#x76F8;&#x540C;&#x7684; objective function &#xFF08;&#x76EE;&#x6807;&#x51FD;&#x6570;&#xFF09;&#x3002; Mini-batches&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x662F;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x5B50;&#x96C6;&#xFF0C;&#x5728;&#x6BCF;&#x6B21; training iteration &#xFF08;&#x8BAD;&#x7EC3;&#x8FED;&#x4EE3;&#xFF09;&#x4E2D; randomly sampled &#xFF08;&#x968F;&#x673A;&#x62BD;&#x6837;&#xFF09;&#x3002;&#x8FD9;&#x4E9B;&#x5C0F;&#x6279;&#x91CF;&#x5927;&#x5927;&#x51CF;&#x5C11;&#x4E86;&#x878D;&#x5408;&#x5230;&#x672C;&#x5730;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x6240;&#x9700;&#x7684;&#x8BA1;&#x7B97;&#x91CF;&#x3002; &#x4E0E;&#x5176;&#x4ED6;&#x964D;&#x4F4E; k-means &#x6536;&#x655B;&#x65F6;&#x95F4;&#x7684;&#x7B97;&#x6CD5;&#x76F8;&#x53CD;&#xFF0C;mini-batch k-means &#x4EA7;&#x751F;&#x7684;&#x7ED3;&#x679C;&#x901A;&#x5E38;&#x53EA;&#x6BD4;&#x6807;&#x51C6;&#x7B97;&#x6CD5;&#x7565;&#x5DEE;&#x3002;</p>
<p>&#x8BE5;&#x7B97;&#x6CD5;&#x5728;&#x4E24;&#x4E2A;&#x4E3B;&#x8981;&#x6B65;&#x9AA4;&#x4E4B;&#x95F4;&#x8FDB;&#x884C;&#x8FED;&#x4EE3;&#xFF0C;&#x7C7B;&#x4F3C;&#x4E8E; vanilla k-means &#x3002; &#x5728;&#x7B2C;&#x4E00;&#x6B65;&#xFF0C; <img src="img/6ae91fb0f3221b92d2dd4e22204d8008.jpg" alt="b"> &#x6837;&#x672C;&#x662F;&#x4ECE;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x968F;&#x673A;&#x62BD;&#x53D6;&#x7684;&#xFF0C;&#x5F62;&#x6210;&#x4E00;&#x4E2A; mini-batch &#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x3002;&#x7136;&#x540E;&#x5C06;&#x5B83;&#x4EEC;&#x5206;&#x914D;&#x5230;&#x6700;&#x8FD1;&#x7684; centroid&#xFF08;&#x8D28;&#x5FC3;&#xFF09;&#x3002; &#x5728;&#x7B2C;&#x4E8C;&#x6B65;&#xFF0C;centroids &#xFF08;&#x8D28;&#x5FC3;&#xFF09;&#x88AB;&#x66F4;&#x65B0;&#x3002;&#x4E0E; k-means &#x76F8;&#x53CD;&#xFF0C;&#x8FD9;&#x662F;&#x5728;&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#x7684;&#x57FA;&#x7840;&#x4E0A;&#x5B8C;&#x6210;&#x7684;&#x3002;&#x5BF9;&#x4E8E; mini-batch &#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#xFF0C;&#x901A;&#x8FC7;&#x53D6;&#x6837;&#x672C;&#x7684; streaming average &#xFF08;&#x6D41;&#x5E73;&#x5747;&#x503C;&#xFF09;&#x548C;&#x5206;&#x914D;&#x7ED9;&#x8BE5;&#x8D28;&#x5FC3;&#x7684;&#x6240;&#x6709;&#x5148;&#x524D;&#x6837;&#x672C;&#x6765;&#x66F4;&#x65B0;&#x5206;&#x914D;&#x7684;&#x8D28;&#x5FC3;&#x3002; &#x8FD9;&#x5177;&#x6709;&#x968F;&#x65F6;&#x95F4;&#x964D;&#x4F4E; centroid &#xFF08;&#x8D28;&#x5FC3;&#xFF09;&#x7684; rate &#xFF08;&#x53D8;&#x5316;&#x7387;&#xFF09;&#x7684;&#x6548;&#x679C;&#x3002;&#x6267;&#x884C;&#x8FD9;&#x4E9B;&#x6B65;&#x9AA4;&#x76F4;&#x5230;&#x8FBE;&#x5230;&#x6536;&#x655B;&#x6216;&#x8FBE;&#x5230;&#x9884;&#x5B9A;&#x6B21;&#x6570;&#x7684;&#x8FED;&#x4EE3;&#x3002;</p>
<p><a href="generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" title="sklearn.cluster.MiniBatchKMeans"><code>MiniBatchKMeans</code></a> &#x6536;&#x655B;&#x901F;&#x5EA6;&#x6BD4; <a href="generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="sklearn.cluster.KMeans"><code>KMeans</code></a> &#xFF0C;&#x4F46;&#x662F;&#x7ED3;&#x679C;&#x7684;&#x8D28;&#x91CF;&#x4F1A;&#x964D;&#x4F4E;&#x3002;&#x5728;&#x5B9E;&#x8DF5;&#x4E2D;&#xFF0C;&#x8D28;&#x91CF;&#x5DEE;&#x5F02;&#x53EF;&#x80FD;&#x76F8;&#x5F53;&#x5C0F;&#xFF0C;&#x5982;&#x793A;&#x4F8B;&#x548C;&#x5F15;&#x7528;&#x7684;&#x53C2;&#x8003;&#x3002;</p>
<p><a href="../auto_examples/cluster/plot_mini_batch_kmeans.html"><img src="img/c851b3cdef3493f17f70f7249928e34b.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_mini_batch_kmeans_0011.png"></a></p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py">Comparison of the K-Means and MiniBatchKMeans clustering algorithms</a>: KMeans &#x4E0E; MiniBatchKMeans &#x7684;&#x6BD4;&#x8F83;</li>
<li><a href="../auto_examples/text/document_clustering.html#sphx-glr-auto-examples-text-document-clustering-py">Clustering text documents using k-means</a>: &#x4F7F;&#x7528; sparse MiniBatchKMeans &#xFF08;&#x7A00;&#x758F; MiniBatchKMeans&#xFF09;&#x7684;&#x6587;&#x6863;&#x805A;&#x7C7B;</li>
<li><a href="../auto_examples/cluster/plot_dict_face_patches.html#sphx-glr-auto-examples-cluster-plot-dict-face-patches-py">Online learning of a dictionary of parts of faces</a></li>
</ul>
<p>&#x53C2;&#x8003;:</p>
<ul>
<li><a href="http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf" target="_blank">&#x201C;Web Scale K-Means clustering&#x201D;</a> D. Sculley, <em>Proceedings of the 19th international conference on World wide web</em> (2010)</li>
</ul>
<h2 id="233-affinity-propagation">2.3.3. Affinity Propagation</h2>
<p><a href="generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation" title="sklearn.cluster.AffinityPropagation"><code>AffinityPropagation</code></a> AP&#x805A;&#x7C7B;&#x662F;&#x901A;&#x8FC7;&#x5728;&#x6837;&#x672C;&#x5BF9;&#x4E4B;&#x95F4;&#x53D1;&#x9001;&#x6D88;&#x606F;&#x76F4;&#x5230;&#x6536;&#x655B;&#x6765;&#x521B;&#x5EFA;&#x805A;&#x7C7B;&#x3002;&#x7136;&#x540E;&#x4F7F;&#x7528;&#x5C11;&#x91CF;&#x793A;&#x4F8B;&#x6837;&#x672C;&#x4F5C;&#x4E3A;&#x805A;&#x7C7B;&#x4E2D;&#x5FC3;&#x6765;&#x63CF;&#x8FF0;&#x6570;&#x636E;&#x96C6;&#xFF0C; &#x805A;&#x7C7B;&#x4E2D;&#x5FC3;&#x662F;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x6700;&#x80FD;&#x4EE3;&#x8868;&#x4E00;&#x7C7B;&#x6570;&#x636E;&#x7684;&#x6837;&#x672C;&#x3002;&#x5728;&#x6837;&#x672C;&#x5BF9;&#x4E4B;&#x95F4;&#x53D1;&#x9001;&#x7684;&#x6D88;&#x606F;&#x8868;&#x793A;&#x4E00;&#x4E2A;&#x6837;&#x672C;&#x4F5C;&#x4E3A;&#x53E6;&#x4E00;&#x4E2A;&#x6837;&#x672C;&#x7684;&#x793A;&#x4F8B;&#x6837;&#x672C;&#x7684; &#x9002;&#x5408;&#x7A0B;&#x5EA6;&#xFF0C;&#x9002;&#x5408;&#x7A0B;&#x5EA6;&#x503C;&#x5728;&#x6839;&#x636E;&#x901A;&#x4FE1;&#x7684;&#x53CD;&#x9988;&#x4E0D;&#x65AD;&#x66F4;&#x65B0;&#x3002;&#x66F4;&#x65B0;&#x8FED;&#x4EE3;&#x76F4;&#x5230;&#x6536;&#x655B;&#xFF0C;&#x5B8C;&#x6210;&#x805A;&#x7C7B;&#x4E2D;&#x5FC3;&#x7684;&#x9009;&#x53D6;&#xFF0C;&#x56E0;&#x6B64;&#x4E5F;&#x7ED9;&#x51FA;&#x4E86;&#x6700;&#x7EC8;&#x805A;&#x7C7B;&#x3002;</p>
<p><a href="../auto_examples/cluster/plot_affinity_propagation.html"><img src="img/12867664a0e0e6047ee303c542b4deac.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_affinity_propagation_0011.png"></a></p>
<pre><code class="lang-py">Affinity Propagation &#x7B97;&#x6CD5;&#x6BD4;&#x8F83;&#x6709;&#x8DA3;&#x7684;&#x662F;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x63D0;&#x4F9B;&#x7684;&#x6570;&#x636E;&#x51B3;&#x5B9A;&#x805A;&#x7C7B;&#x7684;&#x6570;&#x76EE;&#x3002; &#x56E0;&#x6B64;&#x6709;&#x4E24;&#x4E2A;&#x6BD4;&#x8F83;&#x91CD;&#x8981;&#x7684;&#x53C2;&#x6570;
</code></pre>
<p><em>preference</em>, &#x51B3;&#x5B9A;&#x4F7F;&#x7528;&#x591A;&#x5C11;&#x4E2A;&#x793A;&#x4F8B;&#x6837;&#x672C; <a href="#id6">*</a>damping factor*&#xFF08;&#x963B;&#x5C3C;&#x56E0;&#x5B50;&#xFF09; &#x51CF;&#x5C11;&#x5438;&#x5F15;&#x4FE1;&#x606F;&#x548C;&#x5F52;&#x5C5E;&#x4FE1;&#x606F;&#x4EE5;&#x9632;&#x6B62; &#x66F4;&#x65B0;&#x51CF;&#x5C11;&#x5438;&#x5F15;&#x5EA6;&#x548C;&#x5F52;&#x5C5E;&#x5EA6;&#x4FE1;&#x606F;&#x65F6;&#x6570;&#x636E;&#x632F;&#x8361;&#x3002;</p>
<p>AP&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#x4E3B;&#x8981;&#x7684;&#x7F3A;&#x70B9;&#x662F;&#x7B97;&#x6CD5;&#x7684;&#x590D;&#x6742;&#x5EA6;. AP&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#x7684;&#x65F6;&#x95F4;&#x590D;&#x6742;&#x5EA6;&#x662F; <img src="img/2af4d75ca07ede34c7d38b8f7708723d.jpg" alt="O(N^2 T)">, &#x5176;&#x4E2D; <img src="img/a44a7c045f2217894a894c482861387a.jpg" alt="N"> &#x662F;&#x6837;&#x672C;&#x7684;&#x4E2A;&#x6570; &#xFF0C; <img src="img/c4373cf7ea98d1425608569103286d28.jpg" alt="T"> &#x662F;&#x6536;&#x655B;&#x4E4B;&#x524D;&#x8FED;&#x4EE3;&#x7684;&#x6B21;&#x6570;. &#x5982;&#x679C;&#x4F7F;&#x7528;&#x5BC6;&#x96C6;&#x7684;&#x76F8;&#x4F3C;&#x6027;&#x77E9;&#x9635;&#x7A7A;&#x95F4;&#x590D;&#x6742;&#x5EA6;&#x662F; <img src="img/ff5428ca3c50ed06f5162ad194377188.jpg" alt="O(N^2)"> &#x5982;&#x679C;&#x4F7F;&#x7528;&#x7A00;&#x758F;&#x7684;&#x76F8;&#x4F3C;&#x6027;&#x77E9;&#x9635;&#x7A7A;&#x95F4;&#x590D;&#x6742;&#x5EA6;&#x53EF;&#x4EE5;&#x964D;&#x4F4E;&#x3002; &#x8FD9;&#x4F7F;&#x5F97;AP&#x805A;&#x7C7B;&#x6700;&#x9002;&#x5408;&#x4E2D;&#x5C0F;&#x578B;&#x6570;&#x636E;&#x96C6;&#x3002;</p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_affinity_propagation.html#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py">Demo of affinity propagation clustering algorithm</a>: Affinity Propagation on a synthetic 2D datasets with 3 classes.</li>
<li><a href="../auto_examples/applications/plot_stock_market.html#sphx-glr-auto-examples-applications-plot-stock-market-py">Visualizing the stock market structure</a> Affinity Propagation on Financial time series to find groups of companies</li>
</ul>
<p><strong>Algorithm description(&#x7B97;&#x6CD5;&#x63CF;&#x8FF0;):</strong> &#x6837;&#x672C;&#x4E4B;&#x95F4;&#x4F20;&#x9012;&#x7684;&#x4FE1;&#x606F;&#x6709;&#x4E24;&#x79CD;&#x3002; &#x7B2C;&#x4E00;&#x79CD;&#x662F; responsibility(&#x5438;&#x5F15;&#x4FE1;&#x606F;) <img src="img/d7b279566c62332b11d20ca6ff026505.jpg" alt="r(i, k)">, &#x6837;&#x672C; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x9002;&#x5408;&#x4F5C;&#x4E3A;&#x6837;&#x672C; <img src="img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"> &#x7684;&#x805A;&#x7C7B;&#x4E2D;&#x5FC3;&#x7684;&#x7A0B;&#x5EA6;&#x3002;</p>
<p>&#x7B2C;&#x4E8C;&#x79CD;&#x662F; availability(&#x5F52;&#x5C5E;&#x4FE1;&#x606F;) <img src="img/725082a3e3f2eacec65e9c1435a6960d.jpg" alt="a(i, k)"> &#x6837;&#x672C; <img src="img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"> &#x9009;&#x62E9;&#x6837;&#x672C; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x4F5C;&#x4E3A;&#x805A;&#x7C7B;&#x4E2D;&#x5FC3;&#x7684;&#x9002;&#x5408;&#x7A0B;&#x5EA6;,&#x5E76;&#x4E14;&#x8003;&#x8651;&#x5176;&#x4ED6;&#x6240;&#x6709;&#x6837;&#x672C;&#x9009;&#x53D6; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x505A;&#x4E3A;&#x805A;&#x7C7B;&#x4E2D;&#x5FC3;&#x7684;&#x5408;&#x9002;&#x7A0B;&#x5EA6;&#x3002; &#x901A;&#x8FC7;&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#xFF0C;&#x9009;&#x53D6;&#x793A;&#x4F8B;&#x6837;&#x672C;&#x4F5C;&#x4E3A;&#x805A;&#x7C7B;&#x4E2D;&#x5FC3;&#x5982;&#x679C; (1) &#x8BE5;&#x6837;&#x672C;&#x4E0E;&#x5176;&#x8BB8;&#x591A;&#x6837;&#x672C;&#x76F8;&#x4F3C;&#xFF0C;&#x5E76;&#x4E14; (2) &#x88AB;&#x8BB8;&#x591A;&#x6837;&#x672C;&#x9009;&#x53D6; &#x4E3A;&#x5B83;&#x4EEC;&#x81EA;&#x5DF1;&#x7684;&#x793A;&#x4F8B;&#x6837;&#x672C;&#x3002;</p>
<p>&#x6837;&#x672C; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x5BF9;&#x6837;&#x672C; <img src="img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"> &#x5438;&#x5F15;&#x5EA6;&#x8BA1;&#x7B97;&#x516C;&#x5F0F;:</p>
<p><img src="img/8dab78bd2e80188f99e0c88c4c83472a.jpg" alt="r(i, k) \leftarrow s(i, k) - max [ a(i, k&apos;) + s(i, k&apos;) \forall k&apos; \neq k ]"></p>
<p>&#x5176;&#x4E2D; <img src="img/f8d66dde73704b8821db5322592a0cc2.jpg" alt="s(i, k)"> &#x662F;&#x6837;&#x672C; <img src="img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"> &#x548C;&#x6837;&#x672C; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x4E4B;&#x95F4;&#x7684;&#x76F8;&#x4F3C;&#x5EA6;&#x3002; &#x6837;&#x672C; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x4F5C;&#x4E3A;&#x6837;&#x672C; <img src="img/43e13b580daefe5ba754b790dfbd216c.jpg" alt="i"> &#x7684;&#x793A;&#x4F8B;&#x6837;&#x672C;&#x7684;&#x5408;&#x9002;&#x7A0B;&#x5EA6;:</p>
<p><img src="img/851c667ab0811688c25c6819aafacba0.jpg" alt="a(i, k) \leftarrow min [0, r(k, k) + \sum_{i&apos;~s.t.~i&apos; \notin \{i, k\}}{r(i&apos;, k)}]"></p>
<p>&#x7B97;&#x6CD5;&#x5F00;&#x59CB;&#x65F6; <img src="img/451ef7ed1a14a6cdc38324c8a5c7c683.jpg" alt="r"> &#x548C; <img src="img/578c95150175e4efdf851fe66d503079.jpg" alt="a"> &#x90FD;&#x88AB;&#x7F6E; 0,&#x7136;&#x540E;&#x5F00;&#x59CB;&#x8FED;&#x4EE3;&#x8BA1;&#x7B97;&#x76F4;&#x5230;&#x6536;&#x655B;&#x3002; &#x4E3A;&#x4E86;&#x9632;&#x6B62;&#x66F4;&#x65B0;&#x6570;&#x636E;&#x65F6;&#x51FA;&#x73B0;&#x6570;&#x636E;&#x632F;&#x8361;&#xFF0C;&#x5728;&#x8FED;&#x4EE3;&#x8FC7;&#x7A0B;&#x4E2D;&#x5F15;&#x5165;&#x963B;&#x5C3C;&#x56E0;&#x5B50; <img src="img/0f92bc682b050115d03c625ce770c77d.jpg" alt="\lambda"> :</p>
<p><img src="img/f1fa822436569807fdc9dca5d2879d99.jpg" alt="r_{t+1}(i, k) = \lambda\cdot r_{t}(i, k) + (1-\lambda)\cdot r_{t+1}(i, k)"></p>
<p><img src="img/1ae6d373d81c5f3f50905f336b4a070a.jpg" alt="a_{t+1}(i, k) = \lambda\cdot a_{t}(i, k) + (1-\lambda)\cdot a_{t+1}(i, k)"></p>
<p>&#x5176;&#x4E2D; <img src="img/12b2c1da1f9041738fa7153efc651372.jpg" alt="t"> &#x8FED;&#x4EE3;&#x7684;&#x6B21;&#x6570;&#x3002;</p>
<h2 id="234-mean-shift">2.3.4. Mean Shift</h2>
<p><a href="generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift" title="sklearn.cluster.MeanShift"><code>MeanShift</code></a> &#x7B97;&#x6CD5;&#x65E8;&#x5728;&#x4E8E;&#x53D1;&#x73B0;&#x4E00;&#x4E2A;&#x6837;&#x672C;&#x5BC6;&#x5EA6;&#x5E73;&#x6ED1;&#x7684; <em>blobs</em> &#x3002; &#x5747;&#x503C;&#x6F02;&#x79FB;&#x7B97;&#x6CD5;&#x662F;&#x57FA;&#x4E8E;&#x8D28;&#x5FC3;&#x7684;&#x7B97;&#x6CD5;&#xFF0C;&#x901A;&#x8FC7;&#x66F4;&#x65B0;&#x8D28;&#x5FC3;&#x7684;&#x5019;&#x9009;&#x4F4D;&#x7F6E;&#x4E3A;&#x6240;&#x9009;&#x5B9A;&#x533A;&#x57DF;&#x7684;&#x504F;&#x79FB;&#x5747;&#x503C;&#x3002; &#x7136;&#x540E;&#xFF0C;&#x8FD9;&#x4E9B;&#x5019;&#x9009;&#x8005;&#x5728;&#x540E;&#x5904;&#x7406;&#x9636;&#x6BB5;&#x88AB;&#x8FC7;&#x6EE4;&#x4EE5;&#x6D88;&#x9664;&#x8FD1;&#x4F3C;&#x91CD;&#x590D;&#xFF0C;&#x4ECE;&#x800C;&#x5F62;&#x6210;&#x6700;&#x7EC8;&#x8D28;&#x5FC3;&#x96C6;&#x5408;&#x3002;</p>
<p>&#x7ED9;&#x5B9A;&#x7B2C; <img src="img/12b2c1da1f9041738fa7153efc651372.jpg" alt="t"> &#x6B21;&#x8FED;&#x4EE3;&#x4E2D;&#x7684;&#x5019;&#x9009;&#x8D28;&#x5FC3; <img src="img/cf52655ee609af9f3c27c06448a5bf67.jpg" alt="x_i"> , &#x5019;&#x9009;&#x8D28;&#x5FC3;&#x7684;&#x4F4D;&#x7F6E;&#x5C06;&#x88AB;&#x5B89;&#x88C5;&#x5982;&#x4E0B;&#x516C;&#x5F0F;&#x66F4;&#x65B0;:</p>
<p><img src="img/be2b3bbef9fe377c6f748dd05355b58b.jpg" alt="x_i^{t+1} = x_i^t + m(x_i^t)"></p>
<p>&#x5176;&#x4E2D; <img src="img/f35f174b5f70ab18c19107e3f0fbe889.jpg" alt="N(x_i)"> &#x662F;&#x56F4;&#x7ED5; <img src="img/cf52655ee609af9f3c27c06448a5bf67.jpg" alt="x_i"> &#x5468;&#x56F4;&#x4E00;&#x4E2A;&#x7ED9;&#x5B9A;&#x8DDD;&#x79BB;&#x8303;&#x56F4;&#x5185;&#x7684;&#x6837;&#x672C;&#x7A7A;&#x95F4; and <img src="img/94156b879a7455cb0d516efa9c9c0991.jpg" alt="m"> &#x662F; <em>mean shift</em> vector&#xFF08;&#x5747;&#x503C;&#x504F;&#x79FB;&#x5411;&#x91CF;&#xFF09; &#x662F;&#x6240;&#x6709;&#x8D28;&#x5FC3;&#x4E2D;&#x6307;&#x5411; &#x70B9;&#x5BC6;&#x5EA6;&#x589E;&#x52A0;&#x6700;&#x591A;&#x7684;&#x533A;&#x57DF;&#x7684;&#x504F;&#x79FB;&#x5411;&#x91CF;&#x3002;&#x4F7F;&#x7528;&#x4EE5;&#x4E0B;&#x7B49;&#x5F0F;&#x8BA1;&#x7B97;&#xFF0C;&#x6709;&#x6548;&#x5730;&#x5C06;&#x8D28;&#x5FC3;&#x66F4;&#x65B0;&#x4E3A;&#x5176;&#x90BB;&#x57DF;&#x5185;&#x6837;&#x672C;&#x7684;&#x5E73;&#x5747;&#x503C;:</p>
<p><img src="img/97f450040417800904df33c9702d2c66.jpg" alt="m(x_i) = \frac{\sum_{x_j \in N(x_i)}K(x_j - x_i)x_j}{\sum_{x_j \in N(x_i)}K(x_j - x_i)}"></p>
<p>&#x7B97;&#x6CD5;&#x81EA;&#x52A8;&#x8BBE;&#x5B9A;&#x805A;&#x7C7B;&#x7684;&#x6570;&#x76EE;&#xFF0C;&#x53D6;&#x4EE3;&#x4F9D;&#x8D56;&#x53C2;&#x6570; <code>bandwidth``&#xFF08;&#x5E26;&#x5BBD;&#xFF09;,&#x5E26;&#x5BBD;&#x662F;&#x51B3;&#x5B9A;&#x641C;&#x7D22;&#x533A;&#x57DF;&#x7684;size&#x7684;&#x53C2;&#x6570;&#x3002; &#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#x53EF;&#x4EE5;&#x624B;&#x52A8;&#x8BBE;&#x7F6E;&#xFF0C;&#x4F46;&#x662F;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x8BBE;&#x7F6E;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x63D0;&#x4F9B;&#x7684;&#x8BC4;&#x4F30;&#x51FD;&#x6570; ``estimate_bandwidth</code> &#x8FDB;&#x884C;&#x8BC4;&#x4F30;&#x3002;</p>
<p>&#x8BE5;&#x7B97;&#x6CD5;&#x4E0D;&#x662F;&#x9AD8;&#x5EA6;&#x53EF;&#x6269;&#x5C55;&#x7684;&#xFF0C;&#x56E0;&#x4E3A;&#x5728;&#x6267;&#x884C;&#x7B97;&#x6CD5;&#x671F;&#x95F4;&#x9700;&#x8981;&#x6267;&#x884C;&#x591A;&#x4E2A;&#x6700;&#x8FD1;&#x90BB;&#x641C;&#x7D22;&#x3002; &#x8BE5;&#x7B97;&#x6CD5;&#x4FDD;&#x8BC1;&#x6536;&#x655B;&#xFF0C;&#x4F46;&#x662F;&#x5F53; &#x8D28;&#x5FC3;&#x7684;&#x53D8;&#x5316;&#x8F83;&#x5C0F;&#x65F6;&#xFF0C;&#x7B97;&#x6CD5;&#x5C06;&#x505C;&#x6B62;&#x8FED;&#x4EE3;&#x3002;</p>
<p>&#x901A;&#x8FC7;&#x627E;&#x5230;&#x7ED9;&#x5B9A;&#x6837;&#x672C;&#x7684;&#x6700;&#x8FD1;&#x8D28;&#x5FC3;&#x6765;&#x7ED9;&#x65B0;&#x6837;&#x672C;&#x6253;&#x4E0A;&#x6807;&#x7B7E;&#x3002;</p>
<p><a href="../auto_examples/cluster/plot_mean_shift.html"><img src="img/7304e7fb0302be38d7fa1688bcd14df4.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_mean_shift_0011.png"></a></p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_mean_shift.html#sphx-glr-auto-examples-cluster-plot-mean-shift-py">A demo of the mean-shift clustering algorithm</a>: Mean Shift clustering on a synthetic 2D datasets with 3 classes.</li>
</ul>
<p>&#x53C2;&#x8003;:</p>
<ul>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.8968&amp;rep=rep1&amp;type=pdf" target="_blank">&#x201C;Mean shift: A robust approach toward feature space analysis.&#x201D;</a> D. Comaniciu and P. Meer, <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (2002)</li>
</ul>
<h2 id="235-spectral-clustering">2.3.5. Spectral clustering</h2>
<p><a href="generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" title="sklearn.cluster.SpectralClustering"><code>SpectralClustering</code></a> &#x662F;&#x5728;&#x6837;&#x672C;&#x4E4B;&#x95F4;&#x8FDB;&#x884C;&#x4EB2;&#x548C;&#x529B;&#x77E9;&#x9635;&#x7684;&#x4F4E;&#x7EF4;&#x5EA6;&#x5D4C;&#x5165;&#xFF0C;&#x5176;&#x5B9E;&#x662F;&#x4F4E;&#x7EF4;&#x7A7A;&#x95F4;&#x4E2D;&#x7684; KMeans&#x3002; &#x5982;&#x679C;&#x4EB2;&#x548C;&#x5EA6;&#x77E9;&#x9635;&#x7A00;&#x758F;&#xFF0C;&#x5219;&#x8FD9;&#x662F;&#x975E;&#x5E38;&#x6709;&#x6548;&#x7684;&#x5E76;&#x4E14; <a href="http://pyamg.org/" target="_blank">pyamg</a> module &#x4EE5;&#x53CA;&#x5B89;&#x88C5;&#x597D;&#x3002; SpectralClustering &#x9700;&#x8981;&#x6307;&#x5B9A;&#x805A;&#x7C7B;&#x6570;&#x3002;&#x8FD9;&#x4E2A;&#x7B97;&#x6CD5;&#x9002;&#x7528;&#x4E8E;&#x805A;&#x7C7B;&#x6570;&#x5C11;&#x65F6;&#xFF0C;&#x5728;&#x805A;&#x7C7B;&#x6570;&#x591A;&#x662F;&#x4E0D;&#x5EFA;&#x8BAE;&#x4F7F;&#x7528;&#x3002;</p>
<p>&#x5BF9;&#x4E8E;&#x4E24;&#x4E2A;&#x805A;&#x7C7B;&#xFF0C;&#x5B83;&#x89E3;&#x51B3;&#x4E86;&#x76F8;&#x4F3C;&#x56FE;&#x4E0A;&#x7684; <a href="http://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf" target="_blank">normalised cuts</a> &#x95EE;&#x9898;: &#x5C06;&#x56FE;&#x5F62;&#x5207;&#x5272;&#x6210;&#x4E24;&#x4E2A;&#xFF0C;&#x4F7F;&#x5F97;&#x5207;&#x5272;&#x7684;&#x8FB9;&#x7F18;&#x7684;&#x91CD;&#x91CF;&#x6BD4;&#x6BCF;&#x4E2A;&#x7C07;&#x5185;&#x7684;&#x8FB9;&#x7F18;&#x7684;&#x6743;&#x91CD;&#x5C0F;&#x3002;&#x5728;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x65F6;&#xFF0C;&#x8FD9;&#x4E2A;&#x6807;&#x51C6;&#x662F;&#x7279;&#x522B;&#x6709;&#x8DA3;&#x7684;: &#x56FE;&#x50CF;&#x7684;&#x9876;&#x70B9;&#x662F;&#x50CF;&#x7D20;&#xFF0C;&#x76F8;&#x4F3C;&#x56FE;&#x7684;&#x8FB9;&#x7F18;&#x662F;&#x56FE;&#x50CF;&#x7684;&#x6E10;&#x53D8;&#x51FD;&#x6570;&#x3002;</p>
<p><strong><a href="../auto_examples/cluster/plot_segmentation_toy.html"><img src="img/bb0a3257b0276e1ade46d7fa84c49ad0.jpg" alt="noisy_img"></a> <a href="../auto_examples/cluster/plot_segmentation_toy.html"><img src="img/5ec012661471fa940c27472afcce01a2.jpg" alt="segmented_img"></a></strong></p>
<p>Warning</p>
<p>Transforming distance to well-behaved similarities</p>
<p>&#x8BF7;&#x6CE8;&#x610F;&#xFF0C;&#x5982;&#x679C;&#x4F60;&#x7684;&#x76F8;&#x4F3C;&#x77E9;&#x9635;&#x7684;&#x503C;&#x5206;&#x5E03;&#x4E0D;&#x5747;&#x5300;&#xFF0C;&#x4F8B;&#x5982;:&#x5B58;&#x5728;&#x8D1F;&#x503C;&#x6216;&#x8005;&#x8DDD;&#x79BB;&#x77E9;&#x9635;&#x5E76;&#x4E0D;&#x8868;&#x793A;&#x76F8;&#x4F3C;&#x6027; spectral problem &#x5C06;&#x4F1A;&#x53D8;&#x5F97;&#x5947;&#x5F02;&#xFF0C;&#x5E76;&#x4E14;&#x4E0D;&#x80FD;&#x89E3;&#x51B3;&#x3002; &#x5728;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x5EFA;&#x8BAE;&#x5BF9;&#x77E9;&#x9635;&#x7684; entries &#x8FDB;&#x884C;&#x8F6C;&#x6362;&#x3002;&#x6BD4;&#x5982;&#x5728;&#x7B26;&#x53F7;&#x8DDD;&#x79BB;&#x6709;&#x7B26;&#x53F7;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x901A;&#x5E38;&#x4F7F;&#x7528; heat kernel:</p>
<pre><code class="lang-py">similarity = np.exp(-beta * distance / distance.std())
</code></pre>
<p>&#x8BF7;&#x770B;&#x8FD9;&#x6837;&#x4E00;&#x4E2A;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x7684;&#x4F8B;&#x5B50;&#x3002;</p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_segmentation_toy.html#sphx-glr-auto-examples-cluster-plot-segmentation-toy-py">Spectral clustering for image segmentation</a>: Segmenting objects from a noisy background using spectral clustering.</li>
<li><a href="../auto_examples/cluster/plot_face_segmentation.html#sphx-glr-auto-examples-cluster-plot-face-segmentation-py">Segmenting the picture of a raccoon face in regions</a>: Spectral clustering to split the image of the raccoon face in regions.</li>
</ul>
<h3 id="2351-&#x4E0D;&#x540C;&#x7684;&#x6807;&#x8BB0;&#x5206;&#x914D;&#x7B56;&#x7565;">2.3.5.1. &#x4E0D;&#x540C;&#x7684;&#x6807;&#x8BB0;&#x5206;&#x914D;&#x7B56;&#x7565;</h3>
<p>&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x5206;&#x914D;&#x7B56;&#x7565;, &#x5BF9;&#x5E94;&#x4E8E; <code>assign_labels</code> &#x53C2;&#x6570; <a href="generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering" title="sklearn.cluster.SpectralClustering"><code>SpectralClustering</code></a>&#x3002; <code>&quot;kmeans&quot;</code> &#x53EF;&#x4EE5;&#x5339;&#x914D;&#x66F4;&#x7CBE;&#x7EC6;&#x7684;&#x6570;&#x636E;&#x7EC6;&#x8282;&#xFF0C;&#x4F46;&#x662F;&#x53EF;&#x80FD;&#x66F4;&#x52A0;&#x4E0D;&#x7A33;&#x5B9A;&#x3002; &#x7279;&#x522B;&#x662F;&#xFF0C;&#x9664;&#x975E;&#x4F60;&#x8BBE;&#x7F6E; <code>random_state</code> &#x5426;&#x5219;&#x53EF;&#x80FD;&#x65E0;&#x6CD5;&#x590D;&#x73B0;&#x8FD0;&#x884C;&#x7684;&#x7ED3;&#x679C; &#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x53D6;&#x51B3;&#x4E8E;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x3002;&#x53E6;&#x4E00;&#x65B9;&#xFF0C; &#x4F7F;&#x7528; <code>&quot;discretize&quot;</code> &#x7B56;&#x7565;&#x662F; 100% &#x53EF;&#x4EE5;&#x590D;&#x73B0;&#x7684;&#xFF0C;&#x4F46;&#x662F;&#x5B83;&#x5F80;&#x5F80;&#x4F1A;&#x4EA7;&#x751F;&#x76F8;&#x5F53;&#x5747;&#x5300;&#x7684;&#x51E0;&#x4F55;&#x5F62;&#x72B6;&#x7684;&#x8FB9;&#x7F18;&#x3002;</p>
<table>
<thead>
<tr>
<th><code>assign_labels=&quot;kmeans&quot;</code></th>
<th><code>assign_labels=&quot;discretize&quot;</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="../auto_examples/cluster/plot_face_segmentation.html"><img src="img/3579ce0b5c145fb891d865367eeba3ac.jpg" alt="face_kmeans"></a></td>
<td><a href="../auto_examples/cluster/plot_face_segmentation.html"><img src="img/1ff26934befcf3ca9623f1e729a8824c.jpg" alt="face_discretize"></a></td>
</tr>
</tbody>
</table>
<p>&#x53C2;&#x8003;:</p>
<ul>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323" target="_blank">&#x201C;A Tutorial on Spectral Clustering&#x201D;</a> Ulrike von Luxburg, 2007</li>
<li><a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324" target="_blank">&#x201C;Normalized cuts and image segmentation&#x201D;</a> Jianbo Shi, Jitendra Malik, 2000</li>
<li><a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.1501" target="_blank">&#x201C;A Random Walks View of Spectral Segmentation&#x201D;</a> Marina Meila, Jianbo Shi, 2001</li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100" target="_blank">&#x201C;On Spectral Clustering: Analysis and an algorithm&#x201D;</a> Andrew Y. Ng, Michael I. Jordan, Yair Weiss, 2001</li>
</ul>
<h2 id="236-&#x5C42;&#x6B21;&#x805A;&#x7C7B;">2.3.6. &#x5C42;&#x6B21;&#x805A;&#x7C7B;</h2>
<p>Hierarchical clustering &#x662F;&#x4E00;&#x4E2A;&#x5E38;&#x7528;&#x7684;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF0C;&#x5B83;&#x901A;&#x8FC7;&#x4E0D;&#x65AD;&#x7684;&#x5408;&#x5E76;&#x6216;&#x8005;&#x5206;&#x5272;&#x6765;&#x6784;&#x5EFA;&#x805A;&#x7C7B;&#x3002; &#x805A;&#x7C7B;&#x7684;&#x5C42;&#x6B21;&#x88AB;&#x8868;&#x793A;&#x6210;&#x6811;&#xFF08;&#x6216;&#x8005; dendrogram&#xFF08;&#x6811;&#x5F62;&#x56FE;&#xFF09;&#xFF09;&#x3002;&#x6811;&#x6839;&#x662F;&#x62E5;&#x6709;&#x6240;&#x6709;&#x6837;&#x672C;&#x7684;&#x552F;&#x4E00;&#x805A;&#x7C7B;&#xFF0C;&#x53F6;&#x5B50;&#x662F;&#x4EC5;&#x6709;&#x4E00;&#x4E2A;&#x6837;&#x672C;&#x7684;&#x805A;&#x7C7B;&#x3002; &#x8BF7;&#x53C2;&#x7167; <a href="https://en.wikipedia.org/wiki/Hierarchical_clustering" target="_blank">Wikipedia page</a> &#x67E5;&#x770B;&#x66F4;&#x591A;&#x7EC6;&#x8282;&#x3002;</p>
<p>The <a href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code>AgglomerativeClustering</code></a> &#x4F7F;&#x7528;&#x81EA;&#x4E0B;&#x800C;&#x4E0A;&#x7684;&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x5C42;&#x6B21;&#x805A;&#x7C7B;:&#x5F00;&#x59CB;&#x662F;&#x6BCF;&#x4E00;&#x4E2A;&#x5BF9;&#x8C61;&#x662F;&#x4E00;&#x4E2A;&#x805A;&#x7C7B;&#xFF0C; &#x5E76;&#x4E14;&#x805A;&#x7C7B;&#x522B;&#x76F8;&#x7EE7;&#x5408;&#x5E76;&#x5728;&#x4E00;&#x8D77;&#x3002; linkage criteria &#x786E;&#x5B9A;&#x7528;&#x4E8E;&#x5408;&#x5E76;&#x7684;&#x7B56;&#x7565;&#x7684;&#x5EA6;&#x91CF;:</p>
<ul>
<li><strong>Ward</strong> &#x6700;&#x5C0F;&#x5316;&#x6240;&#x6709;&#x805A;&#x7C7B;&#x5185;&#x7684;&#x5E73;&#x65B9;&#x5DEE;&#x603B;&#x548C;&#x3002;&#x8FD9;&#x662F;&#x4E00;&#x79CD; variance-minimizing &#xFF08;&#x65B9;&#x5DEE;&#x6700;&#x5C0F;&#x5316;&#xFF09;&#x7684;&#x4F18;&#x5316;&#x65B9;&#x5411;&#xFF0C; &#x8FD9;&#x662F;&#x4E0E;k-means &#x7684;&#x76EE;&#x6807;&#x51FD;&#x6570;&#x76F8;&#x4F3C;&#x7684;&#x4F18;&#x5316;&#x65B9;&#x6CD5;&#xFF0C;&#x4F46;&#x662F;&#x7528; agglomerative hierarchical&#xFF08;&#x805A;&#x7C7B;&#x5206;&#x5C42;&#xFF09;&#x7684;&#x65B9;&#x6CD5;&#x5904;&#x7406;&#x3002;</li>
<li><strong>Maximum</strong> &#x6216; <strong>complete linkage</strong> &#x6700;&#x5C0F;&#x5316;&#x805A;&#x7C7B;&#x5BF9;&#x4E24;&#x4E2A;&#x6837;&#x672C;&#x4E4B;&#x95F4;&#x7684;&#x6700;&#x5927;&#x8DDD;&#x79BB;&#x3002;</li>
<li><strong>Average linkage</strong> &#x6700;&#x5C0F;&#x5316;&#x805A;&#x7C7B;&#x4E24;&#x4E2A;&#x805A;&#x7C7B;&#x4E2D;&#x6837;&#x672C;&#x8DDD;&#x79BB;&#x7684;&#x5E73;&#x5747;&#x503C;&#x3002;</li>
</ul>
<p><a href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code>AgglomerativeClustering</code></a> &#x5728;&#x4E8E;&#x8FDE;&#x63A5;&#x77E9;&#x9635;&#x8054;&#x5408;&#x4F7F;&#x7528;&#x65F6;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x6269;&#x5927;&#x5230;&#x5927;&#x91CF;&#x7684;&#x6837;&#x672C;&#xFF0C;&#x4F46;&#x662F; &#x5728;&#x6837;&#x672C;&#x4E4B;&#x95F4;&#x6CA1;&#x6709;&#x6DFB;&#x52A0;&#x8FDE;&#x63A5;&#x7EA6;&#x675F;&#x65F6;&#xFF0C;&#x8BA1;&#x7B97;&#x4EE3;&#x4EF7;&#x5F88;&#x5927;:&#x6BCF;&#x4E00;&#x4E2A;&#x6B65;&#x9AA4;&#x90FD;&#x8981;&#x8003;&#x8651;&#x6240;&#x6709;&#x53EF;&#x80FD;&#x7684;&#x5408;&#x5E76;&#x3002;</p>
<p><a href="generated/sklearn.cluster.FeatureAgglomeration.html#sklearn.cluster.FeatureAgglomeration" title="sklearn.cluster.FeatureAgglomeration"><code>FeatureAgglomeration</code></a></p>
<p>The <a href="generated/sklearn.cluster.FeatureAgglomeration.html#sklearn.cluster.FeatureAgglomeration" title="sklearn.cluster.FeatureAgglomeration"><code>FeatureAgglomeration</code></a> &#x4F7F;&#x7528; agglomerative clustering &#x5C06;&#x770B;&#x4E0A;&#x53BB;&#x76F8;&#x4F3C;&#x7684; &#x7279;&#x5F81;&#x7EC4;&#x5408;&#x5728;&#x4E00;&#x8D77;&#xFF0C;&#x4ECE;&#x800C;&#x51CF;&#x5C11;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x3002;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x964D;&#x7EF4;&#x5DE5;&#x5177;, &#x8BF7;&#x53C2;&#x7167; <a href="unsupervised_reduction.html#data-reduction">&#x65E0;&#x76D1;&#x7763;&#x964D;&#x7EF4;</a>&#x3002;</p>
<h3 id="2361-different-linkage-type-ward-complete-and-average-linkage">2.3.6.1. Different linkage type: Ward, complete and average linkage</h3>
<p><a href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code>AgglomerativeClustering</code></a> &#x652F;&#x6301; Ward, average, and complete linkage &#x7B56;&#x7565;.</p>
<p><a href="../auto_examples/cluster/plot_digits_linkage.html"><img src="img/8dcf0f01f9d255c37e21948ad3821885.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_digits_linkage_0011.png"></a> <a href="../auto_examples/cluster/plot_digits_linkage.html"><img src="img/eada6f59eaee0a758bddb97b44835751.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_digits_linkage_0021.png"></a> <a href="../auto_examples/cluster/plot_digits_linkage.html"><img src="img/165303a7d56136efa39130cd3cd9539e.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_digits_linkage_0031.png"></a></p>
<p>Agglomerative cluster &#x5B58;&#x5728; &#x201C;rich get richer&#x201D; &#x73B0;&#x8C61;&#x5BFC;&#x81F4;&#x805A;&#x7C7B;&#x5927;&#x5C0F;&#x4E0D;&#x5747;&#x5300;&#x3002;&#x8FD9;&#x65B9;&#x9762; complete linkage &#x662F;&#x6700;&#x574F;&#x7684;&#x7B56;&#x7565;&#xFF0C;Ward &#x7ED9;&#x51FA;&#x4E86;&#x6700;&#x89C4;&#x5219;&#x7684;&#x5927;&#x5C0F;&#x3002;&#x7136;&#x800C;&#xFF0C;&#x5728; Ward &#x4E2D; affinity (or distance used in clustering) &#x4E0D;&#x80FD;&#x88AB;&#x6539;&#x53D8;&#xFF0C;&#x5BF9;&#x4E8E; non Euclidean metrics &#x6765;&#x8BF4; average linkage &#x662F;&#x4E00;&#x4E2A;&#x597D;&#x7684;&#x9009;&#x62E9;&#x3002;</p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_digits_linkage.html#sphx-glr-auto-examples-cluster-plot-digits-linkage-py">Various Agglomerative Clustering on a 2D embedding of digits</a>: exploration of the different linkage strategies in a real dataset.</li>
</ul>
<h3 id="2362-&#x6DFB;&#x52A0;&#x8FDE;&#x63A5;&#x7EA6;&#x675F;">2.3.6.2. &#x6DFB;&#x52A0;&#x8FDE;&#x63A5;&#x7EA6;&#x675F;</h3>
<p><a href="generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code>AgglomerativeClustering</code></a> &#x4E2D;&#x4E00;&#x4E2A;&#x6709;&#x8DA3;&#x7684;&#x7279;&#x70B9;&#x662F;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; connectivity matrix&#xFF08;&#x8FDE;&#x63A5;&#x77E9;&#x9635;&#xFF09; &#x5C06;&#x8FDE;&#x63A5;&#x7EA6;&#x675F;&#x6DFB;&#x52A0;&#x5230;&#x7B97;&#x6CD5;&#x4E2D;&#xFF08;&#x53EA;&#x6709;&#x76F8;&#x90BB;&#x7684;&#x805A;&#x7C7B;&#x53EF;&#x4EE5;&#x5408;&#x5E76;&#x5230;&#x4E00;&#x8D77;&#xFF09;&#xFF0C;&#x8FDE;&#x63A5;&#x77E9;&#x9635;&#x4E3A;&#x6BCF;&#x4E00;&#x4E2A;&#x6837;&#x672C;&#x7ED9;&#x5B9A;&#x4E86;&#x76F8;&#x90BB;&#x7684;&#x6837;&#x672C;&#x3002; &#x4F8B;&#x5982;&#xFF0C;&#x5728; swiss-roll &#x7684;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x8FDE;&#x63A5;&#x7EA6;&#x675F;&#x7981;&#x6B62;&#x5728;&#x4E0D;&#x76F8;&#x90BB;&#x7684; swiss roll &#x4E0A;&#x5408;&#x5E76;&#xFF0C;&#x4ECE;&#x800C;&#x9632;&#x6B62;&#x5F62;&#x6210;&#x5728; roll &#x4E0A; &#x91CD;&#x590D;&#x6298;&#x53E0;&#x7684;&#x805A;&#x7C7B;&#x3002;</p>
<p><strong><a href="../auto_examples/cluster/plot_ward_structured_vs_unstructured.html"><img src="img/63f146cd209ad922f402bf81bfdeb621.jpg" alt="unstructured"></a> <a href="../auto_examples/cluster/plot_ward_structured_vs_unstructured.html"><img src="img/50bc02ed6fb21594c72e30d1a33bbf89.jpg" alt="structured"></a></strong></p>
<p>&#x8FD9;&#x4E9B;&#x7EA6;&#x675F;&#x5BF9;&#x4E8E;&#x5F3A;&#x52A0;&#x4E00;&#x5B9A;&#x7684;&#x5C40;&#x90E8;&#x7ED3;&#x6784;&#x662F;&#x5F88;&#x6709;&#x7528;&#x7684;&#xFF0C;&#x4F46;&#x662F;&#x8FD9;&#x4E5F;&#x4F7F;&#x5F97;&#x7B97;&#x6CD5;&#x66F4;&#x5FEB;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x5F53;&#x6837;&#x672C;&#x6570;&#x91CF;&#x5DE8;&#x5927;&#x65F6;&#x3002;</p>
<p>&#x8FDE;&#x901A;&#x6027;&#x7684;&#x9650;&#x5236;&#x662F;&#x901A;&#x8FC7;&#x8FDE;&#x63A5;&#x77E9;&#x9635;&#x6765;&#x5B9E;&#x73B0;&#x7684;:&#x4E00;&#x4E2A; scipy sparse matrix&#xFF08;&#x7A00;&#x758F;&#x77E9;&#x9635;&#xFF09;&#xFF0C;&#x4EC5;&#x5728;&#x4E00;&#x884C;&#x548C; &#x4E00;&#x5217;&#x7684;&#x4EA4;&#x96C6;&#x5904;&#x5177;&#x6709;&#x5E94;&#x8BE5;&#x8FDE;&#x63A5;&#x5728;&#x4E00;&#x8D77;&#x7684;&#x6570;&#x636E;&#x96C6;&#x7684;&#x7D22;&#x5F15;&#x3002;&#x8FD9;&#x4E2A;&#x77E9;&#x9635;&#x53EF;&#x4EE5;&#x901A;&#x8FC7; a-priori information &#xFF08;&#x5148;&#x9A8C;&#x4FE1;&#x606F;&#xFF09; &#x6784;&#x5EFA;:&#x4F8B;&#x5982;&#xFF0C;&#x4F60;&#x53EF;&#x80FD;&#x901A;&#x8FC7;&#x4EC5;&#x4EC5;&#x5C06;&#x4ECE;&#x4E00;&#x4E2A;&#x8FDE;&#x63A5;&#x6307;&#x5411;&#x53E6;&#x4E00;&#x4E2A;&#x7684;&#x94FE;&#x63A5;&#x5408;&#x5E76;&#x9875;&#x9762;&#x6765;&#x805A;&#x7C7B;&#x9875;&#x9762;&#x3002;&#x4E5F;&#x53EF;&#x4EE5;&#x4ECE;&#x6570;&#x636E;&#x4E2D;&#x5B66;&#x4E60;&#x5230;,</p>
<blockquote>
<p>&#x4F8B;&#x5982;&#x4F7F;&#x7528; <a href="generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><code>sklearn.neighbors.kneighbors_graph</code></a> &#x9650;&#x5236;&#x4E0E;&#x6700;&#x4E34;&#x8FD1;&#x7684;&#x5408;&#x5E76; :ref:<a href="#id13">`</a>this example</p>
</blockquote>
<pre><code class="lang-py">&lt;sphx_glr_auto_examples_cluster_plot_agglomerative_clustering.py&gt;`, &#x6216;&#x8005;&#x4F7F;&#x7528;
</code></pre>
<p><a href="generated/sklearn.feature_extraction.image.grid_to_graph.html#sklearn.feature_extraction.image.grid_to_graph" title="sklearn.feature_extraction.image.grid_to_graph"><code>sklearn.feature_extraction.image.grid_to_graph</code></a> &#x4EC5;&#x5408;&#x5E76;&#x56FE;&#x50CF;&#x4E0A;&#x76F8;&#x90BB;&#x7684;&#x50CF;&#x7D20;&#x70B9;&#xFF0C; &#x4F8B;&#x5982; <a href="../auto_examples/cluster/plot_face_ward_segmentation.html#sphx-glr-auto-examples-cluster-plot-face-ward-segmentation-py">raccoon face</a> &#x3002;</p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_face_ward_segmentation.html#sphx-glr-auto-examples-cluster-plot-face-ward-segmentation-py">A demo of structured Ward hierarchical clustering on a raccoon face image</a>: Ward clustering to split the image of a raccoon face in regions.</li>
<li><a href="../auto_examples/cluster/plot_ward_structured_vs_unstructured.html#sphx-glr-auto-examples-cluster-plot-ward-structured-vs-unstructured-py">Hierarchical clustering: structured vs unstructured ward</a>: Example of Ward algorithm on a swiss-roll, comparison of structured approaches versus unstructured approaches.</li>
<li><a href="../auto_examples/cluster/plot_feature_agglomeration_vs_univariate_selection.html#sphx-glr-auto-examples-cluster-plot-feature-agglomeration-vs-univariate-selection-py">Feature agglomeration vs. univariate selection</a>: Example of dimensionality reduction with feature agglomeration based on Ward hierarchical clustering.</li>
<li><a href="../auto_examples/cluster/plot_agglomerative_clustering.html#sphx-glr-auto-examples-cluster-plot-agglomerative-clustering-py">Agglomerative clustering with and without structure</a></li>
</ul>
<p>Warning</p>
<p><strong>Connectivity constraints with average and complete linkage</strong></p>
<p>Connectivity constraints &#x548C; complete or average linkage &#x53EF;&#x4EE5;&#x589E;&#x5F3A; agglomerative clustering &#x4E2D;&#x7684; &#x2018;rich getting richer&#x2019; &#x73B0;&#x8C61;&#x3002;&#x7279;&#x522B;&#x662F;&#xFF0C;&#x5982;&#x679C;&#x5EFA;&#x7ACB;&#x7684;&#x662F; <a href="generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><code>sklearn.neighbors.kneighbors_graph</code></a>&#x3002; &#x5728;&#x5C11;&#x91CF;&#x805A;&#x7C7B;&#x7684;&#x9650;&#x5236;&#x4E2D;, &#x66F4;&#x503E;&#x5411;&#x4E8E;&#x7ED9;&#x51FA;&#x4E00;&#x4E9B; macroscopically occupied clusters &#x5E76;&#x4E14;&#x51E0;&#x4E4E;&#x662F;&#x7A7A;&#x7684; (&#x8BA8;&#x8BBA;&#x5185;&#x5BB9;&#x8BF7;&#x67E5;&#x770B; <a href="../auto_examples/cluster/plot_agglomerative_clustering.html#sphx-glr-auto-examples-cluster-plot-agglomerative-clustering-py">Agglomerative clustering with and without structure</a>)&#x3002;</p>
<p><a href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img src="img/1ce6ae6c075734e41812dc91b67d16e5.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_agglomerative_clustering_0011.png"></a> <a href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img src="img/59420186f988199ba986eefc023fb637.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_agglomerative_clustering_0021.png"></a> <a href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img src="img/1fc92e9d8efa5433f7346284592e9ea0.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_agglomerative_clustering_0031.png"></a> <a href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img src="img/d61124c62424b8a8d38adc3c41bb71f6.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_agglomerative_clustering_0041.png"></a></p>
<h3 id="2363-varying-the-metric">2.3.6.3. Varying the metric</h3>
<p>Average and complete linkage &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x5404;&#x79CD;&#x8DDD;&#x79BB; (or affinities), &#x7279;&#x522B;&#x662F; Euclidean distance (<em>l2</em>), Manhattan distance&#xFF08;&#x66FC;&#x54C8;&#x987F;&#x8DDD;&#x79BB;&#xFF09;(or Cityblock&#xFF08;&#x57CE;&#x5E02;&#x533A;&#x5757;&#x8DDD;&#x79BB;&#xFF09;, or <em>l1</em>), cosine distance(&#x4F59;&#x5F26;&#x8DDD;&#x79BB;),</p>
<blockquote>
<p>&#x6216;&#x8005;&#x4EFB;&#x4F55;&#x9884;&#x5148;&#x8BA1;&#x7B97;&#x7684; affinity matrix&#xFF08;&#x4EB2;&#x548C;&#x5EA6;&#x77E9;&#x9635;&#xFF09;.</p>
</blockquote>
<ul>
<li><em>l1</em> distance &#x6709;&#x5229;&#x4E8E;&#x7A00;&#x758F;&#x7279;&#x5F81;&#x6216;&#x8005;&#x7A00;&#x758F;&#x566A;&#x58F0;: &#x4F8B;&#x5982;&#x5F88;&#x591A;&#x7279;&#x5F81;&#x90FD;&#x662F;0&#xFF0C;&#x5C31;&#x60F3;&#x5728;&#x6587;&#x672C;&#x6316;&#x6398;&#x4E2D;&#x4F7F;&#x7528; rare words &#x4E00;&#x6837;&#x3002;</li>
<li><em>cosine</em> distance &#x975E;&#x5E38;&#x6709;&#x8DA3;&#x56E0;&#x4E3A;&#x5B83;&#x5BF9;&#x5168;&#x5C40;&#x653E;&#x7F29;&#x662F;&#x4E00;&#x6837;&#x7684;&#x3002;</li>
</ul>
<p>&#x9009;&#x62E9;&#x5EA6;&#x91CF;&#x6807;&#x51C6;&#x7684;&#x65B9;&#x9488;&#x662F;&#x4F7F;&#x5F97;&#x4E0D;&#x540C;&#x7C7B;&#x6837;&#x672C;&#x4E4B;&#x95F4;&#x8DDD;&#x79BB;&#x6700;&#x5927;&#x5316;&#xFF0C;&#x5E76;&#x4E14;&#x6700;&#x5C0F;&#x5316;&#x540C;&#x7C7B;&#x6837;&#x672C;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#x3002;</p>
<p><a href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img src="img/423f64b70bdfeba3566e0bbcca01c277.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_agglomerative_clustering_metrics_0051.png"></a> <a href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img src="img/5a5de287d8a2c74dd12f86219cc19697.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_agglomerative_clustering_metrics_0061.png"></a> <a href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img src="img/27449ee75d40c9391b04e2ca48c4d83b.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_agglomerative_clustering_metrics_0071.png"></a></p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html#sphx-glr-auto-examples-cluster-plot-agglomerative-clustering-metrics-py">Agglomerative clustering with different metrics</a></li>
</ul>
<h2 id="237-dbscan">2.3.7. DBSCAN</h2>
<p>The <a href="generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code>DBSCAN</code></a> &#x7B97;&#x6CD5;&#x5C06;&#x805A;&#x7C7B;&#x89C6;&#x4E3A;&#x88AB;&#x4F4E;&#x5BC6;&#x5EA6;&#x533A;&#x57DF;&#x5206;&#x9694;&#x7684;&#x9AD8;&#x5BC6;&#x5EA6;&#x533A;&#x57DF;&#x3002;&#x7531;&#x4E8E;&#x8FD9;&#x4E2A;&#x76F8;&#x5F53;&#x666E;&#x904D;&#x7684;&#x89C2;&#x70B9;&#xFF0C; DBSCAN&#x53D1;&#x73B0;&#x7684;&#x805A;&#x7C7B;&#x53EF;&#x4EE5;&#x662F;&#x4EFB;&#x4F55;&#x5F62;&#x72B6;&#x7684;&#xFF0C;&#x4E0E;&#x5047;&#x8BBE;&#x805A;&#x7C7B;&#x662F; convex shaped &#x7684; K-means &#x76F8;&#x53CD;&#x3002; DBSCAN &#x7684;&#x6838;&#x5FC3;&#x6982;&#x5FF5;&#x662F; <em>core samples</em>, &#x662F;&#x6307;&#x4F4D;&#x4E8E;&#x9AD8;&#x5BC6;&#x5EA6;&#x533A;&#x57DF;&#x7684;&#x6837;&#x672C;&#x3002; &#x56E0;&#x6B64;&#x4E00;&#x4E2A;&#x805A;&#x7C7B;&#x662F;&#x4E00;&#x7EC4;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF0C;&#x6BCF;&#x4E2A;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x5F7C;&#x6B64;&#x9760;&#x8FD1;&#xFF08;&#x901A;&#x8FC7;&#x4E00;&#x5B9A;&#x8DDD;&#x79BB;&#x5EA6;&#x91CF;&#x6D4B;&#x91CF;&#xFF09; &#x548C;&#x4E00;&#x7EC4;&#x63A5;&#x8FD1;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x7684;&#x975E;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF08;&#x4F46;&#x672C;&#x8EAB;&#x4E0D;&#x662F;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF09;&#x3002;&#x7B97;&#x6CD5;&#x4E2D;&#x7684;&#x4E24;&#x4E2A;&#x53C2;&#x6570;, <code>min_samples</code> &#x548C; <code>eps</code>,&#x6B63;&#x5F0F;&#x7684;&#x5B9A;&#x4E49;&#x4E86;&#x6211;&#x4EEC;&#x6240;&#x8BF4;&#x7684; <a href="#id16">*</a>dense*&#xFF08;&#x7A20;&#x5BC6;&#xFF09;&#x3002;&#x8F83;&#x9AD8;&#x7684; <code>min_samples</code> &#x6216;&#x8005;</p>
<blockquote>
<p>&#x8F83;&#x4F4E;&#x7684; <a href="#id18">``</a>eps``&#x8868;&#x793A;&#x5F62;&#x6210;&#x805A;&#x7C7B;&#x6240;&#x9700;&#x7684;&#x8F83;&#x9AD8;&#x5BC6;&#x5EA6;&#x3002;</p>
</blockquote>
<p>&#x66F4;&#x6B63;&#x5F0F;&#x7684;,&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x662F;&#x6307;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x6837;&#x672C;&#xFF0C;&#x5B58;&#x5728; <code>min_samples</code> &#x4E2A;&#x5176;&#x4ED6;&#x6837;&#x672C;&#x5728; <code>eps</code> &#x8DDD;&#x79BB;&#x8303;&#x56F4;&#x5185;&#xFF0C;&#x8FD9;&#x4E9B;&#x6837;&#x672C;&#x88AB;&#x5B9A;&#x4E3A;&#x4E3A;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x7684;&#x90BB;&#x5C45; <em>neighbors</em> &#x3002;&#x8FD9;&#x544A;&#x8BC9;&#x6211;&#x4EEC;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x5728;&#x5411;&#x91CF;&#x7A7A;&#x95F4;&#x7A20;&#x5BC6;&#x7684;&#x533A;&#x57DF;&#x3002; &#x4E00;&#x4E2A;&#x805A;&#x7C7B;&#x662F;&#x4E00;&#x4E2A;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x7684;&#x96C6;&#x5408;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x9012;&#x5F52;&#x6765;&#x6784;&#x5EFA;&#xFF0C;&#x9009;&#x53D6;&#x4E00;&#x4E2A;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF0C;&#x67E5;&#x627E;&#x5B83;&#x6240;&#x6709;&#x7684; neighbors &#xFF08;&#x90BB;&#x5C45;&#x6837;&#x672C;&#xFF09; &#x4E2D;&#x7684;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF0C;&#x7136;&#x540E;&#x67E5;&#x627E; <em>their</em> &#xFF08;&#x65B0;&#x83B7;&#x53D6;&#x7684;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF09;&#x7684; neighbors &#xFF08;&#x90BB;&#x5C45;&#x6837;&#x672C;&#xFF09;&#x4E2D;&#x7684;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF0C;&#x9012;&#x5F52;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x3002; &#x805A;&#x7C7B;&#x4E2D;&#x8FD8;&#x5177;&#x6709;&#x4E00;&#x7EC4;&#x975E;&#x6838;&#x5FC3;&#x6837;&#x672C;&#xFF0C;&#x5B83;&#x4EEC;&#x662F;&#x96C6;&#x7FA4;&#x4E2D;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x7684;&#x90BB;&#x5C45;&#x7684;&#x6837;&#x672C;&#xFF0C;&#x4F46;&#x672C;&#x8EAB;&#x5E76;&#x4E0D;&#x662F;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x3002; &#x663E;&#x7136;&#xFF0C;&#x8FD9;&#x4E9B;&#x6837;&#x672C;&#x4F4D;&#x4E8E;&#x805A;&#x7C7B;&#x7684;&#x8FB9;&#x7F18;&#x3002;</p>
<pre><code class="lang-py">&#x6839;&#x636E;&#x5B9A;&#x4E49;&#xFF0C;&#x4EFB;&#x4F55;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x90FD;&#x662F;&#x805A;&#x7C7B;&#x7684;&#x4E00;&#x90E8;&#x5206;&#xFF0C;&#x4EFB;&#x4F55;&#x4E0D;&#x662F;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x5E76;&#x4E14;&#x548C;&#x4EFB;&#x610F;&#x4E00;&#x4E2A;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x8DDD;&#x79BB;&#x90FD;&#x5927;&#x4E8E;
</code></pre>
<p><code>eps</code> &#x7684;&#x6837;&#x672C;&#x5C06;&#x88AB;&#x89C6;&#x4E3A;&#x5F02;&#x5E38;&#x503C;&#x3002;</p>
<p>&#x5728;&#x4E0B;&#x56FE;&#x4E2D;&#xFF0C;&#x989C;&#x8272;&#x8868;&#x793A;&#x805A;&#x7C7B;&#x6210;&#x5458;&#x5C5E;&#x6027;&#xFF0C;&#x5927;&#x5706;&#x5708;&#x8868;&#x793A;&#x7B97;&#x6CD5;&#x53D1;&#x73B0;&#x7684;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x3002; &#x8F83;&#x5C0F;&#x7684;&#x5708;&#x5B50;&#x662F;&#x4ECD;&#x7136;&#x662F;&#x7FA4;&#x96C6;&#x7684; &#x4E00;&#x90E8;&#x5206;&#x7684;&#x975E;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x3002; &#x6B64;&#x5916;&#xFF0C;&#x5F02;&#x5E38;&#x503C;&#x7531;&#x4E0B;&#x9762;&#x7684;&#x9ED1;&#x70B9;&#x8868;&#x793A;&#x3002;</p>
<p><strong><a href="../auto_examples/cluster/plot_dbscan.html"><img src="img/9997b300f697e018f955724f7106ad09.jpg" alt="dbscan_results"></a></strong></p>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py">Demo of DBSCAN clustering algorithm</a></li>
</ul>
<p>&#x5B9E;&#x73B0;</p>
<p>DBSCAN &#x7B97;&#x6CD5;&#x662F;&#x5177;&#x6709;&#x786E;&#x5B9A;&#x6027;&#x7684;&#xFF0C;&#x5F53;&#x4EE5;&#x76F8;&#x540C;&#x7684;&#x987A;&#x5E8F;&#x7ED9;&#x51FA;&#x76F8;&#x540C;&#x7684;&#x6570;&#x636E;&#x65F6;&#x603B;&#x662F;&#x5F62;&#x6210;&#x76F8;&#x540C;&#x7684;&#x805A;&#x7C7B;&#x3002; &#x7136;&#x800C;&#xFF0C;&#x5F53;&#x4EE5;&#x4E0D;&#x540C;&#x7684;&#x987A;&#x5E8F;&#x63D0;&#x4F9B;&#x6570;&#x636E;&#x65F6;&#x805A;&#x7C7B;&#x7684;&#x7ED3;&#x679C;&#x53EF;&#x80FD;&#x4E0D;&#x76F8;&#x540C;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x5373;&#x4F7F;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x603B;&#x662F;&#x88AB; &#x5206;&#x914D;&#x7ED9;&#x76F8;&#x540C;&#x7684;&#x805A;&#x7C7B;&#xFF0C;&#x8FD9;&#x4E9B;&#x96C6;&#x7FA4;&#x7684;&#x6807;&#x7B7E;&#x5C06;&#x53D6;&#x51B3;&#x4E8E;&#x6570;&#x636E;&#x4E2D;&#x9047;&#x5230;&#x8FD9;&#x4E9B;&#x6837;&#x672C;&#x7684;&#x987A;&#x5E8F;&#x3002;&#x7B2C;&#x4E8C;&#x4E2A;&#x66F4;&#x91CD; &#x8981;&#x7684;&#x662F;&#xFF0C;&#x975E;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x7684;&#x805A;&#x7C7B;&#x53EF;&#x80FD;&#x56E0;&#x6570;&#x636E;&#x987A;&#x5E8F;&#x800C;&#x6709;&#x6240;&#x4E0D;&#x540C;&#x3002; &#x5F53;&#x4E00;&#x4E2A;&#x975E;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x8DDD;&#x79BB;&#x4E24;&#x4E2A;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x7684;&#x8DDD;&#x79BB;&#x90FD;&#x5C0F;&#x4E8E; <code>eps</code> &#x65F6;&#xFF0C;&#x5C31;&#x4F1A;&#x53D1;&#x751F;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x3002; &#x901A;&#x8FC7;&#x4E09;&#x89D2;&#x4E0D;&#x7B49;&#x5F0F;&#x53EF;&#x77E5;&#xFF0C;&#x8FD9;&#x4E24;&#x4E2A;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x8DDD;&#x79BB;&#x4E00;&#x5B9A;&#x5927;&#x4E8E; <code>eps</code> &#x6216;&#x8005;&#x5904;&#x4E8E;&#x540C;&#x4E00;&#x4E2A;&#x805A;&#x7C7B;&#x4E2D;&#x3002; &#x975E;&#x6838;&#x5FC3;&#x6837;&#x672C;&#x5C06;&#x88AB;&#x975E;&#x914D;&#x5230;&#x9996;&#x5148;&#x67E5;&#x627E;&#x5230;&#x6539;&#x6837;&#x672C;&#x7684;&#x7C7B;&#x522B;&#xFF0C;&#x56E0;&#x6B64;&#x7ED3;&#x679C;&#x5C06;&#x53D6;&#x51B3;&#x4E8E;&#x6570;&#x636E;&#x7684;&#x987A;&#x5E8F;&#x3002;</p>
<p>&#x5F53;&#x524D;&#x7248;&#x672C;&#x4F7F;&#x7528; ball trees &#x548C; kd-trees &#x6765;&#x786E;&#x5B9A;&#x9886;&#x57DF;&#xFF0C;&#x8FD9;&#x6837;&#x907F;&#x514D;&#x4E86;&#x8BA1;&#x7B97;&#x5168;&#x90E8;&#x7684;&#x8DDD;&#x79BB;&#x77E9;&#x9635; &#xFF08;0.14 &#x4E4B;&#x524D;&#x7684; scikit-learn &#x7248;&#x672C;&#x8BA1;&#x7B97;&#x5168;&#x90E8;&#x7684;&#x8DDD;&#x79BB;&#x77E9;&#x9635;&#xFF09;&#x3002;&#x4FDD;&#x7559;&#x4F7F;&#x7528; custom metrics &#xFF08;&#x81EA;&#x5B9A;&#x4E49;&#x6307;&#x6807;&#xFF09;&#x7684;&#x53EF;&#x80FD;&#x6027;&#x3002;&#x7EC6;&#x8282;&#x8BF7;&#x53C2;&#x7167; <code>NearestNeighbors</code>&#x3002;</p>
<p>&#x5927;&#x91CF;&#x6837;&#x672C;&#x7684;&#x5185;&#x5B58;&#x6D88;&#x8017;</p>
<p>&#x9ED8;&#x8BA4;&#x7684;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#x5E76;&#x6CA1;&#x6709;&#x5145;&#x5206;&#x5229;&#x7528;&#x5185;&#x5B58;&#xFF0C;&#x56E0;&#x4E3A;&#x5728;&#x4E0D;&#x4F7F;&#x7528; kd-trees &#x6216;&#x8005; ball-trees &#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x6784;&#x5EFA;&#x4E00;&#x4E2A; &#x5B8C;&#x6574;&#x7684;&#x76F8;&#x4F3C;&#x5EA6;&#x77E9;&#x9635;&#xFF08;e.g. &#x4F7F;&#x7528;&#x7A00;&#x758F;&#x77E9;&#x9635;&#xFF09;&#x3002;&#x8FD9;&#x4E2A;&#x77E9;&#x9635;&#x5C06;&#x6D88;&#x8017; n^2 &#x4E2A;&#x6D6E;&#x70B9;&#x6570;&#x3002; &#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x7684;&#x51E0;&#x79CD;&#x673A;&#x5236;:</p>
<ul>
<li><p>A sparse radius neighborhood graph &#xFF08;&#x7A00;&#x758F;&#x534A;&#x5F84;&#x90BB;&#x57DF;&#x56FE;&#xFF09;(&#x5176;&#x4E2D;&#x7F3A;&#x5C11;&#x6761;&#x76EE;&#x88AB;&#x5047;&#x5B9A;&#x4E3A;&#x8DDD;&#x79BB;&#x8D85;&#x51FA;eps) &#x53EF;&#x4EE5;&#x4EE5;&#x9AD8;&#x6548;&#x7684;&#x65B9;&#x5F0F;&#x9884;&#x5148;&#x7F16;&#x8BD1;&#xFF0C;&#x5E76;&#x4E14;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; <code>metric=&apos;precomputed&apos;</code> &#x6765;&#x8FD0;&#x884C; dbscan&#x3002;</p>
</li>
<li><p>&#x6570;&#x636E;&#x53EF;&#x4EE5;&#x538B;&#x7F29;&#xFF0C;&#x5F53;&#x6570;&#x636E;&#x4E2D;&#x5B58;&#x5728;&#x51C6;&#x786E;&#x7684;&#x91CD;&#x590D;&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x5220;&#x9664;&#x8FD9;&#x4E9B;&#x91CD;&#x590D;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x6216;&#x8005;&#x4F7F;&#x7528;BIRCH&#x3002; &#x4EFB;&#x4F55;&#x3002;&#x7136;&#x540E;&#x4EC5;&#x9700;&#x8981;&#x4F7F;&#x7528;&#x76F8;&#x5BF9;&#x5C11;&#x91CF;&#x7684;&#x6837;&#x672C;&#x6765;&#x8868;&#x793A;&#x5927;&#x91CF;&#x7684;&#x70B9;&#x3002;&#x5F53;&#x8BAD;&#x7EC3;DBSCAN&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x63D0;&#x4F9B;&#x4E00;&#x4E2A;</p>
<p>&gt; <code>sample_weight</code> &#x53C2;&#x6570;&#x3002;</p>
</li>
</ul>
<p>&#x5F15;&#x7528;:</p>
<ul>
<li>&#x201C;A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise&#x201D; Ester, M., H. P. Kriegel, J. Sander, and X. Xu, In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining, Portland, OR, AAAI Press, pp. 226&#x2013;231. 1996</li>
</ul>
<h2 id="238-birch">2.3.8. Birch</h2>
<p>The <a href="generated/sklearn.cluster.Birch.html#sklearn.cluster.Birch" title="sklearn.cluster.Birch"><code>Birch</code></a> &#x4E3A;&#x63D0;&#x4F9B;&#x7684;&#x6570;&#x636E;&#x6784;&#x5EFA;&#x4E00;&#x9897; Characteristic Feature Tree (CFT&#xFF0C;&#x805A;&#x7C7B;&#x7279;&#x5F81;&#x6811;)&#x3002; &#x6570;&#x636E;&#x5B9E;&#x8D28;&#x4E0A;&#x662F;&#x88AB;&#x6709;&#x635F;&#x538B;&#x7F29;&#x6210;&#x4E00;&#x7EC4; Characteristic Feature nodes (CF Nodes&#xFF0C;&#x805A;&#x7C7B;&#x7279;&#x5F81;&#x8282;&#x70B9;)&#x3002; CF Nodes &#x4E2D;&#x6709;&#x4E00;&#x90E8;&#x5206;&#x5B50;&#x805A;&#x7C7B;&#x88AB;&#x79F0;&#x4E3A; Characteristic Feature subclusters (CF Subclusters)&#xFF0C; &#x5E76;&#x4E14;&#x8FD9;&#x4E9B;&#x4F4D;&#x4E8E;&#x975E;&#x7EC8;&#x7AEF;&#x4F4D;&#x7F6E;&#x7684;CF Subclusters &#x53EF;&#x4EE5;&#x62E5;&#x6709; CF Nodes &#x4F5C;&#x4E3A;&#x5B69;&#x5B50;&#x8282;&#x70B9;&#x3002;</p>
<p>CF Subclusters &#x4FDD;&#x5B58;&#x7528;&#x4E8E;&#x805A;&#x7C7B;&#x7684;&#x5FC5;&#x8981;&#x4FE1;&#x606F;&#xFF0C;&#x9632;&#x6B62;&#x5C06;&#x6574;&#x4E2A;&#x8F93;&#x5165;&#x6570;&#x636E;&#x4FDD;&#x5B58;&#x5728;&#x5185;&#x5B58;&#x4E2D;&#x3002; &#x8FD9;&#x4E9B;&#x4FE1;&#x606F;&#x5305;&#x62EC;:</p>
<ul>
<li>Number of samples in a subcluster&#xFF08;&#x5B50;&#x805A;&#x7C7B;&#x4E2D;&#x6837;&#x672C;&#x6570;&#xFF09;.</li>
<li>Linear Sum - A n-dimensional vector holding the sum of all samples&#xFF08;&#x4FDD;&#x5B58;&#x6240;&#x6709;&#x6837;&#x672C;&#x548C;&#x7684;n&#x7EF4;&#x5411;&#x91CF;&#xFF09;</li>
<li>Squared Sum - Sum of the squared L2 norm of all samples&#xFF08;&#x6240;&#x6709;&#x6837;&#x672C;&#x7684;L2 norm&#x7684;&#x5E73;&#x65B9;&#x548C;&#xFF09;.</li>
<li>Centroids - To avoid recalculation linear sum / n_samples&#xFF08;&#x4E3A;&#x4E86;&#x9632;&#x6B62;&#x91CD;&#x590D;&#x8BA1;&#x7B97; linear sum / n_samples&#xFF09;.</li>
<li>Squared norm of the centroids&#xFF08;&#x8D28;&#x5FC3;&#x7684; Squared norm &#xFF09;.</li>
</ul>
<p>Birch &#x7B97;&#x6CD5;&#x6709;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#xFF0C;&#x5373; threshold &#xFF08;&#x9608;&#x503C;&#xFF09;&#x548C; branching factor &#x5206;&#x652F;&#x56E0;&#x5B50;&#x3002;Branching factor &#xFF08;&#x5206;&#x652F;&#x56E0;&#x5B50;&#xFF09; &#x9650;&#x5236;&#x4E86;&#x4E00;&#x4E2A;&#x8282;&#x70B9;&#x4E2D;&#x7684;&#x5B50;&#x96C6;&#x7FA4;&#x7684;&#x6570;&#x91CF; &#xFF0C;threshold &#xFF08;&#x7C07;&#x534A;&#x5F84;&#x9608;&#x503C;&#xFF09;&#x9650;&#x5236;&#x4E86;&#x65B0;&#x52A0;&#x5165;&#x7684;&#x6837;&#x672C;&#x548C;&#x5B58;&#x5728;&#x4E0E;&#x73B0;&#x6709;&#x5B50;&#x96C6;&#x7FA4;&#x4E2D;&#x6837;&#x672C;&#x7684;&#x6700;&#x5927;&#x8DDD;&#x79BB;&#x3002;</p>
<p>&#x8BE5;&#x7B97;&#x6CD5;&#x53EF;&#x4EE5;&#x89C6;&#x4E3A;&#x5C06;&#x4E00;&#x4E2A;&#x5B9E;&#x4F8B;&#x6216;&#x8005;&#x6570;&#x636E;&#x7B80;&#x5316;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x5C06;&#x8F93;&#x5165;&#x7684;&#x6570;&#x636E;&#x7B80;&#x5316;&#x5230;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4ECE;CFT&#x7684;&#x53F6;&#x5B50;&#x7ED3;&#x70B9;&#x4E2D;&#x83B7;&#x53D6;&#x7684;&#x4E00;&#x7EC4;&#x5B50;&#x805A;&#x7C7B;&#x3002; &#x8FD9;&#x79CD;&#x7B80;&#x5316;&#x7684;&#x6570;&#x636E;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x5C06;&#x5176;&#x9988;&#x9001;&#x5230;global clusterer&#xFF08;&#x5168;&#x5C40;&#x805A;&#x7C7B;&#xFF09;&#x6765;&#x8FDB;&#x4E00;&#x6B65;&#x5904;&#x7406;&#x3002;Global clusterer&#xFF08;&#x5168;&#x5C40;&#x805A;&#x7C7B;&#xFF09;&#x53EF;&#x4EE5; &#x901A;&#x8FC7; <a href="#id21">``</a>n_clusters``&#x6765;&#x8BBE;&#x7F6E;&#x3002;</p>
<p>&#x5982;&#x679C; <code>n_clusters</code> &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; None&#xFF0C;&#x5C06;&#x76F4;&#x63A5;&#x8BFB;&#x53D6;&#x53F6;&#x5B50;&#x7ED3;&#x70B9;&#x4E2D;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#xFF0C;&#x5426;&#x5219;&#xFF0C;global clustering&#xFF08;&#x5168;&#x5C40;&#x805A;&#x7C7B;&#xFF09; &#x5C06;&#x9010;&#x6B65;&#x6807;&#x8BB0;&#x4ED6;&#x7684; subclusters &#x5230; global clusters (labels) &#x4E2D;&#xFF0C;&#x6837;&#x672C;&#x5C06;&#x88AB;&#x6620;&#x5C04;&#x5230; &#x8DDD;&#x79BB;&#x6700;&#x8FD1;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x7684;global label&#x4E2D;&#x3002;</p>
<p><strong>&#x7B97;&#x6CD5;&#x63CF;&#x8FF0;:</strong></p>
<ul>
<li>&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x6837;&#x672C;&#x4F5C;&#x4E3A;&#x4E00;&#x4E2A;CF Node &#x88AB;&#x63D2;&#x5165;&#x5230; CF Tree &#x7684;&#x6839;&#x8282;&#x70B9;&#x3002;&#x7136;&#x540E;&#x5C06;&#x5176;&#x5408;&#x5E76;&#x5230;&#x6839;&#x8282;&#x70B9;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x4E2D;&#x53BB;&#xFF0C;&#x4F7F;&#x5F97;&#x5408;&#x5E76;&#x540E;&#x5B50;&#x805A;&#x7C7B; &#x62E5;&#x6709;&#x6700;&#x5C0F;&#x7684;&#x534A;&#x5F84;&#xFF0C;&#x5B50;&#x805A;&#x7C7B;&#x7684;&#x9009;&#x53D6;&#x53D7; threshold &#x548C; branching factor &#x7684;&#x7EA6;&#x675F;&#x3002;&#x5982;&#x679C;&#x5B50;&#x805A;&#x7C7B;&#x4E5F;&#x62E5;&#x6709;&#x5B69;&#x5B50;&#x8282;&#x70B9;&#xFF0C;&#x5219;&#x91CD;&#x590D;&#x6267; &#x884C;&#x8FD9;&#x4E2A;&#x6B65;&#x9AA4;&#x76F4;&#x5230;&#x5230;&#x8FBE;&#x53F6;&#x5B50;&#x7ED3;&#x70B9;&#x3002;&#x5728;&#x53F6;&#x5B50;&#x7ED3;&#x70B9;&#x4E2D;&#x627E;&#x5230;&#x6700;&#x8FD1;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x4EE5;&#x540E;&#xFF0C;&#x9012;&#x5F52;&#x7684;&#x66F4;&#x65B0;&#x8FD9;&#x4E2A;&#x5B50;&#x805A;&#x7C7B;&#x53CA;&#x5176;&#x7236;&#x805A;&#x7C7B;&#x7684;&#x5C5E;&#x6027;&#x3002;</li>
<li>&#x5982;&#x679C;&#x5408;&#x5E76;&#x4E86;&#x65B0;&#x6837;&#x672C;&#x548C;&#x6700;&#x8FD1;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x83B7;&#x5F97;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x534A;&#x5F84;&#x5927;&#x7EA6;square of the threshold&#xFF08;&#x9608;&#x503C;&#x7684;&#x5E73;&#x65B9;&#xFF09;&#xFF0C; &#x5E76;&#x4E14;&#x5B50;&#x805A;&#x7C7B;&#x7684;&#x6570;&#x91CF;&#x5927;&#x4E8E;branching factor&#xFF08;&#x5206;&#x652F;&#x56E0;&#x5B50;&#xFF09;&#xFF0C;&#x5219;&#x5C06;&#x4E3A;&#x8FD9;&#x4E2A;&#x6837;&#x672C;&#x5206;&#x914D;&#x4E00;&#x4E2A;&#x4E34;&#x65F6;&#x7A7A;&#x95F4;&#x3002; &#x6700;&#x8FDC;&#x7684;&#x4E24;&#x4E2A;&#x5B50;&#x805A;&#x7C7B;&#x88AB;&#x9009;&#x53D6;&#xFF0C;&#x5269;&#x4E0B;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x6309;&#x7167;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#x5206;&#x4E3A;&#x4E24;&#x7EC4;&#x4F5C;&#x4E3A;&#x88AB;&#x9009;&#x53D6;&#x7684;&#x4E24;&#x4E2A;&#x5B50;&#x805A;&#x7C7B;&#x7684;&#x5B69;&#x5B50;&#x8282;&#x70B9;&#x3002;</li>
<li>If this split node has a parent subcluster and there is room for a new subcluster, then the parent is split into two. If there is no room, then this node is again split into two and the process is continued recursively, till it reaches the root. &#x5982;&#x679C;&#x62C6;&#x5206;&#x7684;&#x8282;&#x70B9;&#x6709;&#x4E00;&#x4E2A; parent subcluster &#xFF0C;&#x5E76;&#x4E14;&#x6709;&#x4E00;&#x4E2A;&#x5BB9;&#x7EB3;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x7684;&#x7A7A;&#x95F4;&#xFF0C;&#x90A3;&#x4E48;&#x7236;&#x805A;&#x7C7B;&#x62C6;&#x5206;&#x6210;&#x4E24;&#x4E2A;&#x3002; &#x5982;&#x679C;&#x6CA1;&#x6709;&#x7A7A;&#x95F4;&#x5BB9;&#x7EB3;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x805A;&#x7C7B;&#xFF0C;&#x90A3;&#x4E48;&#x8FD9;&#x4E2A;&#x8282;&#x70B9;&#x5C06;&#x88AB;&#x518D;&#x6B21;&#x62C6;&#x5206;&#xFF0C;&#x4F9D;&#x6B21;&#x5411;&#x4E0A;&#x68C0;&#x67E5;&#x7236;&#x8282;&#x70B9;&#x662F;&#x5426;&#x9700;&#x8981;&#x5206;&#x88C2;&#xFF0C; &#x5982;&#x679C;&#x9700;&#x8981;&#x6309;&#x53F6;&#x5B50;&#x8282;&#x70B9;&#x65B9;&#x5F0F;&#x76F8;&#x540C;&#x5206;&#x88C2;&#x3002;</li>
</ul>
<p><strong>Birch or MiniBatchKMeans?</strong></p>
<blockquote>
<ul>
<li>Birch &#x5728;&#x9AD8;&#x7EF4;&#x6570;&#x636E;&#x4E0A;&#x8868;&#x73B0;&#x4E0D;&#x597D;&#x3002;&#x4E00;&#x6761;&#x7ECF;&#x9A8C;&#x6CD5;&#x5219;&#xFF0C;&#x5982;&#x679C; <code>n_features</code> &#x5927;&#x4E8E;20&#xFF0C;&#x901A;&#x5E38;&#x4F7F;&#x7528; MiniBatchKMeans &#x66F4;&#x597D;&#x3002;</li>
<li>&#x5982;&#x679C;&#x9700;&#x8981;&#x51CF;&#x5C11;&#x6570;&#x636E;&#x5B9E;&#x4F8B;&#x7684;&#x6570;&#x91CF;&#xFF0C;&#x6216;&#x8005;&#x5982;&#x679C;&#x9700;&#x8981;&#x5927;&#x91CF;&#x7684;&#x5B50;&#x805A;&#x7C7B;&#x4F5C;&#x4E3A;&#x9884;&#x5904;&#x7406;&#x6B65;&#x9AA4;&#x6216;&#x8005;&#x5176;&#x4ED6;&#xFF0C; Birch &#x6BD4; MiniBatchKMeans &#x66F4;&#x6709;&#x7528;&#x3002;</li>
</ul>
</blockquote>
<p><strong>How to use partial_fit?</strong></p>
<p>&#x4E3A;&#x4E86;&#x907F;&#x514D;&#x5BF9; global clustering &#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x6BCF;&#x6B21;&#x8C03;&#x7528;&#x5EFA;&#x8BAE;&#x4F7F;&#x7528; <code>partial_fit</code> &#x3002;</p>
<blockquote>
<ol>
<li>&#x521D;&#x59CB;&#x5316; <code>n_clusters=None</code> &#x3002;</li>
<li>&#x901A;&#x8FC7;&#x591A;&#x6B21;&#x8C03;&#x7528; partial_fit &#x8BAD;&#x7EC3;&#x6240;&#x4EE5;&#x7684;&#x6570;&#x636E;&#x3002;</li>
<li>&#x8BBE;&#x7F6E; <code>n_clusters</code> &#x4E3A;&#x6240;&#x9700;&#x503C;&#xFF0C;&#x901A;&#x8FC7;&#x4F7F;&#x7528; <code>brc.set_params(n_clusters=n_clusters)</code> &#x3002;</li>
<li>&#x6700;&#x540E;&#x4E0D;&#x9700;&#x8981;&#x53C2;&#x6570;&#x8C03;&#x7528; <code>partial_fit</code> , &#x4F8B;&#x5982; <code>brc.partial_fit()</code> &#x6267;&#x884C;&#x5168;&#x5C40;&#x805A;&#x7C7B;&#x3002;</li>
</ol>
</blockquote>
<p><a href="../auto_examples/cluster/plot_birch_vs_minibatchkmeans.html"><img src="img/d9ac7cfff134bd66e853020e32d76f5c.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_birch_vs_minibatchkmeans_0011.png"></a></p>
<p>&#x53C2;&#x8003;:</p>
<ul>
<li>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. <a href="http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf" target="_blank">http://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf</a></li>
<li>Roberto Perdisci JBirch - Java implementation of BIRCH clustering algorithm <a href="https://code.google.com/archive/p/jbirch" target="_blank">https://code.google.com/archive/p/jbirch</a></li>
</ul>
<h2 id="239-&#x805A;&#x7C7B;&#x6027;&#x80FD;&#x5EA6;&#x91CF;">2.3.9. &#x805A;&#x7C7B;&#x6027;&#x80FD;&#x5EA6;&#x91CF;</h2>
<p>&#x5EA6;&#x91CF;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#x7684;&#x6027;&#x80FD;&#x4E0D;&#x662F;&#x7B80;&#x5355;&#x7684;&#x7EDF;&#x8BA1;&#x9519;&#x8BEF;&#x7684;&#x6570;&#x91CF;&#x6216;&#x8BA1;&#x7B97;&#x76D1;&#x7763;&#x5206;&#x7C7B;&#x7B97;&#x6CD5;&#x4E2D;&#x7684; precision &#xFF08;&#x51C6;&#x786E;&#x7387;&#xFF09;&#x548C; recall &#xFF08;&#x53EC;&#x56DE;&#x7387;&#xFF09;&#x3002; &#x7279;&#x522B;&#x5730;&#xFF0C;&#x4EFB;&#x4F55; evaluation metric &#xFF08;&#x5EA6;&#x91CF;&#x6307;&#x6807;&#xFF09;&#x4E0D;&#x5E94;&#x8BE5;&#x8003;&#x8651;&#x5230; cluster labels &#xFF08;&#x7C07;&#x6807;&#x7B7E;&#xFF09;&#x7684;&#x7EDD;&#x5BF9;&#x503C;&#xFF0C;&#x800C;&#x662F;&#x5982;&#x679C;&#x8FD9;&#x4E2A;&#x7C07;&#x5B9A;&#x4E49;&#x7C7B;&#x4F3C;&#x4E8E;&#x67D0;&#x4E9B; ground truth set of classes &#x6216;&#x8005;&#x6EE1;&#x8DB3;&#x67D0;&#x4E9B;&#x5047;&#x8BBE;&#xFF0C;&#x4F7F;&#x5F97;&#x5C5E;&#x4E8E;&#x540C;&#x4E00;&#x4E2A;&#x7C7B;&#x7684;&#x6210;&#x5458;&#x66F4;&#x7C7B;&#x4F3C;&#x4E8E;&#x6839;&#x636E;&#x67D0;&#x4E9B; similarity metric &#xFF08;&#x76F8;&#x4F3C;&#x6027;&#x5EA6;&#x91CF;&#xFF09;&#x7684;&#x4E0D;&#x540C;&#x7C7B;&#x7684;&#x6210;&#x5458;&#x3002;</p>
<h3 id="2391-&#x8C03;&#x6574;&#x540E;&#x7684;-rand-&#x6307;&#x6570;">2.3.9.1. &#x8C03;&#x6574;&#x540E;&#x7684; Rand &#x6307;&#x6570;</h3>
<p>&#x8003;&#x8651;&#x5230; the ground truth class &#x8D4B;&#x503C; <code>labels_true</code> &#x548C;&#x76F8;&#x540C;&#x6837;&#x672C; <code>labels_pred</code> &#x7684;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#x5206;&#x914D;&#x7684;&#x77E5;&#x8BC6;&#xFF0C;<strong>adjusted Rand index</strong> &#x662F;&#x4E00;&#x4E2A;&#x51FD;&#x6570;&#xFF0C;&#x7528;&#x4E8E;&#x6D4B;&#x91CF;&#x4E24;&#x4E2A; assignments &#xFF08;&#x4EFB;&#x52A1;&#xFF09;&#x7684; <strong>similarity&#xFF08;&#x76F8;&#x4F3C;&#x5EA6;&#xFF09;</strong> &#xFF0C;&#x5FFD;&#x7565; permutations &#xFF08;&#x6392;&#x5217;&#xFF09;&#x548C; <strong>with chance normalization&#xFF08;&#x4F7F;&#x7528;&#x673A;&#x4F1A;&#x89C4;&#x8303;&#x5316;&#xFF09;</strong>:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_true = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]

<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_rand_score(labels_true, labels_pred)  
<span class="hljs-number">0.24</span>...
</code></pre>
<p>&#x53EF;&#x4EE5;&#x5728;&#x9884;&#x6D4B;&#x7684;&#x6807;&#x7B7E;&#x4E2D; permute &#xFF08;&#x6392;&#x5217;&#xFF09; 0 &#x548C; 1&#xFF0C;&#x91CD;&#x547D;&#x540D;&#x4E3A; 2 &#x5230; 3&#xFF0C; &#x5F97;&#x5230;&#x76F8;&#x540C;&#x7684;&#x5206;&#x6570;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_rand_score(labels_true, labels_pred)  
<span class="hljs-number">0.24</span>...
</code></pre>
<p>&#x53E6;&#x5916;&#xFF0C; <a href="generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score" title="sklearn.metrics.adjusted_rand_score"><code>adjusted_rand_score</code></a> &#x662F; <strong>symmetric&#xFF08;&#x5BF9;&#x79F0;&#x7684;&#xFF09;</strong> : &#x4EA4;&#x6362;&#x53C2;&#x6570;&#x4E0D;&#x4F1A;&#x6539;&#x53D8; score &#xFF08;&#x5F97;&#x5206;&#xFF09;&#x3002;&#x5B83;&#x53EF;&#x4EE5;&#x4F5C;&#x4E3A; <strong>consensus measure&#xFF08;&#x5171;&#x8BC6;&#x5EA6;&#x91CF;&#xFF09;</strong>:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_rand_score(labels_pred, labels_true)  
<span class="hljs-number">0.24</span>...
</code></pre>
<p>&#x5B8C;&#x7F8E;&#x7684;&#x6807;&#x7B7E;&#x5F97;&#x5206;&#x4E3A; 1.0</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = labels_true[:]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_rand_score(labels_true, labels_pred)
<span class="hljs-number">1.0</span>
</code></pre>
<p>&#x574F; (e.g. independent labelings&#xFF08;&#x72EC;&#x7ACB;&#x6807;&#x7B7E;&#xFF09;) &#x6709;&#x8D1F;&#x6570; &#x6216; &#x63A5;&#x8FD1;&#x4E8E; 0.0 &#x5206;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_true = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_rand_score(labels_true, labels_pred)  
<span class="hljs-number">-0.12</span>...
</code></pre>
<h4 id="23911-&#x4F18;&#x70B9;">2.3.9.1.1. &#x4F18;&#x70B9;</h4>
<ul>
<li><strong>Random (uniform) label assignments have a ARI score close to 0.0&#xFF08;&#x968F;&#x673A;&#xFF08;&#x7EDF;&#x4E00;&#xFF09;&#x6807;&#x7B7E;&#x5206;&#x914D;&#x7684; ARI &#x8BC4;&#x5206;&#x63A5;&#x8FD1;&#x4E8E; 0.0&#xFF09;</strong> &#x5BF9;&#x4E8E; <code>n_clusters</code> &#x548C; <code>n_samples</code> &#x7684;&#x4EFB;&#x4F55;&#x503C;&#xFF08;&#x8FD9;&#x4E0D;&#x662F;&#x539F;&#x59CB;&#x7684; Rand index &#x6216;&#x8005; V-measure &#x7684;&#x60C5;&#x51B5;&#xFF09;&#x3002;</li>
<li><strong>Bounded range&#xFF08;&#x8303;&#x56F4;&#x662F;&#x6709;&#x754C;&#x7684;&#xFF09; [-1, 1]</strong>: negative values &#xFF08;&#x8D1F;&#x503C;&#xFF09;&#x662F;&#x574F;&#x7684; (&#x72EC;&#x7ACB;&#x6027;&#x6807;&#x7B7E;), &#x7C7B;&#x4F3C;&#x7684;&#x805A;&#x7C7B;&#x6709;&#x4E00;&#x4E2A; positive ARI &#xFF08;&#x6B63;&#x7684; ARI&#xFF09;&#xFF0C; 1.0 &#x662F;&#x5B8C;&#x7F8E;&#x7684;&#x5339;&#x914D;&#x5F97;&#x5206;&#x3002;</li>
<li><strong>No assumption is made on the cluster structure&#xFF08;&#x5BF9;&#x7C07;&#x7684;&#x7ED3;&#x6784;&#x4E0D;&#x9700;&#x4F5C;&#x51FA;&#x4EFB;&#x4F55;&#x5047;&#x8BBE;&#xFF09;</strong>: &#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x6BD4;&#x8F83;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF0C;&#x4F8B;&#x5982; k-means&#xFF0C;&#x5176;&#x5047;&#x5B9A; isotropic blob shapes &#x4E0E;&#x53EF;&#x4EE5;&#x627E;&#x5230;&#x5177;&#x6709; &#x201C;folded&#x201D; shapes &#x7684;&#x805A;&#x7C7B;&#x7684; spectral clustering algorithms&#xFF08;&#x8C31;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF09;&#x7684;&#x7ED3;&#x679C;&#x3002;</li>
</ul>
<h4 id="23912-&#x7F3A;&#x70B9;">2.3.9.1.2. &#x7F3A;&#x70B9;</h4>
<ul>
<li><p>&#x4E0E; inertia &#x76F8;&#x53CD;&#xFF0C;<strong>ARI requires knowledge of the ground truth classes&#xFF08;ARI &#x9700;&#x8981; ground truth classes &#x7684;&#x76F8;&#x5173;&#x77E5;&#x8BC6;&#xFF09;</strong> &#xFF0C;&#x800C;&#x5728;&#x5B9E;&#x8DF5;&#x4E2D;&#x51E0;&#x4E4E;&#x4E0D;&#x53EF;&#x7528;&#xFF0C;&#x6216;&#x8005;&#x9700;&#x8981;&#x4EBA;&#x5DE5;&#x6807;&#x6CE8;&#x8005;&#x624B;&#x52A8;&#x5206;&#x914D;&#xFF08;&#x5982;&#x5728;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x73AF;&#x5883;&#x4E2D;&#xFF09;&#x3002;</p>
<p>&#x7136;&#x800C;&#xFF0C;ARI &#x8FD8;&#x53EF;&#x4EE5;&#x5728; purely unsupervised setting &#xFF08;&#x7EAF;&#x7CB9;&#x65E0;&#x76D1;&#x7763;&#x7684;&#x8BBE;&#x7F6E;&#x4E2D;&#xFF09;&#x4F5C;&#x4E3A;&#x53EF;&#x7528;&#x4E8E; &#x805A;&#x7C7B;&#x6A21;&#x578B;&#x9009;&#x62E9;&#xFF08;TODO&#xFF09;&#x7684;&#x5171;&#x8BC6;&#x7D22;&#x5F15;&#x7684;&#x6784;&#x5EFA;&#x5757;&#x3002;</p>
</li>
</ul>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html#sphx-glr-auto-examples-cluster-plot-adjusted-for-chance-measures-py">Adjustment for chance in clustering performance evaluation</a>: &#x5206;&#x6790;&#x6570;&#x636E;&#x96C6;&#x5927;&#x5C0F;&#x5BF9;&#x968F;&#x673A;&#x5206;&#x914D;&#x805A;&#x7C7B;&#x5EA6;&#x91CF;&#x503C;&#x7684;&#x5F71;&#x54CD;&#x3002;</li>
</ul>
<h4 id="23913-&#x6570;&#x5B66;&#x8868;&#x8FBE;">2.3.9.1.3. &#x6570;&#x5B66;&#x8868;&#x8FBE;</h4>
<p>&#x5982;&#x679C; C &#x662F;&#x4E00;&#x4E2A; ground truth class assignment&#xFF08;&#x4EFB;&#x52A1;&#xFF09;&#xFF0C; K &#x662F;&#x7C07;&#x7684;&#x4E2A;&#x6570;&#xFF0C;&#x6211;&#x4EEC;&#x5B9A;&#x4E49; <img src="img/578c95150175e4efdf851fe66d503079.jpg" alt="a"> &#x548C; <img src="img/6ae91fb0f3221b92d2dd4e22204d8008.jpg" alt="b"> &#x5982;:</p>
<ul>
<li><img src="img/578c95150175e4efdf851fe66d503079.jpg" alt="a">, &#x5728; C &#x4E2D;&#x7684;&#x76F8;&#x540C;&#x96C6;&#x5408;&#x7684;&#x4E0E; K &#x4E2D;&#x7684;&#x76F8;&#x540C;&#x96C6;&#x5408;&#x4E2D;&#x7684;&#x5143;&#x7D20;&#x7684;&#x5BF9;&#x6570;</li>
<li><img src="img/6ae91fb0f3221b92d2dd4e22204d8008.jpg" alt="b">, &#x5728; C &#x4E2D;&#x7684;&#x4E0D;&#x540C;&#x96C6;&#x5408;&#x4E0E; K &#x4E2D;&#x7684;&#x4E0D;&#x540C;&#x96C6;&#x5408;&#x4E2D;&#x7684;&#x5143;&#x7D20;&#x7684;&#x5BF9;&#x6570;</li>
</ul>
<p>&#x539F;&#x59CB;&#xFF08;&#x672A;&#x7ECF;&#x8C03;&#x6574;&#xFF09;&#x7684; Rand index &#x5219;&#x7531;&#x4E0B;&#x5F0F;&#x7ED9;&#x51FA;:</p>
<p><img src="img/070018458bf56c0d94293de45828e878.jpg" alt="\text{RI} = \frac{a + b}{C_2^{n_{samples}}}"></p>
<p>&#x5176;&#x4E2D; <img src="img/0ce3ae4e9a8bbd17b08f5fae78d60f21.jpg" alt="C_2^{n_{samples}}"> &#x662F;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x53EF;&#x80FD;&#x7684; pairs &#xFF08;&#x6570;&#x636E;&#x5BF9;&#xFF09;&#x7684;&#x603B;&#x6570;&#xFF08;&#x4E0D;&#x6392;&#x5E8F;&#xFF09;&#x3002;</p>
<p>&#x7136;&#x800C;&#xFF0C;RI &#x8BC4;&#x5206;&#x4E0D;&#x80FD;&#x4FDD;&#x8BC1; random label assignments &#xFF08;&#x968F;&#x673A;&#x6807;&#x7B7E;&#x4EFB;&#x52A1;&#xFF09;&#x5C06;&#x83B7;&#x5F97;&#x63A5;&#x8FD1;&#x96F6;&#x7684;&#x503C;&#xFF08;&#x7279;&#x522B;&#x662F;&#x5982;&#x679C;&#x7C07;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x91C7;&#x6837;&#x6570;&#x91CF;&#x76F8;&#x540C;&#x7684;&#x6570;&#x91CF;&#x7EA7;&#xFF09;&#x3002;</p>
<p>&#x4E3A;&#x4E86;&#x62B5;&#x6D88;&#x8FD9;&#x79CD;&#x5F71;&#x54CD;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x5B9A;&#x4E49; adjusted Rand index &#xFF08;&#x8C03;&#x6574;&#x540E;&#x7684; Rand index&#xFF09;&#x6765; discount&#xFF08;&#x6298;&#x73B0;&#xFF09; &#x968F;&#x673A;&#x6807;&#x7B7E;&#x7684;&#x9884;&#x671F; RI <img src="img/7881dd425f1090aadc25eca46dc0daec.jpg" alt="E[\text{RI}]"> ,&#x5982;&#x4E0B;&#x6240;&#x793A;:</p>
<p><img src="img/8f4f76678eb50ebccaba25e86961ff3e.jpg" alt="\text{ARI} = \frac{\text{RI} - E[\text{RI}]}{\max(\text{RI}) - E[\text{RI}]}"></p>
<p>&#x53C2;&#x8003;</p>
<ul>
<li><a href="http://link.springer.com/article/10.1007%2FBF01908075" target="_blank">Comparing Partitions</a> L. Hubert and P. Arabie, Journal of Classification 1985</li>
<li><a href="https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index" target="_blank">Wikipedia entry for the adjusted Rand index</a></li>
</ul>
<h3 id="2392-&#x57FA;&#x4E8E;-mutual-information-&#xFF08;&#x4E92;&#x4FE1;&#x606F;&#xFF09;&#x7684;&#x5206;&#x6570;">2.3.9.2. &#x57FA;&#x4E8E; Mutual Information &#xFF08;&#x4E92;&#x4FE1;&#x606F;&#xFF09;&#x7684;&#x5206;&#x6570;</h3>
<p>&#x8003;&#x8651;&#x5230; ground truth class assignments &#xFF08;&#x6807;&#x5B9A;&#x8FC7;&#x7684;&#x771F;&#x5B9E;&#x6570;&#x636E;&#x7C7B;&#x5206;&#x914D;&#xFF09; <code>labels_true</code> &#x7684;&#x77E5;&#x8BC6;&#x548C;&#x76F8;&#x540C;&#x6837;&#x672C; <code>labels_pred</code> &#x7684;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#x5206;&#x914D;&#xFF0C; <strong>Mutual Information</strong> &#x662F;&#x6D4B;&#x91CF;&#x4E24;&#x8005; <strong>agreement</strong> &#x5206;&#x914D;&#x7684;&#x51FD;&#x6570;&#xFF0C;&#x5FFD;&#x7565; permutations&#xFF08;&#x6392;&#x5217;&#xFF09;&#x3002; &#x8FD9;&#x79CD;&#x6D4B;&#x91CF;&#x65B9;&#x6848;&#x7684;&#x4E24;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x6807;&#x51C6;&#x5316;&#x7248;&#x672C;&#x53EF;&#x7528;&#xFF0C;<strong>Normalized Mutual Information(NMI)</strong> &#x548C; <strong>Adjusted Mutual Information(AMI)</strong>&#x3002;NMI &#x7ECF;&#x5E38;&#x5728;&#x6587;&#x732E;&#x4E2D;&#x4F7F;&#x7528;&#xFF0C;&#x800C; AMI &#x6700;&#x8FD1;&#x88AB;&#x63D0;&#x51FA;&#xFF0C;&#x5E76;&#x4E14; <strong>normalized against chance</strong>:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_true = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]

<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_mutual_info_score(labels_true, labels_pred)  
<span class="hljs-number">0.22504</span>...
</code></pre>
<p>&#x53EF;&#x4EE5;&#x5728; predicted labels &#xFF08;&#x9884;&#x6D4B;&#x7684;&#x6807;&#x7B7E;&#xFF09;&#x4E2D; permute &#xFF08;&#x6392;&#x5217;&#xFF09; 0 &#x548C; 1, &#x91CD;&#x547D;&#x540D;&#x4E3A; 2 &#x5230; 3 &#x5E76;&#x5F97;&#x5230;&#x76F8;&#x540C;&#x7684;&#x5F97;&#x5206;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_mutual_info_score(labels_true, labels_pred)  
<span class="hljs-number">0.22504</span>...
</code></pre>
<p>&#x5168;&#x90E8;&#x7684;&#xFF0C;<a href="generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score" title="sklearn.metrics.mutual_info_score"><code>mutual_info_score</code></a>, <a href="generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score" title="sklearn.metrics.adjusted_mutual_info_score"><code>adjusted_mutual_info_score</code></a> &#x548C; <a href="generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score" title="sklearn.metrics.normalized_mutual_info_score"><code>normalized_mutual_info_score</code></a> &#x662F; symmetric&#xFF08;&#x5BF9;&#x79F0;&#x7684;&#xFF09;: &#x4EA4;&#x6362;&#x53C2;&#x6570;&#x4E0D;&#x4F1A;&#x66F4;&#x6539;&#x5206;&#x6570;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x5B83;&#x4EEC;&#x53EF;&#x4EE5;&#x7528;&#x4F5C; <strong>consensus measure</strong>:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_mutual_info_score(labels_pred, labels_true)  
<span class="hljs-number">0.22504</span>...
</code></pre>
<p>&#x5B8C;&#x7F8E;&#x6807;&#x7B7E;&#x5F97;&#x5206;&#x662F; 1.0:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = labels_true[:]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_mutual_info_score(labels_true, labels_pred)
<span class="hljs-number">1.0</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.normalized_mutual_info_score(labels_true, labels_pred)
<span class="hljs-number">1.0</span>
</code></pre>
<p>&#x8FD9;&#x5BF9;&#x4E8E; <code>mutual_info_score</code> &#x662F;&#x4E0D;&#x6B63;&#x786E;&#x7684;&#xFF0C;&#x56E0;&#x6B64;&#x66F4;&#x96BE;&#x5224;&#x65AD;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>metrics.mutual_info_score(labels_true, labels_pred)  
<span class="hljs-number">0.69</span>...
</code></pre>
<p>&#x574F;&#x7684; (&#x4F8B;&#x5982; independent labelings&#xFF08;&#x72EC;&#x7ACB;&#x6807;&#x7B7E;&#xFF09;) &#x5177;&#x6709;&#x975E;&#x6B63;&#x5206;&#x6570;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_true = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.adjusted_mutual_info_score(labels_true, labels_pred)  
<span class="hljs-number">-0.10526</span>...
</code></pre>
<h4 id="23921-&#x4F18;&#x70B9;">2.3.9.2.1. &#x4F18;&#x70B9;</h4>
<ul>
<li><strong>Random (uniform) label assignments have a AMI score close to 0.0&#xFF08;&#x968F;&#x673A;&#xFF08;&#x7EDF;&#x4E00;&#xFF09;&#x6807;&#x7B7E;&#x5206;&#x914D;&#x7684;AMI&#x8BC4;&#x5206;&#x63A5;&#x8FD1;0.0&#xFF09;</strong> &#x5BF9;&#x4E8E; <code>n_clusters</code> &#x548C; <code>n_samples</code> &#x7684;&#x4EFB;&#x4F55;&#x503C;&#xFF08;&#x8FD9;&#x4E0D;&#x662F;&#x539F;&#x59CB; Mutual Information &#x6216;&#x8005; V-measure &#x7684;&#x60C5;&#x51B5;&#xFF09;&#x3002;</li>
<li><strong>Bounded range&#xFF08;&#x6709;&#x754C;&#x8303;&#x56F4;&#xFF09; [0, 1]</strong>: &#x63A5;&#x8FD1; 0 &#x7684;&#x503C;&#x8868;&#x793A;&#x4E24;&#x4E2A;&#x4E3B;&#x8981;&#x72EC;&#x7ACB;&#x7684;&#x6807;&#x7B7E;&#x5206;&#x914D;&#xFF0C;&#x800C;&#x63A5;&#x8FD1; 1 &#x7684;&#x503C;&#x8868;&#x793A;&#x91CD;&#x8981;&#x7684;&#x4E00;&#x81F4;&#x6027;&#x3002;&#x6B64;&#x5916;&#xFF0C;&#x6B63;&#x597D; 0 &#x7684;&#x503C;&#x8868;&#x793A; <strong>purely&#xFF08;&#x7EAF;&#x7CB9;&#xFF09;</strong> &#x72EC;&#x7ACB;&#x6807;&#x7B7E;&#x5206;&#x914D;&#xFF0C;&#x6B63;&#x597D;&#x4E3A; 1 &#x7684; AMI &#x8868;&#x793A;&#x4E24;&#x4E2A;&#x6807;&#x7B7E;&#x5206;&#x914D;&#x76F8;&#x7B49;&#xFF08;&#x6709;&#x6216;&#x8005;&#x6CA1;&#x6709; permutation&#xFF09;&#x3002;</li>
<li><strong>No assumption is made on the cluster structure&#xFF08;&#x5BF9;&#x7C07;&#x7684;&#x7ED3;&#x6784;&#x6CA1;&#x6709;&#x4F5C;&#x51FA;&#x4EFB;&#x4F55;&#x5047;&#x8BBE;&#xFF09;</strong>: &#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x6BD4;&#x8F83;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF0C;&#x4F8B;&#x5982; k-means&#xFF0C;&#x5176;&#x5047;&#x5B9A; isotropic blob shapes &#x4E0E;&#x53EF;&#x4EE5;&#x627E;&#x5230;&#x5177;&#x6709; &#x201C;folded&#x201D; shapes &#x7684;&#x805A;&#x7C7B;&#x7684; spectral clustering algorithms &#xFF08;&#x9891;&#x8C31;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF09;&#x7684;&#x7ED3;&#x679C;&#x3002;</li>
</ul>
<h4 id="23922-&#x7F3A;&#x70B9;">2.3.9.2.2. &#x7F3A;&#x70B9;</h4>
<ul>
<li><p>&#x4E0E; inertia &#x76F8;&#x53CD;&#xFF0C;<strong>MI-based measures require the knowledge of the ground truth classes&#xFF08;MI-based measures &#x9700;&#x8981;&#x4E86;&#x89E3; ground truth classes&#xFF09;</strong> &#xFF0C;&#x800C;&#x5728;&#x5B9E;&#x8DF5;&#x4E2D;&#x51E0;&#x4E4E;&#x4E0D;&#x53EF;&#x7528;&#xFF0C;&#x6216;&#x8005;&#x9700;&#x8981;&#x4EBA;&#x5DE5;&#x6807;&#x6CE8;&#x6216;&#x624B;&#x52A8;&#x5206;&#x914D;&#xFF08;&#x5982;&#x5728;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x73AF;&#x5883;&#x4E2D;&#xFF09;&#x3002;</p>
<p>&#x7136;&#x800C;&#xFF0C;&#x57FA;&#x4E8E; MI-based measures &#xFF08;&#x57FA;&#x4E8E; MI &#x7684;&#x6D4B;&#x91CF;&#x65B9;&#x5F0F;&#xFF09;&#x4E5F;&#x53EF;&#x7528;&#x4E8E;&#x7EAF;&#x65E0;&#x4EBA;&#x76D1;&#x63A7;&#x7684;&#x8BBE;&#x7F6E;&#xFF0C;&#x4F5C;&#x4E3A;&#x53EF;&#x7528;&#x4E8E;&#x805A;&#x7C7B;&#x6A21;&#x578B;&#x9009;&#x62E9;&#x7684; Consensus Index &#xFF08;&#x5171;&#x8BC6;&#x7D22;&#x5F15;&#xFF09;&#x7684;&#x6784;&#x5EFA;&#x5757;&#x3002;</p>
</li>
<li><p>NMI &#x548C; MI &#x6CA1;&#x6709;&#x8C03;&#x6574;&#x673A;&#x4F1A;&#x3002;</p>
</li>
</ul>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html#sphx-glr-auto-examples-cluster-plot-adjusted-for-chance-measures-py">Adjustment for chance in clustering performance evaluation</a>: &#x5206;&#x6790;&#x6570;&#x636E;&#x96C6;&#x5927;&#x5C0F;&#x5BF9;&#x968F;&#x673A;&#x5206;&#x914D;&#x805A;&#x7C7B;&#x5EA6;&#x91CF;&#x503C;&#x7684;&#x5F71;&#x54CD;&#x3002; &#x6B64;&#x793A;&#x4F8B;&#x8FD8;&#x5305;&#x62EC; Adjusted Rand Index&#x3002;</li>
</ul>
<h4 id="23923-&#x6570;&#x5B66;&#x516C;&#x5F0F;">2.3.9.2.3. &#x6570;&#x5B66;&#x516C;&#x5F0F;</h4>
<p>&#x5047;&#x8BBE;&#x4E24;&#x4E2A;&#x6807;&#x7B7E;&#x5206;&#x914D;&#xFF08;&#x76F8;&#x540C;&#x7684; N &#x4E2A;&#x5BF9;&#x8C61;&#xFF09;&#xFF0C;<img src="img/11c00539ec3e5944afd76511830591db.jpg" alt="U"> &#x548C; <img src="img/5303ecbc70bf5189b8785555c03c54ee.jpg" alt="V">&#x3002; &#x5B83;&#x4EEC;&#x7684; entropy &#xFF08;&#x71B5;&#xFF09;&#x662F;&#x4E00;&#x4E2A; partition set &#xFF08;&#x5206;&#x533A;&#x96C6;&#x5408;&#xFF09;&#x7684;&#x4E0D;&#x786E;&#x5B9A;&#x6027;&#x91CF;&#xFF0C;&#x5B9A;&#x4E49;&#x5982;&#x4E0B;:</p>
<p><img src="img/07610ee9d3a524eb0a3fb7ae409614c1.jpg" alt="H(U) = - \sum_{i=1}^{|U|}P(i)\log(P(i))"></p>
<p>&#x5176;&#x4E2D; <img src="img/18906a7fe0c5d78e0a291e472ded58ce.jpg" alt="P(i) = |U_i| / N"> &#x662F;&#x4ECE; <img src="img/11c00539ec3e5944afd76511830591db.jpg" alt="U"> &#x4E2D;&#x968F;&#x673A;&#x9009;&#x53D6;&#x7684;&#x5BF9;&#x8C61;&#x5230;&#x7C7B; <img src="img/59100a001bb4b110e00f7ddf1354cd5b.jpg" alt="U_i"> &#x7684;&#x6982;&#x7387;&#x3002;&#x540C;&#x6837;&#x5BF9;&#x4E8E; <img src="img/5303ecbc70bf5189b8785555c03c54ee.jpg" alt="V">:</p>
<p><img src="img/b4e752f6314fe52f8c066964d26145a8.jpg" alt="H(V) = - \sum_{j=1}^{|V|}P&apos;(j)\log(P&apos;(j))"></p>
<p>&#x4F7F;&#x7528; <img src="img/e270fdc1fb7cabab295d31d189d77258.jpg" alt="P&apos;(j) = |V_j| / N">. <img src="img/11c00539ec3e5944afd76511830591db.jpg" alt="U"> &#x548C; <img src="img/5303ecbc70bf5189b8785555c03c54ee.jpg" alt="V"> &#x4E4B;&#x95F4;&#x7684; mutual information (MI) &#x7531;&#x4E0B;&#x5F0F;&#x8BA1;&#x7B97;:</p>
<p><img src="img/352bc5f9f9d6aefcdaf8deca4f7964ff.jpg" alt="\text{MI}(U, V) = \sum_{i=1}^{|U|}\sum_{j=1}^{|V|}P(i, j)\log\left(\frac{P(i,j)}{P(i)P&apos;(j)}\right)"></p>
<p>&#x5176;&#x4E2D; <img src="img/b67ce2997477f658a6a39026c01e07c4.jpg" alt="P(i, j) = |U_i \cap V_j| / N"> &#x662F;&#x968F;&#x673A;&#x9009;&#x62E9;&#x7684;&#x5BF9;&#x8C61;&#x843D;&#x5165;&#x4E24;&#x4E2A;&#x7C7B;&#x7684;&#x6982;&#x7387; <img src="img/59100a001bb4b110e00f7ddf1354cd5b.jpg" alt="U_i"> &#x548C; <img src="img/22f3a10ad9acceb77ea6193f945b11cf.jpg" alt="V_j"> &#x3002;</p>
<p>&#x4E5F;&#x53EF;&#x4EE5;&#x7528;&#x8BBE;&#x5B9A;&#x7684;&#x57FA;&#x6570;&#x8868;&#x8FBE;&#x5F0F;&#x8868;&#x793A;:</p>
<p><img src="img/170bd587959dabf132e4e0f39fa0a7b7.jpg" alt="\text{MI}(U, V) = \sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \frac{|U_i \cap V_j|}{N}\log\left(\frac{N|U_i \cap V_j|}{|U_i||V_j|}\right)"></p>
<p>normalized (&#x5F52;&#x4E00;&#x5316;) mutual information &#x88AB;&#x5B9A;&#x4E49;&#x4E3A;</p>
<p><img src="img/7695a05e60c9dc0ec13f779fc19da966.jpg" alt="\text{NMI}(U, V) = \frac{\text{MI}(U, V)}{\sqrt{H(U)H(V)}}"></p>
<p>mutual information &#x7684;&#x4EF7;&#x503C;&#x4EE5;&#x53CA; normalized variant &#xFF08;&#x6807;&#x51C6;&#x5316;&#x53D8;&#x91CF;&#xFF09;&#x7684;&#x503C;&#x4E0D;&#x4F1A;&#x56E0; chance &#xFF08;&#x673A;&#x4F1A;&#xFF09;&#x800C;&#x88AB;&#x8C03;&#x6574;&#xFF0C;&#x968F;&#x7740;&#x4E0D;&#x540C;&#x6807;&#x7B7E;&#xFF08;clusters&#xFF08;&#x7C07;&#xFF09;&#xFF09;&#x7684;&#x6570;&#x91CF;&#x7684;&#x589E;&#x52A0;&#xFF0C;&#x4E0D;&#x7BA1;&#x6807;&#x7B7E;&#x5206;&#x914D;&#x4E4B;&#x95F4;&#x7684; &#x201C;mutual information&#x201D; &#x7684;&#x5B9E;&#x9645;&#x6570;&#x91CF;&#x5982;&#x4F55;&#xFF0C;&#x90FD;&#x4F1A;&#x8D8B;&#x5411;&#x4E8E;&#x589E;&#x52A0;&#x3002;</p>
<p>mutual information &#x7684;&#x671F;&#x671B;&#x503C;&#x53EF;&#x4EE5;&#x7528; Vinh, Epps &#x548C; Bailey,(2009) &#x7684;&#x4EE5;&#x4E0B;&#x516C;&#x5F0F;&#x6765;&#x8BA1;&#x7B97;&#x3002;&#x5728;&#x8FD9;&#x4E2A;&#x65B9;&#x7A0B;&#x5F0F;&#x4E2D;, <img src="img/f3893160388ee4203c313659d729cef0.jpg" alt="a_i = |U_i|"> (<img src="img/59100a001bb4b110e00f7ddf1354cd5b.jpg" alt="U_i"> &#x4E2D;&#x5143;&#x7D20;&#x7684;&#x6570;&#x91CF;) &#x548C; <img src="img/e2bd3aaa1586d4d17301f7fe016eefd7.jpg" alt="b_j = |V_j|"> (<img src="img/22f3a10ad9acceb77ea6193f945b11cf.jpg" alt="V_j"> &#x4E2D;&#x5143;&#x7D20;&#x7684;&#x6570;&#x91CF;).</p>
<p><img src="img/942734d190e4b1d2c51b0e2ee6c24428.jpg" alt="E[\text{MI}(U,V)]=\sum_{i=1}^|U| \sum_{j=1}^|V| \sum_{n_{ij}=(a_i+b_j-N)^+
}^{\min(a_i, b_j)} \frac{n_{ij}}{N}\log \left( \frac{ N.n_{ij}}{a_i b_j}\right)
\frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})!
(N-a_i-b_j+n_{ij})!}"></p>
<p>&#x4F7F;&#x7528;&#x671F;&#x671B;&#x503C;, &#x7136;&#x540E;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E0E; adjusted Rand index &#x76F8;&#x4F3C;&#x7684;&#x5F62;&#x5F0F;&#x6765;&#x8BA1;&#x7B97;&#x8C03;&#x6574;&#x540E;&#x7684; mutual information:</p>
<p><img src="img/17689bafe240fb42feab1cca674b5b88.jpg" alt="\text{AMI} = \frac{\text{MI} - E[\text{MI}]}{\max(H(U), H(V)) - E[\text{MI}]}"></p>
<p>&#x53C2;&#x8003;</p>
<ul>
<li>Strehl, Alexander, and Joydeep Ghosh (2002). &#x201C;Cluster ensembles &#x2013; a knowledge reuse framework for combining multiple partitions&#x201D;. Journal of Machine Learning Research 3: 583&#x2013;617. <a href="http://strehl.com/download/strehl-jmlr02.pdf" target="_blank">doi:10.1162/153244303321897735</a>.</li>
<li>Vinh, Epps, and Bailey, (2009). &#x201C;Information theoretic measures for clusterings comparison&#x201D;. Proceedings of the 26th Annual International Conference on Machine Learning - ICML &#x2018;09. <a href="https://dl.acm.org/citation.cfm?doid=1553374.1553511" target="_blank">doi:10.1145/1553374.1553511</a>. ISBN 9781605585161.</li>
<li>Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance, JMLR <a href="http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf" target="_blank">http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf</a></li>
<li><a href="https://en.wikipedia.org/wiki/Mutual_Information" target="_blank">Wikipedia entry for the (normalized) Mutual Information</a></li>
<li><a href="https://en.wikipedia.org/wiki/Adjusted_Mutual_Information" target="_blank">Wikipedia entry for the Adjusted Mutual Information</a></li>
</ul>
<h3 id="2393-&#x540C;&#x8D28;&#x6027;&#xFF0C;&#x5B8C;&#x6574;&#x6027;&#x548C;-v-measure">2.3.9.3. &#x540C;&#x8D28;&#x6027;&#xFF0C;&#x5B8C;&#x6574;&#x6027;&#x548C; V-measure</h3>
<p>&#x9274;&#x4E8E;&#x6837;&#x672C;&#x7684; ground truth class assignments &#xFF08;&#x6807;&#x5B9A;&#x8FC7;&#x7684;&#x771F;&#x5B9E;&#x6570;&#x636E;&#x7C7B;&#x5206;&#x914D;&#xFF09;&#x7684;&#x77E5;&#x8BC6;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; conditional entropy &#xFF08;&#x6761;&#x4EF6;&#x71B5;&#xFF09;&#x5206;&#x6790;&#x6765;&#x5B9A;&#x4E49;&#x4E00;&#x4E9B; intuitive metric&#xFF08;&#x76F4;&#x89C2;&#x7684;&#x5EA6;&#x91CF;&#xFF09;&#x3002;</p>
<p>&#x7279;&#x522B;&#x662F; Rosenberg &#x548C; Hirschberg (2007) &#x4E3A;&#x4EFB;&#x4F55; cluster &#xFF08;&#x7C07;&#xFF09;&#x5206;&#x914D;&#x5B9A;&#x4E49;&#x4E86;&#x4EE5;&#x4E0B;&#x4E24;&#x4E2A;&#x7406;&#x60F3;&#x7684;&#x76EE;&#x6807;:</p>
<ul>
<li><strong>homogeneity(&#x540C;&#x8D28;&#x6027;)</strong>: &#x6BCF;&#x4E2A;&#x7C07;&#x53EA;&#x5305;&#x542B;&#x4E00;&#x4E2A;&#x7C7B;&#x7684;&#x6210;&#x5458;</li>
<li><strong>completeness(&#x5B8C;&#x6574;&#x6027;)</strong>: &#x7ED9;&#x5B9A;&#x7C7B;&#x7684;&#x6240;&#x6709;&#x6210;&#x5458;&#x90FD;&#x5206;&#x914D;&#x7ED9;&#x540C;&#x4E00;&#x4E2A;&#x7C07;&#x3002;</li>
</ul>
<p>&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x628A;&#x8FD9;&#x4E9B;&#x6982;&#x5FF5;&#x4F5C;&#x4E3A;&#x5206;&#x6570; <a href="generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score" title="sklearn.metrics.homogeneity_score"><code>homogeneity_score</code></a> &#x548C; <a href="generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score" title="sklearn.metrics.completeness_score"><code>completeness_score</code></a> &#x3002;&#x4E24;&#x8005;&#x5747;&#x5728; 0.0 &#x4EE5;&#x4E0B; &#x548C; 1.0 &#x4EE5;&#x4E0A;&#xFF08;&#x8D8A;&#x9AD8;&#x8D8A;&#x597D;&#xFF09;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_true = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]

<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.homogeneity_score(labels_true, labels_pred)  
<span class="hljs-number">0.66</span>...

<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.completeness_score(labels_true, labels_pred) 
<span class="hljs-number">0.42</span>...
</code></pre>
<p>&#x79F0;&#x4E3A; <strong>V-measure</strong> &#x7684; harmonic mean &#x7531;&#x4EE5;&#x4E0B;&#x51FD;&#x6570;&#x8BA1;&#x7B97; <a href="generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score" title="sklearn.metrics.v_measure_score"><code>v_measure_score</code></a>:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>metrics.v_measure_score(labels_true, labels_pred)    
<span class="hljs-number">0.51</span>...
</code></pre>
<p>V-measure &#x5B9E;&#x9645;&#x4E0A;&#x7B49;&#x4E8E;&#x4E0A;&#x9762;&#x8BA8;&#x8BBA;&#x7684; mutual information (NMI) &#x7531; label entropies <a href="#b2011">[B2011]</a> &#xFF08;&#x6807;&#x51C6;&#x71B5; <a href="#b2011">[B2011]</a>&#xFF09; &#x7684;&#x603B;&#x548C; normalized &#xFF08;&#x5F52;&#x4E00;&#x5316;&#xFF09;&#x3002;</p>
<p>Homogeneity&#xFF08;&#x540C;&#x8D28;&#x6027;&#xFF09;, completeness&#xFF08;&#x5B8C;&#x6574;&#x6027;&#xFF09; and V-measure &#x53EF;&#x4EE5;&#x7ACB;&#x5373;&#x8BA1;&#x7B97; <a href="generated/sklearn.metrics.homogeneity_completeness_v_measure.html#sklearn.metrics.homogeneity_completeness_v_measure" title="sklearn.metrics.homogeneity_completeness_v_measure"><code>homogeneity_completeness_v_measure</code></a> &#x5982;&#x4E0B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>metrics.homogeneity_completeness_v_measure(labels_true, labels_pred)
<span class="hljs-meta">... </span>                                                     
(<span class="hljs-number">0.66</span>..., <span class="hljs-number">0.42</span>..., <span class="hljs-number">0.51</span>...)
</code></pre>
<p>&#x4EE5;&#x4E0B;&#x805A;&#x7C7B;&#x5206;&#x914D;&#x7A0D;&#x5FAE;&#x597D;&#x4E00;&#x4E9B;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x662F;&#x540C;&#x6784;&#x4F46;&#x4E0D;&#x5B8C;&#x6574;&#x7684;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.homogeneity_completeness_v_measure(labels_true, labels_pred)
<span class="hljs-meta">... </span>                                                     
(<span class="hljs-number">1.0</span>, <span class="hljs-number">0.68</span>..., <span class="hljs-number">0.81</span>...)
</code></pre>
<p>Note</p>
<p><a href="generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score" title="sklearn.metrics.v_measure_score"><code>v_measure_score</code></a> &#x662F; <strong>symmetric&#xFF08;&#x5BF9;&#x79F0;&#x7684;&#xFF09;</strong>: &#x5B83;&#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x8BC4;&#x4F30;&#x540C;&#x4E00;&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x4E24;&#x4E2A; independent assignments &#xFF08;&#x72EC;&#x7ACB;&#x8D4B;&#x503C;&#xFF09;&#x7684; <strong>agreement&#xFF08;&#x534F;&#x8BAE;&#xFF09;</strong>&#x3002;</p>
<p>&#x8FD9;&#x4E0D;&#x662F;&#x8FD9;&#x6837;&#x7684; <a href="generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score" title="sklearn.metrics.completeness_score"><code>completeness_score</code></a> &#x548C; <a href="generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score" title="sklearn.metrics.homogeneity_score"><code>homogeneity_score</code></a>: &#x4E24;&#x8005;&#x7684;&#x5173;&#x7CFB;&#x662F;&#x88AB;&#x8FD9;&#x6837;&#x7EA6;&#x675F;&#x7740;:</p>
<pre><code class="lang-py">homogeneity_score(a, b) == completeness_score(b, a)
</code></pre>
<h4 id="23931-&#x4F18;&#x70B9;">2.3.9.3.1. &#x4F18;&#x70B9;</h4>
<ul>
<li><strong>Bounded scores&#xFF08;&#x5206;&#x6570;&#x662F;&#x6709;&#x754C;&#x7684;&#xFF09;</strong>: 0.0 &#x662F;&#x6700;&#x574F;&#x7684;, 1.0 &#x662F;&#x4E00;&#x4E2A;&#x5B8C;&#x7F8E;&#x7684;&#x5206;&#x6570;.</li>
<li>Intuitive interpretation&#xFF08;&#x76F4;&#x89C2;&#x89E3;&#x91CA;&#xFF09;: &#x5177;&#x6709;&#x4E0D;&#x826F; V-measure &#x7684;&#x805A;&#x7C7B;&#x53EF;&#x4EE5;&#x5728; <strong>qualitatively analyzed in terms of homogeneity and completeness&#xFF08;&#x5728;&#x540C;&#x8D28;&#x6027;&#x548C;&#x5B8C;&#x6574;&#x6027;&#x65B9;&#x9762;&#x8FDB;&#x884C;&#x5B9A;&#x6027;&#x5206;&#x6790;&#xFF09;</strong> &#x4EE5;&#x66F4;&#x597D;&#x5730;&#x611F;&#x77E5;&#x5230;&#x4F5C;&#x4E1A;&#x5B8C;&#x6210;&#x7684;&#x9519;&#x8BEF;&#x7C7B;&#x578B;&#x3002;</li>
<li><strong>No assumption is made on the cluster structure&#xFF08;&#x5BF9;&#x7C07;&#x7684;&#x7ED3;&#x6784;&#x6CA1;&#x6709;&#x4F5C;&#x51FA;&#x4EFB;&#x4F55;&#x5047;&#x8BBE;&#xFF09;</strong>: &#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x6BD4;&#x8F83;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF0C;&#x4F8B;&#x5982; k-means &#xFF0C;&#x5176;&#x5047;&#x5B9A; isotropic blob shapes &#x4E0E;&#x53EF;&#x4EE5;&#x627E;&#x5230;&#x5177;&#x6709; &#x201C;folded&#x201D; shapes &#x7684;&#x805A;&#x7C7B;&#x7684; spectral clustering algorithms &#xFF08;&#x9891;&#x8C31;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF09;&#x7684;&#x7ED3;&#x679C;&#x3002;</li>
</ul>
<h4 id="23932-&#x7F3A;&#x70B9;">2.3.9.3.2. &#x7F3A;&#x70B9;</h4>
<ul>
<li><p>&#x4EE5;&#x524D;&#x5F15;&#x5165;&#x7684; metrics &#xFF08;&#x5EA6;&#x91CF;&#x6807;&#x51C6;&#xFF09;<strong>not normalized with regards to random labeling&#xFF08;&#x5E76;&#x4E0D;&#x662F;&#x968F;&#x673A;&#x6807;&#x8BB0;&#x7684;&#x6807;&#x51C6;&#x5316;&#x7684;&#xFF09;</strong>: &#x8FD9;&#x610F;&#x5473;&#x7740;&#xFF0C;&#x6839;&#x636E; number of samples &#xFF08;&#x6837;&#x672C;&#x6570;&#x91CF;&#xFF09;&#xFF0C;clusters &#xFF08;&#x7C07;&#xFF09;&#x548C; ground truth classes &#xFF08;&#x6807;&#x5B9A;&#x8FC7;&#x7684;&#x771F;&#x5B9E;&#x6570;&#x636E;&#x7C7B;&#xFF09;&#xFF0C;&#x5B8C;&#x5168;&#x968F;&#x673A;&#x7684;&#x6807;&#x7B7E;&#x5E76;&#x4E0D;&#x603B;&#x662F;&#x4EA7;&#x751F; homogeneity &#xFF08;&#x540C;&#x8D28;&#x6027;&#xFF09;&#xFF0C;completeness&#xFF08;&#x5B8C;&#x6574;&#x6027;&#xFF09;&#x548C; hence v-measure &#x7684;&#x76F8;&#x540C;&#x503C;&#x3002;&#x7279;&#x522B;&#x662F; <strong>random labeling won&#x2019;t yield zero scores especially when the number of clusters is large&#xFF08;&#x968F;&#x673A;&#x6807;&#x8BB0;&#x4E0D;&#x4F1A;&#x4EA7;&#x751F;&#x96F6;&#x5206;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x5F53;&#x96C6;&#x7FA4;&#x6570;&#x91CF;&#x5927;&#x65F6;&#xFF09;</strong>&#x3002;</p>
<p>&#x5F53;&#x6837;&#x672C;&#x6570;&#x91CF;&#x8D85;&#x8FC7; 1000&#xFF0C;&#x7C07;&#x7684;&#x6570;&#x91CF;&#x5C0F;&#x4E8E; 10 &#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x5B89;&#x5168;&#x5730;&#x5FFD;&#x7565;&#x6B64;&#x95EE;&#x9898;&#x3002;<strong>For smaller sample sizes or larger number of clusters it is safer to use an adjusted index such as the Adjusted Rand Index (ARI)&#xFF08;&#x5BF9;&#x4E8E;&#x8F83;&#x5C0F;&#x7684;&#x6837;&#x672C;&#x6570;&#x91CF;&#x6216;&#x8005;&#x8F83;&#x5927;&#x6570;&#x91CF;&#x7684;&#x7C07;&#xFF0C;&#x4F7F;&#x7528; adjusted index &#x4F8B;&#x5982; Adjusted Rand Index (ARI)&#xFF09;</strong>&#x3002;</p>
</li>
</ul>
<p><a href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html"><img src="img/77e9cd089beb314666ac8397f95afc0a.jpg" alt="http://sklearn.apachecn.org/cn/0.19.0/_images/sphx_glr_plot_adjusted_for_chance_measures_0011.png"></a></p>
<ul>
<li>&#x8FD9;&#x4E9B; metrics &#xFF08;&#x6307;&#x6807;&#xFF09; <strong>require the knowledge of the ground truth classes&#xFF08;&#x9700;&#x8981;&#x6807;&#x5B9A;&#x8FC7;&#x7684;&#x771F;&#x5B9E;&#x6570;&#x636E;&#x7C7B;&#x7684;&#x77E5;&#x8BC6;&#xFF09;</strong>&#xFF0C;&#x800C;&#x5728;&#x5B9E;&#x8DF5;&#x4E2D;&#x51E0;&#x4E4E;&#x4E0D;&#x53EF;&#x7528;&#xFF0C;&#x6216;&#x9700;&#x8981;&#x4EBA;&#x5DE5;&#x6807;&#x6CE8;&#x6765;&#x4EBA;&#x5DE5;&#x5206;&#x914D;&#xFF08;&#x5982;&#x5728;&#x53D7;&#x76D1;&#x7763;&#x7684;&#x5B66;&#x4E60;&#x73AF;&#x5883;&#x4E2D;&#xFF09;&#x3002;</li>
</ul>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html#sphx-glr-auto-examples-cluster-plot-adjusted-for-chance-measures-py">Adjustment for chance in clustering performance evaluation</a>: &#x5206;&#x6790;&#x6570;&#x636E;&#x96C6;&#x5927;&#x5C0F;&#x5BF9;&#x968F;&#x673A;&#x5206;&#x914D;&#x805A;&#x7C7B;&#x5EA6;&#x91CF;&#x503C;&#x7684;&#x5F71;&#x54CD;&#x3002;</li>
</ul>
<h4 id="23933-&#x6570;&#x5B66;&#x8868;&#x8FBE;">2.3.9.3.3. &#x6570;&#x5B66;&#x8868;&#x8FBE;</h4>
<p>Homogeneity&#xFF08;&#x540C;&#x8D28;&#x6027;&#xFF09; &#x548C; completeness&#xFF08;&#x5B8C;&#x6574;&#x6027;&#xFF09; &#x7684;&#x5F97;&#x5206;&#x7531;&#x4E0B;&#x9762;&#x516C;&#x5F0F;&#x7ED9;&#x51FA;:</p>
<p><img src="img/148aed7690723555d32f36019c3d6948.jpg" alt="h = 1 - \frac{H(C|K)}{H(C)}"></p>
<p><img src="img/b714492d7f23932738745c4ed05fe7ae.jpg" alt="c = 1 - \frac{H(K|C)}{H(K)}"></p>
<p>&#x5176;&#x4E2D; <img src="img/c9f28da3986a32d6c1421f357d52b9fa.jpg" alt="H(C|K)"> &#x662F; <strong>&#x7ED9;&#x5B9A;&#x7C07;&#x5206;&#x914D;&#x7684;&#x7C7B;&#x7684; conditional entropy &#xFF08;&#x6761;&#x4EF6;&#x71B5;&#xFF09;</strong> &#xFF0C;&#x7531;&#x4E0B;&#x5F0F;&#x7ED9;&#x51FA;:</p>
<p><img src="img/e18ade3134bef595ea6ddf488ff9557a.jpg" alt="H(C|K) = - \sum_{c=1}^{|C|} \sum_{k=1}^{|K|} \frac{n_{c,k}}{n}
\cdot \log\left(\frac{n_{c,k}}{n_k}\right)"></p>
<p>&#x5E76;&#x4E14; <img src="img/be4190a760361bd7ae65c77218465778.jpg" alt="H(C)"> &#x662F; <strong>entropy of the classes&#xFF08;&#x7C7B;&#x7684;&#x71B5;&#xFF09;</strong>&#xFF0C;&#x5E76;&#x4E14;&#x7531;&#x4E0B;&#x5F0F;&#x7ED9;&#x51FA;:</p>
<p><img src="img/8c43dd6816e66709ef3f9d681ec3941a.jpg" alt="H(C) = - \sum_{c=1}^{|C|} \frac{n_c}{n} \cdot \log\left(\frac{n_c}{n}\right)"></p>
<p><img src="img/c87d9110f3d32ffa5fa08671e4af11fb.jpg" alt="n"> &#x4E2A;&#x6837;&#x672C;&#x603B;&#x6570;&#xFF0C; <img src="img/21e9f42c5b6730d593e37a11c6ffb13a.jpg" alt="n_c"> &#x548C; <img src="img/6042b714de932f6ed841e71bfe9acede.jpg" alt="n_k"> &#x5206;&#x522B;&#x5C5E;&#x4E8E; <img src="img/d5c9a11453ea30a1be50a1034052bd6b.jpg" alt="c"> &#x7C7B;&#x548C;&#x7C07; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x7684;&#x6837;&#x672C;&#x6570;&#xFF0C;&#x6700;&#x540E; <img src="img/0acf1512409eb0a9a90102698304fd52.jpg" alt="n_{c,k}"> &#x5206;&#x914D;&#x7ED9;&#x7C07; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x7684;&#x7C7B; <img src="img/d5c9a11453ea30a1be50a1034052bd6b.jpg" alt="c"> &#x7684;&#x6837;&#x672C;&#x6570;&#x3002;</p>
<p><strong>conditional entropy of clusters given class&#xFF08;&#x7ED9;&#x5B9A;&#x7C7B;&#x7684;&#x6761;&#x4EF6;&#x71B5;&#xFF09;</strong> <img src="img/05588cdc4e82289930a92b0097f67d2d.jpg" alt="H(K|C)"> &#x548C; <strong>entropy of clusters&#xFF08;&#x7C7B;&#x7684;&#x71B5;&#xFF09;</strong> <img src="img/5062c88fba7988fa39aca3bc91857721.jpg" alt="H(K)"> &#x4EE5; symmetric manner &#xFF08;&#x5BF9;&#x79F0;&#x65B9;&#x5F0F;&#xFF09;&#x5B9A;&#x4E49;&#x3002;</p>
<p>Rosenberg &#x548C; Hirschberg &#x8FDB;&#x4E00;&#x6B65;&#x5B9A;&#x4E49; <strong>V-measure</strong> &#x4F5C;&#x4E3A; <strong>harmonic mean of homogeneity and completeness&#xFF08;&#x540C;&#x8D28;&#x6027;&#x548C;&#x5B8C;&#x6574;&#x6027;&#x7684; harmonic mean&#xFF09;</strong>:</p>
<p><img src="img/611639bdcfd73c857a43842913d6e826.jpg" alt="v = 2 \cdot \frac{h \cdot c}{h + c}"></p>
<p>&#x53C2;&#x8003;</p>
<ul>
<li><a href="http://aclweb.org/anthology/D/D07/D07-1043.pdf" target="_blank">V-Measure: A conditional entropy-based external cluster evaluation measure</a> Andrew Rosenberg and Julia Hirschberg, 2007</li>
</ul>
<p>| [B2011] | <em>(<a href="#id30">1</a>, <a href="#id31">2</a>)</em> <a href="http://www.cs.columbia.edu/~hila/hila-thesis-distributed.pdf" target="_blank">Identication and Characterization of Events in Social Media</a>, Hila Becker, PhD Thesis. |</p>
<h3 id="2394-fowlkes-mallows-&#x5206;&#x6570;">2.3.9.4. Fowlkes-Mallows &#x5206;&#x6570;</h3>
<p>&#x5F53;&#x6837;&#x672C;&#x7684;&#x5DF2;&#x6807;&#x5B9A;&#x7684;&#x771F;&#x5B9E;&#x6570;&#x636E;&#x7684;&#x7C7B;&#x522B;&#x5206;&#x914D;&#x5DF2;&#x77E5;&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; Fowlkes-Mallows index &#xFF08;Fowlkes-Mallows &#x6307;&#x6570;&#xFF09;(<a href="generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score" title="sklearn.metrics.fowlkes_mallows_score"><code>sklearn.metrics.fowlkes_mallows_score</code></a>) &#x3002;Fowlkes-Mallows &#x5206;&#x6570; FMI &#x88AB;&#x5B9A;&#x4E49;&#x4E3A; geometric mean of the pairwise precision &#xFF08;&#x6210;&#x5BF9;&#x7684;&#x51C6;&#x786E;&#x7387;&#xFF09;&#x548C; recall &#xFF08;&#x53EC;&#x56DE;&#x7387;&#xFF09;&#x7684;&#x51E0;&#x4F55;&#x5E73;&#x5747;&#x503C;:</p>
<p><img src="img/403595258114953d3411fd1bfbf335f8.jpg" alt="\text{FMI} = \frac{\text{TP}}{\sqrt{(\text{TP} + \text{FP}) (\text{TP} + \text{FN})}}"></p>
<p>&#x5176;&#x4E2D;&#x7684; <code>TP</code> &#x662F; <strong>True Positive&#xFF08;&#x771F;&#x6B63;&#x4F8B;&#xFF09;</strong> &#x7684;&#x6570;&#x91CF;&#xFF08;&#x5373;&#xFF0C;&#x771F;&#x5B9E;&#x6807;&#x7B7E;&#x548C;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x4E2D;&#x5C5E;&#x4E8E;&#x76F8;&#x540C;&#x7C07;&#x7684;&#x70B9;&#x5BF9;&#x6570;&#xFF09;&#xFF0C;<code>FP</code> &#x662F; <strong>False Positive&#xFF08;&#x5047;&#x6B63;&#x4F8B;&#xFF09;</strong> &#xFF08;&#x5373;&#xFF0C;&#x5728;&#x771F;&#x5B9E;&#x6807;&#x7B7E;&#x4E2D;&#x5C5E;&#x4E8E;&#x540C;&#x4E00;&#x7C07;&#x7684;&#x70B9;&#x5BF9;&#x6570;&#xFF0C;&#x800C;&#x4E0D;&#x5728;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x4E2D;&#xFF09;&#xFF0C;<code>FN</code> &#x662F; <strong>False Negative&#xFF08;&#x5047;&#x8D1F;&#x4F8B;&#xFF09;</strong> &#x7684;&#x6570;&#x91CF;&#xFF08;&#x5373;&#xFF0C;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x4E2D;&#x5C5E;&#x4E8E;&#x540C;&#x4E00;&#x7C07;&#x7684;&#x70B9;&#x5BF9;&#x6570;&#xFF0C;&#x800C;&#x4E0D;&#x5728;&#x771F;&#x5B9E;&#x6807;&#x7B7E;&#x4E2D;&#xFF09;&#x3002;</p>
<p>score &#xFF08;&#x5206;&#x6570;&#xFF09;&#x8303;&#x56F4;&#x4E3A; 0 &#x5230; 1&#x3002;&#x8F83;&#x9AD8;&#x7684;&#x503C;&#x8868;&#x793A;&#x4E24;&#x4E2A;&#x7C07;&#x4E4B;&#x95F4;&#x7684;&#x826F;&#x597D;&#x76F8;&#x4F3C;&#x6027;&#x3002;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_true = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]
</code></pre>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>metrics.fowlkes_mallows_score(labels_true, labels_pred)  
<span class="hljs-number">0.47140</span>...
</code></pre>
<p>&#x53EF;&#x4EE5;&#x5728; predicted labels &#xFF08;&#x9884;&#x6D4B;&#x7684;&#x6807;&#x7B7E;&#xFF09;&#x4E2D; permute &#xFF08;&#x6392;&#x5217;&#xFF09; 0 &#x548C; 1 &#xFF0C;&#x91CD;&#x547D;&#x540D;&#x4E3A; 2 &#x5230; 3 &#x5E76;&#x5F97;&#x5230;&#x76F8;&#x540C;&#x7684;&#x5F97;&#x5206;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>]

<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.fowlkes_mallows_score(labels_true, labels_pred)  
<span class="hljs-number">0.47140</span>...
</code></pre>
<p>&#x5B8C;&#x7F8E;&#x7684;&#x6807;&#x7B7E;&#x5F97;&#x5206;&#x662F; 1.0:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = labels_true[:]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.fowlkes_mallows_score(labels_true, labels_pred)  
<span class="hljs-number">1.0</span>
</code></pre>
<p>&#x574F;&#x7684;&#xFF08;&#x4F8B;&#x5982; independent labelings &#xFF08;&#x72EC;&#x7ACB;&#x6807;&#x7B7E;&#xFF09;&#xFF09;&#x7684;&#x6807;&#x7B7E;&#x5F97;&#x5206;&#x4E3A; 0:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>labels_true = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>labels_pred = [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.fowlkes_mallows_score(labels_true, labels_pred)  
<span class="hljs-number">0.0</span>
</code></pre>
<h4 id="23941-&#x4F18;&#x70B9;">2.3.9.4.1. &#x4F18;&#x70B9;</h4>
<ul>
<li><strong>Random (uniform) label assignments have a FMI score close to 0.0&#xFF08;&#x968F;&#x673A;&#xFF08;&#x7EDF;&#x4E00;&#xFF09;&#x6807;&#x7B7E;&#x5206;&#x914D; FMI &#x5F97;&#x5206;&#x63A5;&#x8FD1;&#x4E8E; 0.0&#xFF09;</strong> &#x5BF9;&#x4E8E; <code>n_clusters</code> &#x548C; <code>n_samples</code> &#x7684;&#x4EFB;&#x4F55;&#x503C;&#xFF08;&#x5BF9;&#x4E8E;&#x539F;&#x59CB; Mutual Information &#x6216;&#x4F8B;&#x5982; V-measure &#x800C;&#x8A00;&#xFF09;&#x3002;</li>
<li><strong>Bounded range&#xFF08;&#x6709;&#x754C;&#x8303;&#x56F4;&#xFF09; [0, 1]</strong>: &#x63A5;&#x8FD1;&#x4E8E; 0 &#x7684;&#x503C;&#x8868;&#x793A;&#x4E24;&#x4E2A;&#x6807;&#x7B7E;&#x5206;&#x914D;&#x5728;&#x5F88;&#x5927;&#x7A0B;&#x5EA6;&#x4E0A;&#x662F;&#x72EC;&#x7ACB;&#x7684;&#xFF0C;&#x800C;&#x63A5;&#x8FD1;&#x4E8E; 1 &#x7684;&#x503C;&#x8868;&#x793A; significant agreement &#x3002;&#x6B64;&#x5916;&#xFF0C;&#x6B63;&#x597D;&#x4E3A; 0 &#x7684;&#x503C;&#x8868;&#x793A; <strong>purely</strong> &#x72EC;&#x7ACB;&#x6807;&#x7B7E;&#x5206;&#x914D;&#xFF0C;&#x6B63;&#x597D;&#x4E3A; 1 &#x7684; AMI &#x8868;&#x793A;&#x4E24;&#x4E2A;&#x6807;&#x7B7E;&#x5206;&#x914D;&#x76F8;&#x7B49;&#xFF08;&#x6709;&#x6216;&#x8005;&#x6CA1;&#x6709; permutation &#xFF08;&#x6392;&#x5217;&#xFF09;&#xFF09;&#x3002;</li>
<li><strong>No assumption is made on the cluster structure&#xFF08;&#x5BF9;&#x7C07;&#x7684;&#x7ED3;&#x6784;&#x6CA1;&#x6709;&#x4F5C;&#x51FA;&#x4EFB;&#x4F55;&#x5047;&#x8BBE;&#xFF09;</strong>: &#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x6BD4;&#x8F83;&#x8BF8;&#x5982; k-means &#x7684;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF0C;&#x5176;&#x5C06;&#x5047;&#x8BBE; isotropic blob shapes &#x4E0E;&#x80FD;&#x591F;&#x627E;&#x5230;&#x5177;&#x6709; &#x201C;folded&#x201D; shapes &#x7684;&#x7C07;&#x7684; spectral clustering algorithms &#xFF08;&#x9891;&#x8C31;&#x805A;&#x7C7B;&#x7B97;&#x6CD5;&#xFF09;&#x7684;&#x7ED3;&#x679C;&#x76F8;&#x7ED3;&#x5408;&#x3002;</li>
</ul>
<h4 id="23942-&#x7F3A;&#x70B9;">2.3.9.4.2. &#x7F3A;&#x70B9;</h4>
<ul>
<li>&#x4E0E; inertia&#xFF08;&#x4E60;&#x60EF;&#xFF09;&#x76F8;&#x53CD;&#xFF0C;<strong>FMI-based measures require the knowledge of the ground truth classes&#xFF08;&#x57FA;&#x4E8E; FMI &#x7684;&#x6D4B;&#x91CF;&#x65B9;&#x6848;&#x9700;&#x8981;&#x4E86;&#x89E3;&#x5DF2;&#x6807;&#x6CE8;&#x7684;&#x771F;&#x662F;&#x6570;&#x636E;&#x7684;&#x7C7B;&#xFF09;</strong> &#xFF0C;&#x800C;&#x51E0;&#x4E4E;&#x4E0D;&#x7528;&#x4E8E;&#x5B9E;&#x8DF5;&#x548C;&#x9700;&#x8981;&#x4EBA;&#x5DE5;&#x6807;&#x6CE8;&#x8005;&#x7684;&#x624B;&#x52A8;&#x4EFB;&#x52A1;&#xFF08;&#x5982;&#x5728;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x7684;&#x5B66;&#x4E60;&#x73AF;&#x5883;&#x4E2D;&#xFF09;&#x3002;</li>
</ul>
<p>&#x53C2;&#x8003;</p>
<ul>
<li>E. B. Fowkles and C. L. Mallows, 1983. &#x201C;A method for comparing two hierarchical clusterings&#x201D;. Journal of the American Statistical Association. <a href="http://wildfire.stat.ucla.edu/pdflibrary/fowlkes.pdf" target="_blank">http://wildfire.stat.ucla.edu/pdflibrary/fowlkes.pdf</a></li>
<li><a href="https://en.wikipedia.org/wiki/Fowlkes-Mallows_index" target="_blank">Wikipedia entry for the Fowlkes-Mallows Index</a></li>
</ul>
<h3 id="2395-silhouette-&#x7CFB;&#x6570;">2.3.9.5. Silhouette &#x7CFB;&#x6570;</h3>
<p>&#x5982;&#x679C;&#x6807;&#x6CE8;&#x8FC7;&#x7684;&#x771F;&#x5B9E;&#x6570;&#x636E;&#x7684;&#x6807;&#x7B7E;&#x4E0D;&#x77E5;&#x9053;&#xFF0C;&#x5219;&#x5FC5;&#x987B;&#x4F7F;&#x7528;&#x6A21;&#x578B;&#x672C;&#x8EAB;&#x8FDB;&#x884C;&#x5EA6;&#x91CF;&#x3002;Silhouette Coefficient (<a href="generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score" title="sklearn.metrics.silhouette_score"><code>sklearn.metrics.silhouette_score</code></a>) &#x662F;&#x4E00;&#x4E2A;&#x8FD9;&#x6837;&#x7684;&#x8BC4;&#x4F30;&#x7684;&#x4F8B;&#x5B50;&#xFF0C;&#x5176;&#x4E2D;&#x8F83;&#x9AD8;&#x7684; Silhouette Coefficient &#x5F97;&#x5206;&#x4E0E;&#x5177;&#x6709;&#x66F4;&#x597D;&#x5B9A;&#x4E49;&#x7684;&#x805A;&#x7C7B;&#x7684;&#x6A21;&#x578B;&#x76F8;&#x5173;&#x3002;Silhouette Coefficient &#x662F;&#x4E3A;&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#x5B9A;&#x4E49;&#x7684;&#xFF0C;&#x7531;&#x4E24;&#x4E2A;&#x5F97;&#x5206;&#x7EC4;&#x6210;:</p>
<ul>
<li><strong>a</strong>: &#x6837;&#x672C;&#x4E0E;&#x540C;&#x4E00;&#x7C7B;&#x522B;&#x4E2D;&#x6240;&#x6709;&#x5176;&#x4ED6;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x5E73;&#x5747;&#x8DDD;&#x79BB;&#x3002;</li>
<li><strong>b</strong>: &#x6837;&#x672C;&#x4E0E; <em>&#x4E0B;&#x4E00;&#x4E2A;&#x8DDD;&#x79BB;&#x6700;&#x8FD1;&#x7684;&#x7C07;</em> &#x4E2D;&#x7684;&#x6240;&#x6709;&#x5176;&#x4ED6;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x5E73;&#x5747;&#x8DDD;&#x79BB;&#x3002;</li>
</ul>
<p>&#x7136;&#x540E;&#x5C06;&#x5355;&#x4E2A;&#x6837;&#x672C;&#x7684; Silhouette &#x7CFB;&#x6570; <em>s</em> &#x7ED9;&#x51FA;&#x4E3A;:</p>
<p><img src="img/8f839ebe5b506fef19bd8cc121b3f557.jpg" alt="s = \frac{b - a}{max(a, b)}"></p>
<p>&#x7ED9;&#x5B9A;&#x4E00;&#x7EC4;&#x6837;&#x672C;&#x7684; Silhouette &#x7CFB;&#x6570;&#x4F5C;&#x4E3A;&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#x7684; Silhouette &#x7CFB;&#x6570;&#x7684;&#x5E73;&#x5747;&#x503C;&#x3002;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> pairwise_distances
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = datasets.load_iris()
<span class="hljs-meta">&gt;&gt;&gt; </span>X = dataset.data
<span class="hljs-meta">&gt;&gt;&gt; </span>y = dataset.target
</code></pre>
<p>&#x5728;&#x6B63;&#x5E38;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x5C06; Silhouette &#x7CFB;&#x6570;&#x5E94;&#x7528;&#x4E8E;&#x805A;&#x7C7B;&#x5206;&#x6790;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans
<span class="hljs-meta">&gt;&gt;&gt; </span>kmeans_model = KMeans(n_clusters=<span class="hljs-number">3</span>, random_state=<span class="hljs-number">1</span>).fit(X)
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = kmeans_model.labels_
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.silhouette_score(X, labels, metric=<span class="hljs-string">&apos;euclidean&apos;</span>)
<span class="hljs-meta">... </span>                                                     
<span class="hljs-number">0.55</span>...
</code></pre>
<p>&#x53C2;&#x8003;</p>
<ul>
<li>Peter J. Rousseeuw (1987). &#x201C;Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis&#x201D;. Computational and Applied Mathematics 20: 53&#x2013;65. <a href="http://dx.doi.org/10.1016/0377-0427(87" target="_blank">doi:10.1016/0377-0427(87)90125-7</a>90125-7).</li>
</ul>
<h4 id="23951-&#x4F18;&#x70B9;">2.3.9.5.1. &#x4F18;&#x70B9;</h4>
<ul>
<li>&#x5BF9;&#x4E8E;&#x4E0D;&#x6B63;&#x786E;&#x7684; clustering &#xFF08;&#x805A;&#x7C7B;&#xFF09;&#xFF0C;&#x5206;&#x6570;&#x4E3A; -1 &#xFF0C; highly dense clustering &#xFF08;&#x9AD8;&#x5BC6;&#x5EA6;&#x805A;&#x7C7B;&#xFF09;&#x4E3A; +1 &#x3002;&#x96F6;&#x70B9;&#x9644;&#x8FD1;&#x7684;&#x5206;&#x6570;&#x8868;&#x793A; overlapping clusters &#xFF08;&#x91CD;&#x53E0;&#x7684;&#x805A;&#x7C7B;&#xFF09;&#x3002;</li>
<li>&#x5F53; clusters &#xFF08;&#x7C07;&#xFF09;&#x5BC6;&#x96C6;&#x4E14;&#x5206;&#x79BB;&#x8F83;&#x597D;&#x65F6;&#xFF0C;&#x5206;&#x6570;&#x66F4;&#x9AD8;&#xFF0C;&#x8FD9;&#x4E0E; cluster &#xFF08;&#x7C07;&#xFF09;&#x7684;&#x6807;&#x51C6;&#x6982;&#x5FF5;&#x6709;&#x5173;&#x3002;</li>
</ul>
<h4 id="23952-&#x7F3A;&#x70B9;">2.3.9.5.2. &#x7F3A;&#x70B9;</h4>
<ul>
<li>convex clusters&#xFF08;&#x51F8;&#x7684;&#x7C07;&#xFF09;&#x7684; Silhouette Coefficient &#x901A;&#x5E38;&#x6BD4;&#x5176;&#x4ED6;&#x7C7B;&#x578B;&#x7684; cluster &#xFF08;&#x7C07;&#xFF09;&#x66F4;&#x9AD8;&#xFF0C;&#x4F8B;&#x5982;&#x901A;&#x8FC7; DBSCAN &#x83B7;&#x5F97;&#x7684;&#x57FA;&#x4E8E;&#x5BC6;&#x5EA6;&#x7684; cluster&#xFF08;&#x7C07;&#xFF09;&#x3002;</li>
</ul>
<p>&#x793A;&#x4F8B;:</p>
<ul>
<li><a href="../auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py">Selecting the number of clusters with silhouette analysis on KMeans clustering</a> : &#x5728;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;silhouette &#x5206;&#x6790;&#x7528;&#x4E8E;&#x4E3A; n_clusters &#x9009;&#x62E9;&#x6700;&#x4F73;&#x503C;.</li>
</ul>
<h3 id="2396-calinski-harabaz-&#x6307;&#x6570;">2.3.9.6. Calinski-Harabaz &#x6307;&#x6570;</h3>
<p>&#x5982;&#x679C;&#x4E0D;&#x77E5;&#x9053;&#x771F;&#x5B9E;&#x6570;&#x636E;&#x7684;&#x7C7B;&#x522B;&#x6807;&#x7B7E;&#xFF0C;&#x5219;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; Calinski-Harabaz &#x6307;&#x6570; (<a href="generated/sklearn.metrics.calinski_harabaz_score.html#sklearn.metrics.calinski_harabaz_score" title="sklearn.metrics.calinski_harabaz_score"><code>sklearn.metrics.calinski_harabaz_score</code></a>) &#x6765;&#x8BC4;&#x4F30;&#x6A21;&#x578B;&#xFF0C;&#x5176;&#x4E2D;&#x8F83;&#x9AD8;&#x7684; Calinski-Harabaz &#x7684;&#x5F97;&#x5206;&#x4E0E;&#x5177;&#x6709;&#x66F4;&#x597D;&#x5B9A;&#x4E49;&#x7684;&#x805A;&#x7C7B;&#x7684;&#x6A21;&#x578B;&#x76F8;&#x5173;&#x3002;</p>
<p>&#x5BF9;&#x4E8E; <img src="img/f93871977da52a6d11045d57c3e18728.jpg" alt="k"> &#x7C07;&#xFF0C;Calinski-Harabaz &#x5F97;&#x5206; <img src="img/0faa297883831c0432cf4d72960eeb6c.jpg" alt="s"> &#x662F;&#x4F5C;&#x4E3A; between-clusters dispersion mean &#xFF08;&#x7C07;&#x95F4;&#x8272;&#x6563;&#x5E73;&#x5747;&#x503C;&#xFF09;&#x4E0E; within-cluster dispersion&#xFF08;&#x7FA4;&#x5185;&#x8272;&#x6563;&#x4E4B;&#x95F4;&#xFF09;&#x7684;&#x6BD4;&#x503C;&#x7ED9;&#x51FA;&#x7684;:</p>
<p><img src="img/af875bce0483bd18603c4d247e6a3745.jpg" alt="s(k) = \frac{\mathrm{Tr}(B_k)}{\mathrm{Tr}(W_k)} \times \frac{N - k}{k - 1}"></p>
<p>&#x5176;&#x4E2D; <img src="img/71581bfc44b992a82bd0bc7a6eee38f4.jpg" alt="B_K"> &#x662F; between group dispersion matrix &#xFF08;&#x7EC4;&#x95F4;&#x8272;&#x6563;&#x77E9;&#x9635;&#xFF09;&#xFF0C; <img src="img/9127c3e2b5748eee602354fed5570605.jpg" alt="W_K"> &#x662F;&#x7531;&#x4EE5;&#x4E0B;&#x5B9A;&#x4E49;&#x7684; within-cluster dispersion matrix &#xFF08;&#x7FA4;&#x5185;&#x8272;&#x6563;&#x77E9;&#x9635;&#xFF09;:</p>
<p><img src="img/a24e299927ed136dd98d6c87904c973d.jpg" alt="W_k = \sum_{q=1}^k \sum_{x \in C_q} (x - c_q) (x - c_q)^T"></p>
<p><img src="img/7e8b544e8ce168b079607ff9674a2c91.jpg" alt="B_k = \sum_q n_q (c_q - c) (c_q - c)^T"></p>
<p><img src="img/a44a7c045f2217894a894c482861387a.jpg" alt="N"> &#x4E3A;&#x6570;&#x636E;&#x4E2D;&#x7684;&#x70B9;&#x6570;&#xFF0C;<img src="img/03aa3da890dedc42b04c1df154062257.jpg" alt="C_q"> &#x4E3A; cluster &#xFF08;&#x7C07;&#xFF09; <img src="img/dc074c105944810a277030dfab298376.jpg" alt="q"> &#x4E2D;&#x7684;&#x70B9;&#x96C6;&#xFF0C; <img src="img/385a9104b38457eeb59acf86cf974472.jpg" alt="c_q"> &#x4E3A; cluster&#xFF08;&#x7C07;&#xFF09; <img src="img/dc074c105944810a277030dfab298376.jpg" alt="q"> &#x7684;&#x4E2D;&#x5FC3;&#xFF0C; <img src="img/d5c9a11453ea30a1be50a1034052bd6b.jpg" alt="c"> &#x4E3A; <img src="img/5bb034cee5851ab5105aca4c40a4e16e.jpg" alt="E"> &#x7684;&#x4E2D;&#x5FC3;&#xFF0C; <img src="img/33b99b5c21f0cf5b03e92fe60cbe6ad0.jpg" alt="n_q"> &#x4E3A; cluster&#xFF08;&#x7C07;&#xFF09; <img src="img/dc074c105944810a277030dfab298376.jpg" alt="q"> &#x4E2D;&#x7684;&#x70B9;&#x6570;&#x3002;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> pairwise_distances
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = datasets.load_iris()
<span class="hljs-meta">&gt;&gt;&gt; </span>X = dataset.data
<span class="hljs-meta">&gt;&gt;&gt; </span>y = dataset.target
</code></pre>
<p>&#x5728;&#x6B63;&#x5E38;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x5C06; Calinski-Harabaz index &#xFF08;Calinski-Harabaz &#x6307;&#x6570;&#xFF09;&#x5E94;&#x7528;&#x4E8E; cluster analysis &#xFF08;&#x805A;&#x7C7B;&#x5206;&#x6790;&#xFF09;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans
<span class="hljs-meta">&gt;&gt;&gt; </span>kmeans_model = KMeans(n_clusters=<span class="hljs-number">3</span>, random_state=<span class="hljs-number">1</span>).fit(X)
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = kmeans_model.labels_
<span class="hljs-meta">&gt;&gt;&gt; </span>metrics.calinski_harabaz_score(X, labels)  
<span class="hljs-number">560.39</span>...
</code></pre>
<h4 id="23961-&#x4F18;&#x70B9;">2.3.9.6.1. &#x4F18;&#x70B9;</h4>
<ul>
<li>&#x5F53; cluster &#xFF08;&#x7C07;&#xFF09;&#x5BC6;&#x96C6;&#x4E14;&#x5206;&#x79BB;&#x8F83;&#x597D;&#x65F6;&#xFF0C;&#x5206;&#x6570;&#x66F4;&#x9AD8;&#xFF0C;&#x8FD9;&#x4E0E;&#x4E00;&#x4E2A;&#x6807;&#x51C6;&#x7684; cluster&#xFF08;&#x7C07;&#xFF09;&#x6709;&#x5173;&#x3002;</li>
<li>&#x5F97;&#x5206;&#x8BA1;&#x7B97;&#x5F88;&#x5FEB;</li>
</ul>
<h4 id="23962-&#x7F3A;&#x70B9;">2.3.9.6.2. &#x7F3A;&#x70B9;</h4>
<ul>
<li>&#x51F8;&#x7684;&#x7C07;&#x7684; Calinski-Harabaz index&#xFF08;Calinski-Harabaz &#x6307;&#x6570;&#xFF09;&#x901A;&#x5E38;&#x9AD8;&#x4E8E;&#x5176;&#x4ED6;&#x7C7B;&#x578B;&#x7684; cluster&#xFF08;&#x7C07;&#xFF09;&#xFF0C;&#x4F8B;&#x5982;&#x901A;&#x8FC7; DBSCAN &#x83B7;&#x5F97;&#x7684;&#x57FA;&#x4E8E;&#x5BC6;&#x5EA6;&#x7684; cluster&#xFF08;&#x7C07;&#xFF09;&#x3002;</li>
</ul>
<p>&#x53C2;&#x8003;</p>
<ul>
<li>Cali&#x144;ski, T., &amp; Harabasz, J. (1974). &#x201C;A dendrite method for cluster analysis&#x201D;. Communications in Statistics-theory and Methods 3: 1-27. <a href="http://dx.doi.org/10.1080/03610926.2011.560741" target="_blank">doi:10.1080/03610926.2011.560741</a>.</li>
</ul>
<p><hr></p>
<div align="center">
    <p><a href="http://www.apachecn.org" target="_blank"><font face="KaiTi" size="6" color="red">&#x6211;&#x4EEC;&#x4E00;&#x76F4;&#x5728;&#x52AA;&#x529B;</font></a></p>
    <p><a href="https://github.com/apachecn/sklearn-doc-zh/" target="_blank">apachecn/sklearn-doc-zh</a></p>
    <p><iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=sklearn-doc-zh&amp;type=watch&amp;count=true&amp;v=2" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=sklearn-doc-zh&amp;type=star&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=sklearn-doc-zh&amp;type=fork&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <a target="_blank" href="shang.qq.com/wpa/qunwpa"><img border="0" src="http://data.apachecn.org/img/logo/ApacheCN-group.png" alt="ML | ApacheCN" title="ML | ApacheCN"></a></p>
</div>
 <div style="text-align:center;margin:0 0 10.5px;">
     <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
     <ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-3565452474788507" data-ad-slot="2543897000">
     </ins>
     <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>

    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?9cbab13b4d28a9811ae1d2d2176dab66";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
    </script>

    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-102475051-5"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-102475051-5');
    </script>
</div>

<p><meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo"></p>
<p><iframe src="https://www.bilibili.com/read/cv2710377" style="display:none"></iframe>
<img src="http://t.cn/AiCoDHwb" hidden="hidden"></p>
<div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
    <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
    <div id="gitalk-container"></div>
    <script type="text/javascript">
        const gitalk = new Gitalk({
        clientID: 'c56c649fa375b552e607',
        clientSecret: '21401635722aa1b9518d38d5ff1f0f151b4786ca',
        repo: 'sklearn-doc-zh',
        owner: 'apachecn',
        admin: ['jiangzhonglian', 'wizardforcel'],
        id: md5(location.pathname),
        distractionFreeMode: false
        })
        gitalk.render('gitalk-container')
    </script>
</div>

<footer class="page-footer"><span class="copyright">Copyright &#xA9; ibooker.org.cn 2019 all right reserved&#xFF0C;&#x7531; ApacheCN &#x56E2;&#x961F;&#x63D0;&#x4F9B;&#x652F;&#x6301;</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A; 
2019-06-04 20:46:46
</span></footer>
<script>console.log("plugin-popup....");document.onclick = function(e){ e.target.tagName === "IMG" && window.open(e.target.src,e.target.src)}</script><style>img{cursor:pointer}</style>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="21.html" class="navigation navigation-prev " aria-label="Previous page: 2.2. 流形学习">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="23.html" class="navigation navigation-next " aria-label="Next page: 2.4. 双聚类">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"2.3. 聚类","level":"1.3.2.3","depth":3,"next":{"title":"2.4. 双聚类","level":"1.3.2.4","depth":3,"path":"23.md","ref":"23.md","articles":[]},"previous":{"title":"2.2. 流形学习","level":"1.3.2.2","depth":3,"path":"21.md","ref":"21.md","articles":[]},"dir":"ltr"},"config":{"plugins":["github","github-buttons","-sharing","insert-logo","sharing-plus","back-to-top-button","code","copy-code-button","mathjax","pageview-count","edit-link","emphasize","alerts","auto-scroll-table","popup","hide-element","page-toc-button","tbfed-pagefooter","sitemap","advanced-emoji","expandable-chapters","splitter","search-pro"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy ibooker.org.cn 2019","modify_label":"该文件修订时间： ","modify_format":"YYYY-MM-DD HH:mm:ss"},"emphasize":{},"github":{"url":"https://github.com/apachecn/sklearn-doc-zh"},"splitter":{},"search-pro":{},"search":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"auto-scroll-table":{},"popup":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"code":{"copyButtons":true},"hide-element":{"elements":[".gitbook-link"]},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"sitemap":{"hostname":"http://sklearn.apachecn.org"},"page-toc-button":{"maxTocDepth":4,"minTocSize":4},"back-to-top-button":{},"pageview-count":{},"alerts":{},"github-buttons":{"buttons":[{"user":"apachecn","repo":"sklearn-doc-zh","type":"star","count":true,"size":"small"}]},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"copy-code-button":{},"advanced-emoji":{"embedEmojis":false},"sharing":{"qq":false,"all":["qq","douban","facebook","google","linkedin","twitter","weibo","whatsapp"],"douban":false,"facebook":false,"weibo":true,"whatsapp":false,"twitter":false,"line":false,"google":false,"qzone":true},"edit-link":{"label":"编辑本页","base":"https://github.com/apachecn/sklearn-doc-zh/blob/master/docs/0.19.x"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"insert-logo":{"style":"background: none; max-height: 150px; min-height: 150px","url":"http://data.apachecn.org/img/logo.jpg"},"expandable-chapters":{}},"my_links":{"sidebar":{"Home":"https://www.baidu.com"}},"theme":"default","author":"ApacheCN","my_plugins":["donate","todo","-lunr","-search","expandable-chapters-small","chapter-fold","expandable-chapters","expandable-chapters-small","back-to-top-button","ga","baidu","sitemap","tbfed-pagefooter","advanced-emoji","sectionx","page-treeview","simple-page-toc","ancre-navigation","theme-apachecn@git+https://github.com/apachecn/theme-apachecn#HEAD","pagefooter-apachecn@git+https://github.com/apachecn/gitbook-plugin-pagefooter-apachecn#HEAD"],"my_pluginsConfig":{"page-treeview":{"copyright":"Copyright &#169; aleen42","minHeaderCount":"2","minHeaderDeep":"2"},"ignores":["node_modules"],"simple-page-toc":{"maxDepth":3,"skipFirstH1":true},"page-copyright":{"wisdom":"Designer, Frontend Developer & overall web enthusiast","noPowered":false,"copyright":"Copyright &#169; 你的名字","style":"normal","timeColor":"#666","utcOffset":"8","format":"YYYY-MM-dd hh:mm:ss","signature":"你的签名","copyrightColor":"#666","description":"modified at"},"donate":{"wechat":"微信收款的二维码URL","alipay":"支付宝收款的二维码URL","title":"","button":"赏","alipayText":"支付宝打赏","wechatText":"微信打赏"},"page-toc-button":{"maxTocDepth":2,"minTocSize":2},"github-buttons":{"buttons":[{"user":"apachecn","repo":"sklearn-doc-zh","type":"star","count":true,"size":"small"},{"user":"apachecn","width":"160","type":"follow","count":true,"size":"small"}]},"ga":{"token":"UA-102475051-10"},"baidu":{"token":"75439e2cbd22bdd813226000e9dcc12f"},"pagefooter-apachecn":{"copyright":"Copyright &copy ibooker.org.cn 2019","modify_label":"该文件修订时间： ","modify_format":"YYYY-MM-DD HH:mm:ss"}},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"sklearn 中文文档","language":"zh-hans","gitbook":"*","description":"sklearn 中文文档: 教程和文档"},"file":{"path":"22.md","mtime":"2019-06-04T12:46:46.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-11-29T10:03:22.665Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-insert-logo/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-pageview-count/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-alerts/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-auto-scroll-table/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-hide-element/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-page-toc-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

